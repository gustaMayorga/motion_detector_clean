# PROYECTO vigIA - DOCUMENTACIÓN COMPLETA
# Generado el 2025-03-16 09:17:11.843334

## ESTRUCTURA DE DIRECTORIOS

```
.env
.gitignore
Data.txt
Dockerfile
__init__.py
avances.txt
config.yaml
configs/
    config.yaml
data/
    configs/
        system_config.yaml
    hls/
    recordings/
    snapshots/
docker-compose.yml
docs/
    guia_usuario.md
documentar_proyecto.py
main.py
models/
    yolov8n.pt
requirements.txt
src/
    agent_modules/
        __init__.py
        access_control/
            access_agent.py
            hardware_controller.py
        base/
            __init__.py
            agent_base.py
        base_agent.py
        video_analytics/
            __init__.py
            video_agent.py
    ai/
        behavior_analyzer.py
        face_recognition_system.py
        object_detector.py
    alerts/
        alert_prioritizer.py
    analytics/
        behavior_analyzer.py
    api/
        __init__.py
        api.py
        auth.py
        server.py
        surveillance_api.py
        websocket.py
    camera_vendors/
        base.py
        dahua.py
        hikvision.py
    config/
        agent_config.py
        base_config.py
        config_loader.py
        system_config.py
    core/
        __init__.py
        event_system/
            __init__.py
            event_bus.py
        master_control/
            __init__.py
            system_controller.py
        ml_engine/
            __init__.py
            behavior_analyzer.py
            face_recognition.py
            ml_controller.py
            object_detection.py
            object_detector.py
            object_tracker.py
            object_tracking.py
            plate_recognition.py
    database/
        db.py
        models.py
    detection/
        object_detector.py
    events/
        event_bus.py
    frontend/
        dashboard/
            camera_view_panel.js
            security_alerts.js
            statistics_panel.js
            unified_control.js
        labeling/
            labeling_tool.js
        services/
            alert_service.js
            auth_service.js
            config_service.js
        src/
            components/
                ConfigEditor.vue
        static/
            css/
                styles.css
        templates/
            index.html
    main.py
    ml/
        model_evaluation.py
        model_trainer.py
    notifications/
        email_notifier.py
        notification_manager.py
        push_notifier.py
        sms_notifier.py
        webhook_notifier.py
    processing/
        video_processor.py
    response/
        active_response.py
    services/
        __init__.py
        alert_manager.py
        communication/
            alert_service.py
            communication_base.py
            whatsapp_service.py
        notification/
            __init__.py
            notification_base.py
            whatsapp_service.py
        video_recorder/
            __init__.py
            recorder.py
        visitor_management.py
    storage/
        smart_recorder.py
        storage_manager.py
        video_indexer.py
    tools/
        diagnostic.py
    tracking/
        multi_object_tracker.py
    training/
        adaptive_learning.py
        dataset_manager.py
        model_trainer.py
    utils/
        __init__.py
        logging/
            __init__.py
            logger.py
    web/
        __init__.py
        server.py
        static/
        templates/
            agents.html
            base.html
            error.html
            events.html
            index.html
            media.html
vigia.db
vigia_proyecto_completo.txt
```

## CONTENIDO DE ARCHIVOS

### .env
``` | 354 bytes | Modificado: 2025-03-14 11:12:14.663578
```
# Configuración de la Base de Datos
DATABASE_URL=postgresql://vigia:vigia@db:5432/vigia

# Configuración de Redis
REDIS_HOST=redis
REDIS_PORT=6379

# Configuración de JWT
JWT_SECRET=supersecretkey_change_this_in_production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=60

# Configuración del Sistema
LOG_LEVEL=INFO
ENVIRONMENT=development
```

### .gitignore
``` | 364 bytes | Modificado: 2025-03-13 13:27:50.294139
```
@"
# Entornos virtuales
venv/
env/
vigia_env*/
**/venv/
**/__pycache__/

# Archivos grandes
*.pt
*.pth
*.onnx
*.weights
*.dll
*.lib
*.pyd
models/*.pt
data/*.mp4
data/*.avi

# Archivos de caché de Python
__pycache__/
*.py[cod]
*$py.class
.pytest_cache/

# Sistema
.DS_Store
Thumbs.db
"@ | Out-File -FilePath ".gitignore" -Encoding utf8
```

### Data.txt
```txt | 6011 bytes | Modificado: 2025-03-14 16:27:40.377001
```
Parece que necesito hacer un análisis completo del proyecto para verificar todos los archivos, su estructura y entender de qué trata el proyecto. Basándome en los archivos revisados, puedo empezar a delinear lo siguiente:
El proyecto parece ser un sistema de vigilancia inteligente con IA llamado "vigIA" que incluye:
Detección de objetos y movimiento
Seguimiento de objetos
Análisis de comportamiento
Reconocimiento facial
Sistema de alertas
6. Almacenamiento de video y eventos
Interfaz web para monitoreo
Capacidades de aprendizaje adaptativo
Gestión de visitantes y control de acceso
Voy a analizar la estructura de archivos y las correcciones necesarias:
Errores de Indentación en los archivos Python:
src/training/dataset_manager.py - métodos sin bloques de código implementados
src/training/model_trainer.py - método export_model sin cuerpo implementado
src/ml/model_evaluation.py - problemas de indentación al principio y fin del archivo
src/ai/behavior_analyzer.py - problemas de indentación similar
Problemas de accesibilidad en botones HTML:
Buttons sin atributo title en src/frontend/templates/index.html
La estructura general del proyecto parece ser:
El archivo principal parece ser src/main.py que inicia el sistema y carga la configuración.
Los errores principales que veo son problemas de indentación en algunos módulos de Python y problemas de accesibilidad en el HTML. También veo que algunos archivos pueden tener implementaciones incompletas o placeholder.
En cuanto al entendimiento general del proyecto:
Este es un sistema de videovigilancia inteligente con IA que puede detectar objetos y comportamientos anómalos, generar alertas, almacenar evidencia y ofrecer una interfaz de control. Parece tener capacidades avanzadas como análisis adaptativo (que aprende de los datos específicos del cliente) y múltiples métodos de notificación.
</think>
Revisión del Proyecto vigIA - Sistema de Vigilancia Inteligente
He revisado todos los archivos y entiendo que estás desarrollando un sistema integral de videovigilancia inteligente con IA llamado "vigIA". Veamos la estructura y estado actual del proyecto:
Arquitectura general del sistema
El proyecto está bien organizado con una arquitectura modular:
Correcciones pendientes
Hay algunos errores de sintaxis y estructura que deben corregirse:
1. Archivos con bloques vacíos
src/training/dataset_manager.py - Los métodos necesitan implementación
src/training/model_trainer.py - Método export_model sin cuerpo
2. Problemas de indentación
src/ml/model_evaluation.py - Indentación incorrecta
src/ai/behavior_analyzer.py - Indentación inesperada
3. Problemas de accesibilidad HTML
src/frontend/templates/index.html - Botones sin atributo title
Componentes principales
El sistema incluye:
Detección de objetos: Motor basado en modelos de IA para reconocer objetos
Análisis de comportamiento: Detecta patrones como intrusión, merodeo, etc.
Seguimiento de objetos: Sistema de tracking para seguimiento en tiempo real
4. Gestión de almacenamiento: Para videos, imágenes y eventos
Sistema de alertas: Notificaciones por múltiples canales
Dashboard web: Interfaz de control centralizada
Aprendizaje adaptativo: Personalización por cliente
Próximos pasos recomendados
Completar implementaciones pendientes:
Implementar los métodos vacíos en dataset_manager.py y model_trainer.py
Corregir errores de indentación:
Revisar y corregir la indentación en los archivos mencionados
Mejorar accesibilidad web:
Añadir atributos title a los botones en index.html
Configurar sistema:
Crear los archivos de configuración en formato YAML para los agentes y sistema


src/
  ├── agent_modules/       # Agentes de seguridad modulares
  ├── ai/                  # Componentes de IA (detección, reconocimiento, análisis)
  ├── api/                 # API REST para comunicación
  ├── config/              # Configuración del sistema
  ├── core/                # Núcleo del sistema y controladores
  ├── events/              # Sistema de eventos
  ├── frontend/            # Interfaz de usuario web
  ├── ml/                  # Modelos de machine learning
  ├── notifications/       # Sistema de notificaciones
  ├── response/            # Respuestas activas a eventos
  ├── services/            # Servicios diversos (visitantes, alertas)
  ├── storage/             # Almacenamiento de video y datos
  ├── tracking/            # Seguimiento de objetos
  ├── training/            # Entrenamiento de modelos
  └── web/                 # Servidor web



  Para el Docker:

docker-compose down
docker-compose build
docker-compose up -d
docker-compose logs -f app


-------------------------------------

Docker INconsciente:

Pasos para después del reinicio:
Iniciar limpiamente Docker Desktop:
Asegúrate de que inicie correctamente
Espera unos minutos para que se estabilice
Limpiar el entorno Docker:

   # Remover contenedores, redes, imágenes y volúmenes no utilizados
   docker system prune -a --volumes


      cd E:\IA\motion_detector_clean
   docker-compose build
   docker-compose up -d



   Si el problema persiste después del reinicio:
Revisa el archivo de configuración de Docker:

   # Verificar que el compose file sea válido
   docker-compose config



Prueba con un compose file simplificado:
Crea un docker-compose.yml mínimo con solo el servicio principal
Ve agregando servicios uno a uno
Considera la opción de desinstalar y reinstalar Docker Desktop
Alternativa: Ejecutar sin Docker temporalmente
Si necesitas avanzar con el desarrollo mientras solucionas los problemas de Docker:

# Crear entorno virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar la aplicación 
$env:PYTHONPATH = "."
python -m src.main
```

### Dockerfile
``` | 1098 bytes | Modificado: 2025-03-14 10:23:46.477601
```
FROM python:3.10-slim

WORKDIR /app

# Instalar todas las dependencias del sistema necesarias de una vez
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    git \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Copiar archivos de requisitos
COPY requirements.txt .

# Instalar dependencias en orden específico para optimizar
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir psycopg2-binary && \
    pip install --no-cache-dir numpy opencv-python && \
    pip install --no-cache-dir torch>=1.7.0 torchvision --index-url https://download.pytorch.org/whl/cpu && \
    pip install --no-cache-dir -r requirements.txt

# Copiar el código de la aplicación
COPY . .

# Crear directorios necesarios
RUN mkdir -p data/recordings data/snapshots data/hls logs models data/configs

# Configurar variables de entorno
ENV PYTHONPATH=/app

# Puerto para la API
EXPOSE 8000

# Comando por defecto
CMD ["python", "-m", "src.main"]
```

### __init__.py
```py | 153 bytes | Modificado: 2025-03-05 19:19:16.234872
```
from . import agent_modules
from . import core
from . import services
from . import utils

__all__ = ['agent_modules', 'core', 'services', 'utils'] 
```

### avances.txt
```txt | 13888 bytes | Modificado: 2025-03-15 14:09:43.879719
```
SEGUIMIENTO DE AVANCES - PROYECTO vigIA
=======================================

Fecha: 2023-07-15
Hora: 10:30

AVANCE #1:
- Implementado dataset_manager.py completo con las siguientes funciones:
  * _discover_datasets: Encuentra datasets existentes
  * create_dataset: Crea estructura para nuevo dataset
  * add_sample: Añade muestra al dataset con anotaciones
  * export_dataset: Exporta en formato compatible (YOLO, COCO)
  * get_dataset_info: Obtiene información del dataset
  * delete_dataset: Elimina un dataset completo
- Estructura cumple con prácticas recomendadas de YOLO
- Soporte para exportación a diferentes formatos

Fecha: 2023-07-15
Hora: 11:15

AVANCE #2:
- Implementado model_trainer.py con integración MLflow:
  * Soporte para tracking de experimentos
  * Registro de parámetros, métricas y artefactos
  * Exportación de modelos a ONNX y TFLite
- Creado conector para cámaras Dahua (dahua.py):
  * Obtención de URLs de streaming RTSP
  * Control PTZ
  * Captura de snapshots
  * Información del dispositivo
- Ambos módulos incluyen manejo de errores y logging

Fecha: 2023-07-15
Hora: 12:00

AVANCE #3:
- Implementado sistema de eventos con Redis PubSub:
  * Publicación asíncrona de mensajes
  * Suscripción a canales con manejadores personalizados
  * Reconexión automática en caso de fallos
  * Manejo de errores y logging
- Creado esquema de base de datos con SQLAlchemy:
  * Modelos para usuarios, cámaras, alertas, zonas, etc.
  * Relaciones entre entidades
  * Timestamps automáticos con mixins
  * Helper de gestión de sesiones de base de datos
- Los módulos implementados siguen buenas prácticas:
  * Tipado estático
  * Manejo de excepciones
  * Documentación de código
  * Patrones de diseño adecuados

Fecha: 2023-07-15 
Hora: 13:00

AVANCE #4:
- Implementado archivo de configuración YAML centralizado:
  * Configuración completa del sistema
  * Soporte para variables de entorno
  * Configuración de componentes (cámaras, detección, etc.)
  * Estructura modular y escalable
- Creada API REST con FastAPI:
  * Autenticación JWT
  * Gestión de usuarios
  * Gestión de cámaras y zonas
  * Consulta de alertas
  * Estado del sistema
- Creado cargador de configuración:
  * Procesamiento de variables de entorno
  * Manejo de errores
  * Guardado de configuración
- El sistema ya cuenta con una arquitectura completa y funcional

Fecha: 2023-07-15 
Hora: 14:00

AVANCE #5:
- Implementado procesador de video:
  * Integración con YOLO para detección de objetos
  * Integración con ByteTrack para seguimiento de objetos
  * Análisis de zonas y generación de eventos
  * Análisis de comportamiento (merodeo, intrusión)
  * Visualización de resultados
- Implementada API WebSocket:
  * Transmisión de eventos en tiempo real
  * Manejo de conexiones y desconexiones
  * Integración con EventBus
  * Canales por tipo de evento
- Implementado gestor de almacenamiento:
  * Grabación automática de video
  * Captura de snapshots
  * Limpieza automática según retención
  * Monitoreo de uso de disco
- La arquitectura ahora funciona completamente en tiempo real

Fecha: 2023-07-15 
Hora: 15:00

AVANCE #6:
- Implementado script de inicialización del sistema:
  * Arranque coordinado de todos los componentes
  * Verificación y creación de datos iniciales
  * Manejo de señales para apagado graceful
  * Integración con la API y WebSockets
- Creado componente frontend para la configuración:
  * Editor de configuración general del sistema
  * Gestión de cámaras y zonas
  * Configuración de agentes de análisis
  * Interfaz intuitiva con pestañas y formularios
- Implementada configuración de Docker:
  * Dockerfile para el backend
  * Docker-compose con servicios necesarios (PostgreSQL, Redis)
  * Volúmenes para persistencia de datos
  * Nginx para servir el frontend
- El sistema está ahora listo para ser desplegado y utilizado 

Fecha: 2023-10-12
Hora: 16:30

AVANCE #7:
- Actualizaciones para compatibilidad con las últimas bibliotecas:
  * Cambiada ruta de importación en video_processor.py: 
    - De: ultralytics.yolo.utils.ops 
    - A: ultralytics.utils.ops
  * Creado archivo base.py para integración de cámaras
  * Creado archivo auth.py para autenticación en websockets
  * Instaladas dependencias adicionales:
    - email-validator para validación de correos
    - pydantic[email] para modelos más robustos
    - fastapi y dependencias relacionadas
- Cambios en estructura de directorios:
  * Creados directorios data/configs, data/recordings, data/snapshots
  * Creados directorios models y logs para almacenamiento
- Ajustes en configuración y variables de entorno:
  * Creado archivo system_config.yaml inicial
  * Configuradas variables de entorno para ejecución en modo desarrollo
- Soluciones para problemas de dependencias:
  * Comentadas temporalmente funciones de tracking (ByteTrack)
  * Ajustada configuración para inicio sin Redis en modo de prueba
- El sistema ahora puede ejecutarse en modo depuración con:
  python -m src.main --debug 

Fecha: 2023-10-12
Hora: 17:15

ACTUALIZACIÓN #7.1:
- Instaladas dependencias adicionales para autenticación y seguridad:
  * werkzeug para generación de hashes de contraseñas
  * flask-sqlalchemy para modelos de usuarios
  * psycopg2-binary para compatibilidad con PostgreSQL
- Primer inicio exitoso con inicialización de base de datos
- Creación automática de usuario administrador predeterminado
- El sistema ahora inicia correctamente en modo depuración 

Fecha: 2023-10-12
Hora: 17:45

ACTUALIZACIÓN #7.2:
- Solución para problema de conexión con Redis:
  * Modificado código para continuar en modo degradado sin Redis
  * Implementado modo de prueba que omite servicios externos
- El sistema ahora inicia correctamente sin dependencias externas
- Configuración para ejecutar en entornos limitados o de desarrollo
- Mejorada la resiliencia: el sistema puede operar con servicios no disponibles 

Fecha: 2023-10-12
Hora: 18:15

ACTUALIZACIÓN #7.3:
- Implementada solución robusta para ejecutar sin Redis:
  * Creado sistema de mock objects para simular bus de eventos
  * Manejo de excepciones mejorado para continuar sin servicios críticos
  * Implementada clase AsyncMock para simular funciones asíncronas
- El sistema ahora tiene mejor gestión de errores y tolerancia a fallos
- Probado inicio completo en entorno sin dependencias externas 

Fecha: 2023-10-12
Hora: 18:45

ACTUALIZACIÓN #7.4:
- Implementación de manejadores de eventos faltantes:
  * Añadido método handle_recording_started al StorageManager
  * Añadido método handle_recording_stopped al StorageManager
  * Mejorado el manejo de grabaciones en proceso
- Reforzado el sistema de manejo de errores:
  * Detección y recuperación de componentes faltantes
  * Simulación de componentes para pruebas (Mock objects)
- El sistema ahora detecta y reporta correctamente problemas en tiempo de ejecución
- Preparado para iniciar sin servicios de almacenamiento cuando sea necesario 

Fecha: 2023-10-12
Hora: 19:15

ACTUALIZACIÓN #7.5:
- Implementación de manejadores de eventos adicionales:
  * Añadido manejador handle_alert_generated al StorageManager
  * Implementado almacenamiento de snapshots para alertas
  * Asociación automática entre alertas y sus evidencias visuales
- Corrección de modelo de datos:
  * Añadido campo is_active a la clase Camera
  * Actualizado esquema de base de datos
- El sistema ahora puede procesar alertas correctamente
- Mejorado el flujo de eventos entre detección y almacenamiento 

Fecha: 2023-10-12
Hora: 19:45

ACTUALIZACIÓN #7.6:
- Resuelto problema de inconsistencia en la base de datos:
  * Actualizada estructura de la tabla cameras con nuevos campos
  * Recreada base de datos para aplicar todos los cambios de esquema
  * Sincronizados modelos SQLAlchemy con tablas físicas
- Mejoras en el esquema de datos:
  * Simplificación de campos de configuración de cámaras
  * Mejor organización de relaciones entre entidades
  * Campos optimizados para rendimiento en consultas frecuentes
- El sistema ahora tiene un esquema de datos sólido y coherente
- Base de datos completamente compatible con la estructura del código 

Fecha: 2023-10-12
Hora: 20:15

ACTUALIZACIÓN #7.7:
- Sistema inicializado correctamente:
  * Base de datos creada con estructura actual
  * Bus de eventos conectado a Redis
  * Gestor de almacenamiento inicializado
  * Manejador de WebSockets configurado
- Configuración de red y puertos:
  * Detección y solución de conflictos de puertos
  * Implementada configuración dinámica de puerto mediante variables de entorno
  * Mejorada gestión de conexiones a servicios
- El sistema ahora arranca completo con todos los componentes
- API REST y WebSockets listos para servir clientes
- Primera ejecución exitosa del sistema completo 

Fecha: 2023-10-12
Hora: 20:45

ACTUALIZACIÓN #7.8:
- Configuración personalizada de red:
  * Cambiado puerto predeterminado de 8000 a 8800
  * Evitado conflicto con otros servicios en el sistema
  * Mejorada configuración de binding de red
- Documentación y procedimientos:
  * Añadidas instrucciones para configuración de puertos
  * Documentado proceso de resolución de conflictos
  * Creada guía de diagnóstico de problemas de red
- El sistema ahora es más flexible y configurable
- Mejorada la experiencia de instalación y despliegue 

Fecha: 2023-10-12
Hora: 21:15

ACTUALIZACIÓN #7.9:
- Resuelto problema de configuración CORS:
  * Actualizada lógica para manejo de orígenes permitidos
  * Mejorada resiliencia ante cambios en configuración
  * Simplificada configuración de seguridad de API
- Ajustes en la estructura del archivo de configuración:
  * Eliminadas entradas obsoletas o duplicadas
  * Mejorada organización de secciones
  * Documentadas opciones disponibles
- El sistema ahora maneja mejor configuraciones incompletas o faltantes
- Mejorado soporte para despliegues en entornos diversos 

Fecha: 2023-10-12
Hora: 21:45

ACTUALIZACIÓN #7.10:
- Mejorada la experiencia de usuario en la API:
  * Añadido endpoint en ruta raíz con información básica
  * Documentados todos los endpoints disponibles
  * Propuesta de navegación por recursos del API
- Sistema completamente operativo:
  * API accesible en puerto 8800
  * Documentación interactiva disponible
  * Endpoints para gestión de cámaras y alertas
- Verificada integración completa entre componentes:
  * Base de datos y modelos
  * Sistema de eventos
  * API REST
  * WebSockets para tiempo real
- El sistema está listo para pruebas funcionales completas 

Fecha: 2023-10-12
Hora: 22:15

ACTUALIZACIÓN #7.11:
- Diagnóstico integral y corrección del sistema de autenticación:
  * Creada herramienta de diagnóstico completo
  * Corrección de hash de contraseñas en base de datos
  * Mejorado sistema de creación y actualización de usuarios
  * Implementado registro detallado de operaciones
- Solución robusta para el inicio de sesión:
  * Verificación correcta de credenciales
  * Manejo adecuado de roles y permisos
  * Tokens JWT configurados correctamente
- Documentación completa del proceso de autenticación:
  * Guía para obtener tokens mediante API
  * Explicación del flujo de autenticación
  * Procedimientos de gestión de usuarios
- Sistema completamente funcional y accesible 

Fecha: 2023-10-13
Hora: 08:30

ACTUALIZACIÓN #7.12:
- Corregido sistema de autenticación con tokens JWT:
  * Mejorado proceso de decodificación de tokens
  * Añadido registro detallado para depuración
  * Implementado manejo correcto de errores en autenticación
  * Compatibilidad con diferentes versiones de PyJWT
- Verificados endpoints protegidos de la API:
  * Estado del sistema
  * Gestión de usuarios
  * Gestión de cámaras y alertas
- Documentación actualizada para uso correcto de autenticación
- El sistema ahora funciona correctamente con todas las funciones protegidas 

Fecha: 2023-10-13
Hora: 09:15

ACTUALIZACIÓN #7.13:
- Depuración avanzada del sistema de autenticación JWT:
  * Implementado endpoint de diagnóstico de tokens
  * Corregida inconsistencia de tipo en ID de usuario (sub)
  * Mejorado manejo de errores con mensajes detallados
  * Logs detallados para seguimiento de autenticación
- Documentación actualizada para diagnóstico de problemas:
  * Instrucciones para verificar tokens
  * Guía para detectar problemas de autenticación
  * Ejemplos de uso correcto de la API
- Implementado sistema de recuperación automática:
  * Detección y manejo de tokens mal formados
  * Compatibilidad con diferentes versiones del cliente
- El sistema ahora es robusto ante problemas de autenticación 

Fecha: 2023-10-13
Hora: 10:00

ACTUALIZACIÓN #7.14:
- Correcciones para compatibilidad con clientes diversos:
  * Mejorado manejo de datos en formato JSON y formulario
  * Adaptación de rutas para acceso más intuitivo
  * Implementada documentación en español para API
  * Guía detallada para uso desde diferentes plataformas
- Script de prueba PowerShell completo y funcional:
  * Verificación paso a paso de todos los componentes
  * Identificación clara de éxitos y errores
  * Creación automática de usuarios de prueba
  * Demostración de todas las funcionalidades principales
- Mejoras de usabilidad para administradores:
  * Endpoints más descriptivos
  * Mensajes de error detallados y específicos
  * Registros mejorados para diagnóstico
- Sistema completamente funcional y probado 
```

### config.yaml
```yaml | 1414 bytes | Modificado: 2025-03-13 21:46:25.871082
```
# Crear un archivo config.yaml más completo
@"
# Configuración del Sistema vigIA
# ------------------------------

# Configuración general del sistema
system:
  name: "vigIA"
  version: "1.0.0"
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  timezone: "America/Argentina/Buenos_Aires"
  temp_dir: "/tmp/vigia"
  enable_debug: false
  
# Configuración de base de datos
database:
  type: "postgresql"
  host: "db"
  port: 5432
  database: "vigia"
  username: "vigia"
  password: "vigia"
  pool_size: 10
  max_connections: 20
  ssl_mode: "prefer"
  
# Configuración de Redis para eventos
redis:
  host: "redis"
  port: 6379
  db: 0
  password: null
  use_ssl: false
  retry_on_timeout: true
  
# Configuración de almacenamiento
storage:
  recordings_dir: "/app/data/recordings"
  max_disk_usage_percent: 90
  retention_days: 30
  auto_clean: true
  snapshots_dir: "/app/data/snapshots"
  models_dir: "/app/models"
  
# Configuración de API
api:
  host: "0.0.0.0"
  port: 8000
  enable_cors: true
  cors_origins: ["*"]
  jwt_expiration: 86400  # 24 horas en segundos
  
# Configuración de detección y análisis
detection:
  default_model: "yolov8n.pt"
  confidence_threshold: 0.25
  iou_threshold: 0.45
  max_detections: 100
  enable_gpu: true
  gpu_id: 0
  batch_size: 1
"@ | Out-File -FilePath "configs\config.yaml" -Encoding ascii
```

### docker-compose.yml
```yml | 917 bytes | Modificado: 2025-03-14 11:11:58.858947
```
version: '3.8'

services:
  app:
    build: .
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./configs:/app/configs
      - ./logs:/app/logs
      - ./models:/app/models
    environment:
      - DATABASE_URL=postgresql://vigia:vigia@db:5432/vigia
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - JWT_SECRET=supersecretkey_change_this_in_production
    depends_on:
      - db
      - redis

  db:
    image: postgres:13
    restart: unless-stopped
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=vigia
      - POSTGRES_PASSWORD=vigia
      - POSTGRES_DB=vigia
    ports:
      - "5432:5432"

  redis:
    image: redis:6
    restart: unless-stopped
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"

volumes:
  postgres_data:
  redis_data:
```

### documentar_proyecto.py
```py | 4148 bytes | Modificado: 2025-03-16 09:17:08.741822
```
#!/usr/bin/env python
"""
Script para documentar la estructura y contenido del proyecto vigIA
"""

import os
import datetime
import fnmatch

# Configuración
proyecto_dir = "E:/IA/motion_detector_clean"  # Ajusta esta ruta
archivo_salida = "vigia_proyecto_completo.txt"
ignorar_directorios = ["venv", "__pycache__", "node_modules", ".git", ".idea", ".vscode", "logs", "ByteTrack"]
ignorar_extensiones = [".pyc", ".pyo", ".so", ".dll", ".exe", ".bin", ".dat", ".db", ".jpg", ".jpeg", ".png", ".gif", ".mp4", ".avi"]
max_tamano_archivo = 1 * 1024 * 1024  # 1MB en bytes

# Inicializar estadísticas
archivos_procesados = 0
archivos_ignorados = 0
tamano_total = 0

# Crear o sobrescribir el archivo de salida
with open(archivo_salida, 'w', encoding='utf-8') as f:
    f.write("# PROYECTO vigIA - DOCUMENTACIÓN COMPLETA\n")
    f.write(f"# Generado el {datetime.datetime.now()}\n\n")
    
    # Estructura de directorios
    f.write("## ESTRUCTURA DE DIRECTORIOS\n\n```\n")
    
    def obtener_arbol_directorios(ruta, indentacion="", ignorar=None):
        elementos = sorted(os.listdir(ruta))
        for elemento in elementos:
            ruta_completa = os.path.join(ruta, elemento)
            if os.path.isdir(ruta_completa):
                if elemento in ignorar:
                    continue
                f.write(f"{indentacion}{elemento}/\n")
                obtener_arbol_directorios(ruta_completa, indentacion + "    ", ignorar)
            else:
                f.write(f"{indentacion}{elemento}\n")
    
    obtener_arbol_directorios(proyecto_dir, "", ignorar_directorios)
    f.write("```\n\n")
    
    # Contenido de archivos
    f.write("## CONTENIDO DE ARCHIVOS\n\n")
    
    for raiz, dirs, archivos in os.walk(proyecto_dir):
        # Filtrar directorios ignorados
        dirs[:] = [d for d in dirs if d not in ignorar_directorios]
        
        for archivo in sorted(archivos):
            ruta_completa = os.path.join(raiz, archivo)
            
            # Verificar si debemos ignorar este archivo
            ignorar = False
            
            # Verificar extensión
            _, extension = os.path.splitext(archivo)
            if extension.lower() in ignorar_extensiones:
                ignorar = True
            
            # Verificar tamaño
            tamano = os.path.getsize(ruta_completa)
            if tamano > max_tamano_archivo:
                ignorar = True
                
            if ignorar:
                archivos_ignorados += 1
                continue
                
            # Obtener ruta relativa
            ruta_relativa = os.path.relpath(ruta_completa, proyecto_dir)
            
            # Escribir información del archivo
            f.write(f"### {ruta_relativa}\n")
            f.write(f"```{extension[1:]} | {tamano} bytes | Modificado: {datetime.datetime.fromtimestamp(os.path.getmtime(ruta_completa))}\n")
            f.write("```\n")
            
            # Escribir contenido del archivo
            try:
                with open(ruta_completa, 'r', encoding='utf-8', errors='replace') as archivo_contenido:
                    contenido = archivo_contenido.read()
                    f.write(contenido)
            except Exception as e:
                f.write(f"ERROR: No se pudo leer el archivo: {str(e)}")
                
            f.write("\n```\n\n")
            
            archivos_procesados += 1
            tamano_total += tamano
    
    # Resumen
    f.write("## RESUMEN DE LA DOCUMENTACIÓN\n\n")
    f.write(f"- Archivos procesados: {archivos_procesados}\n")
    f.write(f"- Archivos ignorados: {archivos_ignorados}\n")
    f.write(f"- Tamaño total de archivos incluidos: {tamano_total / 1024:.2f} KB\n\n")
    f.write("Documentación generada con el script de documentación automática de vigIA.\n")

print(f"Documentación completa guardada en: {archivo_salida}")
print(f"Archivos procesados: {archivos_procesados}")
print(f"Archivos ignorados: {archivos_ignorados}")
print(f"Tamaño total: {tamano_total / 1024:.2f} KB")
```

### main.py
```py | 757 bytes | Modificado: 2025-03-05 13:50:24.348797
```
import asyncio
from pathlib import Path
from src.core.master_control.system_controller import SystemController
import signal
import sys

async def main():
    # Cargar configuración
    config_path = Path("data/configs/system_config.yaml")
    
    # Inicializar controlador
    controller = SystemController(config_path)
    
    # Manejar señales de terminación
    def signal_handler(sig, frame):
        print("\nDeteniendo sistema...")
        asyncio.create_task(controller.shutdown())
        sys.exit(0)
        
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # Iniciar sistema
    await controller.start()

if __name__ == "__main__":
    asyncio.run(main()) 
```

### requirements.txt
```txt | 517 bytes | Modificado: 2025-03-14 17:07:27.386709
```
# API y Web
fastapi==0.95.0
uvicorn==0.21.1
sqlalchemy==2.0.7
pydantic==1.10.7
python-dotenv==1.0.0
pyjwt==2.6.0
jinja2==3.1.2

# Base de datos
psycopg2-binary==2.9.5
redis==4.5.4
alembic==1.10.2

# Computer Vision
opencv-python==4.7.0.72
ultralytics==8.0.6
torch>=1.7.0
torchvision>=0.8.1
numpy==1.24.2
pillow==9.4.0

# Procesamiento
scikit-learn==1.2.2
scipy==1.10.1
matplotlib==3.7.1
pandas==1.5.3

# Utilidades
pyyaml==6.0
python-multipart==0.0.6
tenacity==8.2.2
aiofiles==23.1.0

```

### vigia_proyecto_completo.txt
```txt | 34435 bytes | Modificado: 2025-03-16 09:17:11.864330
```
# PROYECTO vigIA - DOCUMENTACIÓN COMPLETA
# Generado el 2025-03-16 09:17:11.843334

## ESTRUCTURA DE DIRECTORIOS

```
.env
.gitignore
Data.txt
Dockerfile
__init__.py
avances.txt
config.yaml
configs/
    config.yaml
data/
    configs/
        system_config.yaml
    hls/
    recordings/
    snapshots/
docker-compose.yml
docs/
    guia_usuario.md
documentar_proyecto.py
main.py
models/
    yolov8n.pt
requirements.txt
src/
    agent_modules/
        __init__.py
        access_control/
            access_agent.py
            hardware_controller.py
        base/
            __init__.py
            agent_base.py
        base_agent.py
        video_analytics/
            __init__.py
            video_agent.py
    ai/
        behavior_analyzer.py
        face_recognition_system.py
        object_detector.py
    alerts/
        alert_prioritizer.py
    analytics/
        behavior_analyzer.py
    api/
        __init__.py
        api.py
        auth.py
        server.py
        surveillance_api.py
        websocket.py
    camera_vendors/
        base.py
        dahua.py
        hikvision.py
    config/
        agent_config.py
        base_config.py
        config_loader.py
        system_config.py
    core/
        __init__.py
        event_system/
            __init__.py
            event_bus.py
        master_control/
            __init__.py
            system_controller.py
        ml_engine/
            __init__.py
            behavior_analyzer.py
            face_recognition.py
            ml_controller.py
            object_detection.py
            object_detector.py
            object_tracker.py
            object_tracking.py
            plate_recognition.py
    database/
        db.py
        models.py
    detection/
        object_detector.py
    events/
        event_bus.py
    frontend/
        dashboard/
            camera_view_panel.js
            security_alerts.js
            statistics_panel.js
            unified_control.js
        labeling/
            labeling_tool.js
        services/
            alert_service.js
            auth_service.js
            config_service.js
        src/
            components/
                ConfigEditor.vue
        static/
            css/
                styles.css
        templates/
            index.html
    main.py
    ml/
        model_evaluation.py
        model_trainer.py
    notifications/
        email_notifier.py
        notification_manager.py
        push_notifier.py
        sms_notifier.py
        webhook_notifier.py
    processing/
        video_processor.py
    response/
        active_response.py
    services/
        __init__.py
        alert_manager.py
        communication/
            alert_service.py
            communication_base.py
            whatsapp_service.py
        notification/
            __init__.py
            notification_base.py
            whatsapp_service.py
        video_recorder/
            __init__.py
            recorder.py
        visitor_management.py
    storage/
        smart_recorder.py
        storage_manager.py
        video_indexer.py
    tools/
        diagnostic.py
    tracking/
        multi_object_tracker.py
    training/
        adaptive_learning.py
        dataset_manager.py
        model_trainer.py
    utils/
        __init__.py
        logging/
            __init__.py
            logger.py
    web/
        __init__.py
        server.py
        static/
        templates/
            agents.html
            base.html
            error.html
            events.html
            index.html
            media.html
vigia.db
vigia_proyecto_completo.txt
```

## CONTENIDO DE ARCHIVOS

### .env
``` | 354 bytes | Modificado: 2025-03-14 11:12:14.663578
```
# Configuración de la Base de Datos
DATABASE_URL=postgresql://vigia:vigia@db:5432/vigia

# Configuración de Redis
REDIS_HOST=redis
REDIS_PORT=6379

# Configuración de JWT
JWT_SECRET=supersecretkey_change_this_in_production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=60

# Configuración del Sistema
LOG_LEVEL=INFO
ENVIRONMENT=development
```

### .gitignore
``` | 364 bytes | Modificado: 2025-03-13 13:27:50.294139
```
@"
# Entornos virtuales
venv/
env/
vigia_env*/
**/venv/
**/__pycache__/

# Archivos grandes
*.pt
*.pth
*.onnx
*.weights
*.dll
*.lib
*.pyd
models/*.pt
data/*.mp4
data/*.avi

# Archivos de caché de Python
__pycache__/
*.py[cod]
*$py.class
.pytest_cache/

# Sistema
.DS_Store
Thumbs.db
"@ | Out-File -FilePath ".gitignore" -Encoding utf8
```

### Data.txt
```txt | 6011 bytes | Modificado: 2025-03-14 16:27:40.377001
```
Parece que necesito hacer un análisis completo del proyecto para verificar todos los archivos, su estructura y entender de qué trata el proyecto. Basándome en los archivos revisados, puedo empezar a delinear lo siguiente:
El proyecto parece ser un sistema de vigilancia inteligente con IA llamado "vigIA" que incluye:
Detección de objetos y movimiento
Seguimiento de objetos
Análisis de comportamiento
Reconocimiento facial
Sistema de alertas
6. Almacenamiento de video y eventos
Interfaz web para monitoreo
Capacidades de aprendizaje adaptativo
Gestión de visitantes y control de acceso
Voy a analizar la estructura de archivos y las correcciones necesarias:
Errores de Indentación en los archivos Python:
src/training/dataset_manager.py - métodos sin bloques de código implementados
src/training/model_trainer.py - método export_model sin cuerpo implementado
src/ml/model_evaluation.py - problemas de indentación al principio y fin del archivo
src/ai/behavior_analyzer.py - problemas de indentación similar
Problemas de accesibilidad en botones HTML:
Buttons sin atributo title en src/frontend/templates/index.html
La estructura general del proyecto parece ser:
El archivo principal parece ser src/main.py que inicia el sistema y carga la configuración.
Los errores principales que veo son problemas de indentación en algunos módulos de Python y problemas de accesibilidad en el HTML. También veo que algunos archivos pueden tener implementaciones incompletas o placeholder.
En cuanto al entendimiento general del proyecto:
Este es un sistema de videovigilancia inteligente con IA que puede detectar objetos y comportamientos anómalos, generar alertas, almacenar evidencia y ofrecer una interfaz de control. Parece tener capacidades avanzadas como análisis adaptativo (que aprende de los datos específicos del cliente) y múltiples métodos de notificación.
</think>
Revisión del Proyecto vigIA - Sistema de Vigilancia Inteligente
He revisado todos los archivos y entiendo que estás desarrollando un sistema integral de videovigilancia inteligente con IA llamado "vigIA". Veamos la estructura y estado actual del proyecto:
Arquitectura general del sistema
El proyecto está bien organizado con una arquitectura modular:
Correcciones pendientes
Hay algunos errores de sintaxis y estructura que deben corregirse:
1. Archivos con bloques vacíos
src/training/dataset_manager.py - Los métodos necesitan implementación
src/training/model_trainer.py - Método export_model sin cuerpo
2. Problemas de indentación
src/ml/model_evaluation.py - Indentación incorrecta
src/ai/behavior_analyzer.py - Indentación inesperada
3. Problemas de accesibilidad HTML
src/frontend/templates/index.html - Botones sin atributo title
Componentes principales
El sistema incluye:
Detección de objetos: Motor basado en modelos de IA para reconocer objetos
Análisis de comportamiento: Detecta patrones como intrusión, merodeo, etc.
Seguimiento de objetos: Sistema de tracking para seguimiento en tiempo real
4. Gestión de almacenamiento: Para videos, imágenes y eventos
Sistema de alertas: Notificaciones por múltiples canales
Dashboard web: Interfaz de control centralizada
Aprendizaje adaptativo: Personalización por cliente
Próximos pasos recomendados
Completar implementaciones pendientes:
Implementar los métodos vacíos en dataset_manager.py y model_trainer.py
Corregir errores de indentación:
Revisar y corregir la indentación en los archivos mencionados
Mejorar accesibilidad web:
Añadir atributos title a los botones en index.html
Configurar sistema:
Crear los archivos de configuración en formato YAML para los agentes y sistema


src/
  ├── agent_modules/       # Agentes de seguridad modulares
  ├── ai/                  # Componentes de IA (detección, reconocimiento, análisis)
  ├── api/                 # API REST para comunicación
  ├── config/              # Configuración del sistema
  ├── core/                # Núcleo del sistema y controladores
  ├── events/              # Sistema de eventos
  ├── frontend/            # Interfaz de usuario web
  ├── ml/                  # Modelos de machine learning
  ├── notifications/       # Sistema de notificaciones
  ├── response/            # Respuestas activas a eventos
  ├── services/            # Servicios diversos (visitantes, alertas)
  ├── storage/             # Almacenamiento de video y datos
  ├── tracking/            # Seguimiento de objetos
  ├── training/            # Entrenamiento de modelos
  └── web/                 # Servidor web



  Para el Docker:

docker-compose down
docker-compose build
docker-compose up -d
docker-compose logs -f app


-------------------------------------

Docker INconsciente:

Pasos para después del reinicio:
Iniciar limpiamente Docker Desktop:
Asegúrate de que inicie correctamente
Espera unos minutos para que se estabilice
Limpiar el entorno Docker:

   # Remover contenedores, redes, imágenes y volúmenes no utilizados
   docker system prune -a --volumes


      cd E:\IA\motion_detector_clean
   docker-compose build
   docker-compose up -d



   Si el problema persiste después del reinicio:
Revisa el archivo de configuración de Docker:

   # Verificar que el compose file sea válido
   docker-compose config



Prueba con un compose file simplificado:
Crea un docker-compose.yml mínimo con solo el servicio principal
Ve agregando servicios uno a uno
Considera la opción de desinstalar y reinstalar Docker Desktop
Alternativa: Ejecutar sin Docker temporalmente
Si necesitas avanzar con el desarrollo mientras solucionas los problemas de Docker:

# Crear entorno virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar la aplicación 
$env:PYTHONPATH = "."
python -m src.main
```

### Dockerfile
``` | 1098 bytes | Modificado: 2025-03-14 10:23:46.477601
```
FROM python:3.10-slim

WORKDIR /app

# Instalar todas las dependencias del sistema necesarias de una vez
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    git \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Copiar archivos de requisitos
COPY requirements.txt .

# Instalar dependencias en orden específico para optimizar
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir psycopg2-binary && \
    pip install --no-cache-dir numpy opencv-python && \
    pip install --no-cache-dir torch>=1.7.0 torchvision --index-url https://download.pytorch.org/whl/cpu && \
    pip install --no-cache-dir -r requirements.txt

# Copiar el código de la aplicación
COPY . .

# Crear directorios necesarios
RUN mkdir -p data/recordings data/snapshots data/hls logs models data/configs

# Configurar variables de entorno
ENV PYTHONPATH=/app

# Puerto para la API
EXPOSE 8000

# Comando por defecto
CMD ["python", "-m", "src.main"]
```

### __init__.py
```py | 153 bytes | Modificado: 2025-03-05 19:19:16.234872
```
from . import agent_modules
from . import core
from . import services
from . import utils

__all__ = ['agent_modules', 'core', 'services', 'utils'] 
```

### avances.txt
```txt | 13888 bytes | Modificado: 2025-03-15 14:09:43.879719
```
SEGUIMIENTO DE AVANCES - PROYECTO vigIA
=======================================

Fecha: 2023-07-15
Hora: 10:30

AVANCE #1:
- Implementado dataset_manager.py completo con las siguientes funciones:
  * _discover_datasets: Encuentra datasets existentes
  * create_dataset: Crea estructura para nuevo dataset
  * add_sample: Añade muestra al dataset con anotaciones
  * export_dataset: Exporta en formato compatible (YOLO, COCO)
  * get_dataset_info: Obtiene información del dataset
  * delete_dataset: Elimina un dataset completo
- Estructura cumple con prácticas recomendadas de YOLO
- Soporte para exportación a diferentes formatos

Fecha: 2023-07-15
Hora: 11:15

AVANCE #2:
- Implementado model_trainer.py con integración MLflow:
  * Soporte para tracking de experimentos
  * Registro de parámetros, métricas y artefactos
  * Exportación de modelos a ONNX y TFLite
- Creado conector para cámaras Dahua (dahua.py):
  * Obtención de URLs de streaming RTSP
  * Control PTZ
  * Captura de snapshots
  * Información del dispositivo
- Ambos módulos incluyen manejo de errores y logging

Fecha: 2023-07-15
Hora: 12:00

AVANCE #3:
- Implementado sistema de eventos con Redis PubSub:
  * Publicación asíncrona de mensajes
  * Suscripción a canales con manejadores personalizados
  * Reconexión automática en caso de fallos
  * Manejo de errores y logging
- Creado esquema de base de datos con SQLAlchemy:
  * Modelos para usuarios, cámaras, alertas, zonas, etc.
  * Relaciones entre entidades
  * Timestamps automáticos con mixins
  * Helper de gestión de sesiones de base de datos
- Los módulos implementados siguen buenas prácticas:
  * Tipado estático
  * Manejo de excepciones
  * Documentación de código
  * Patrones de diseño adecuados

Fecha: 2023-07-15 
Hora: 13:00

AVANCE #4:
- Implementado archivo de configuración YAML centralizado:
  * Configuración completa del sistema
  * Soporte para variables de entorno
  * Configuración de componentes (cámaras, detección, etc.)
  * Estructura modular y escalable
- Creada API REST con FastAPI:
  * Autenticación JWT
  * Gestión de usuarios
  * Gestión de cámaras y zonas
  * Consulta de alertas
  * Estado del sistema
- Creado cargador de configuración:
  * Procesamiento de variables de entorno
  * Manejo de errores
  * Guardado de configuración
- El sistema ya cuenta con una arquitectura completa y funcional

Fecha: 2023-07-15 
Hora: 14:00

AVANCE #5:
- Implementado procesador de video:
  * Integración con YOLO para detección de objetos
  * Integración con ByteTrack para seguimiento de objetos
  * Análisis de zonas y generación de eventos
  * Análisis de comportamiento (merodeo, intrusión)
  * Visualización de resultados
- Implementada API WebSocket:
  * Transmisión de eventos en tiempo real
  * Manejo de conexiones y desconexiones
  * Integración con EventBus
  * Canales por tipo de evento
- Implementado gestor de almacenamiento:
  * Grabación automática de video
  * Captura de snapshots
  * Limpieza automática según retención
  * Monitoreo de uso de disco
- La arquitectura ahora funciona completamente en tiempo real

Fecha: 2023-07-15 
Hora: 15:00

AVANCE #6:
- Implementado script de inicialización del sistema:
  * Arranque coordinado de todos los componentes
  * Verificación y creación de datos iniciales
  * Manejo de señales para apagado graceful
  * Integración con la API y WebSockets
- Creado componente frontend para la configuración:
  * Editor de configuración general del sistema
  * Gestión de cámaras y zonas
  * Configuración de agentes de análisis
  * Interfaz intuitiva con pestañas y formularios
- Implementada configuración de Docker:
  * Dockerfile para el backend
  * Docker-compose con servicios necesarios (PostgreSQL, Redis)
  * Volúmenes para persistencia de datos
  * Nginx para servir el frontend
- El sistema está ahora listo para ser desplegado y utilizado 

Fecha: 2023-10-12
Hora: 16:30

AVANCE #7:
- Actualizaciones para compatibilidad con las últimas bibliotecas:
  * Cambiada ruta de importación en video_processor.py: 
    - De: ultralytics.yolo.utils.ops 
    - A: ultralytics.utils.ops
  * Creado archivo base.py para integración de cámaras
  * Creado archivo auth.py para autenticación en websockets
  * Instaladas dependencias adicionales:
    - email-validator para validación de correos
    - pydantic[email] para modelos más robustos
    - fastapi y dependencias relacionadas
- Cambios en estructura de directorios:
  * Creados directorios data/configs, data/recordings, data/snapshots
  * Creados directorios models y logs para almacenamiento
- Ajustes en configuración y variables de entorno:
  * Creado archivo system_config.yaml inicial
  * Configuradas variables de entorno para ejecución en modo desarrollo
- Soluciones para problemas de dependencias:
  * Comentadas temporalmente funciones de tracking (ByteTrack)
  * Ajustada configuración para inicio sin Redis en modo de prueba
- El sistema ahora puede ejecutarse en modo depuración con:
  python -m src.main --debug 

Fecha: 2023-10-12
Hora: 17:15

ACTUALIZACIÓN #7.1:
- Instaladas dependencias adicionales para autenticación y seguridad:
  * werkzeug para generación de hashes de contraseñas
  * flask-sqlalchemy para modelos de usuarios
  * psycopg2-binary para compatibilidad con PostgreSQL
- Primer inicio exitoso con inicialización de base de datos
- Creación automática de usuario administrador predeterminado
- El sistema ahora inicia correctamente en modo depuración 

Fecha: 2023-10-12
Hora: 17:45

ACTUALIZACIÓN #7.2:
- Solución para problema de conexión con Redis:
  * Modificado código para continuar en modo degradado sin Redis
  * Implementado modo de prueba que omite servicios externos
- El sistema ahora inicia correctamente sin dependencias externas
- Configuración para ejecutar en entornos limitados o de desarrollo
- Mejorada la resiliencia: el sistema puede operar con servicios no disponibles 

Fecha: 2023-10-12
Hora: 18:15

ACTUALIZACIÓN #7.3:
- Implementada solución robusta para ejecutar sin Redis:
  * Creado sistema de mock objects para simular bus de eventos
  * Manejo de excepciones mejorado para continuar sin servicios críticos
  * Implementada clase AsyncMock para simular funciones asíncronas
- El sistema ahora tiene mejor gestión de errores y tolerancia a fallos
- Probado inicio completo en entorno sin dependencias externas 

Fecha: 2023-10-12
Hora: 18:45

ACTUALIZACIÓN #7.4:
- Implementación de manejadores de eventos faltantes:
  * Añadido método handle_recording_started al StorageManager
  * Añadido método handle_recording_stopped al StorageManager
  * Mejorado el manejo de grabaciones en proceso
- Reforzado el sistema de manejo de errores:
  * Detección y recuperación de componentes faltantes
  * Simulación de componentes para pruebas (Mock objects)
- El sistema ahora detecta y reporta correctamente problemas en tiempo de ejecución
- Preparado para iniciar sin servicios de almacenamiento cuando sea necesario 

Fecha: 2023-10-12
Hora: 19:15

ACTUALIZACIÓN #7.5:
- Implementación de manejadores de eventos adicionales:
  * Añadido manejador handle_alert_generated al StorageManager
  * Implementado almacenamiento de snapshots para alertas
  * Asociación automática entre alertas y sus evidencias visuales
- Corrección de modelo de datos:
  * Añadido campo is_active a la clase Camera
  * Actualizado esquema de base de datos
- El sistema ahora puede procesar alertas correctamente
- Mejorado el flujo de eventos entre detección y almacenamiento 

Fecha: 2023-10-12
Hora: 19:45

ACTUALIZACIÓN #7.6:
- Resuelto problema de inconsistencia en la base de datos:
  * Actualizada estructura de la tabla cameras con nuevos campos
  * Recreada base de datos para aplicar todos los cambios de esquema
  * Sincronizados modelos SQLAlchemy con tablas físicas
- Mejoras en el esquema de datos:
  * Simplificación de campos de configuración de cámaras
  * Mejor organización de relaciones entre entidades
  * Campos optimizados para rendimiento en consultas frecuentes
- El sistema ahora tiene un esquema de datos sólido y coherente
- Base de datos completamente compatible con la estructura del código 

Fecha: 2023-10-12
Hora: 20:15

ACTUALIZACIÓN #7.7:
- Sistema inicializado correctamente:
  * Base de datos creada con estructura actual
  * Bus de eventos conectado a Redis
  * Gestor de almacenamiento inicializado
  * Manejador de WebSockets configurado
- Configuración de red y puertos:
  * Detección y solución de conflictos de puertos
  * Implementada configuración dinámica de puerto mediante variables de entorno
  * Mejorada gestión de conexiones a servicios
- El sistema ahora arranca completo con todos los componentes
- API REST y WebSockets listos para servir clientes
- Primera ejecución exitosa del sistema completo 

Fecha: 2023-10-12
Hora: 20:45

ACTUALIZACIÓN #7.8:
- Configuración personalizada de red:
  * Cambiado puerto predeterminado de 8000 a 8800
  * Evitado conflicto con otros servicios en el sistema
  * Mejorada configuración de binding de red
- Documentación y procedimientos:
  * Añadidas instrucciones para configuración de puertos
  * Documentado proceso de resolución de conflictos
  * Creada guía de diagnóstico de problemas de red
- El sistema ahora es más flexible y configurable
- Mejorada la experiencia de instalación y despliegue 

Fecha: 2023-10-12
Hora: 21:15

ACTUALIZACIÓN #7.9:
- Resuelto problema de configuración CORS:
  * Actualizada lógica para manejo de orígenes permitidos
  * Mejorada resiliencia ante cambios en configuración
  * Simplificada configuración de seguridad de API
- Ajustes en la estructura del archivo de configuración:
  * Eliminadas entradas obsoletas o duplicadas
  * Mejorada organización de secciones
  * Documentadas opciones disponibles
- El sistema ahora maneja mejor configuraciones incompletas o faltantes
- Mejorado soporte para despliegues en entornos diversos 

Fecha: 2023-10-12
Hora: 21:45

ACTUALIZACIÓN #7.10:
- Mejorada la experiencia de usuario en la API:
  * Añadido endpoint en ruta raíz con información básica
  * Documentados todos los endpoints disponibles
  * Propuesta de navegación por recursos del API
- Sistema completamente operativo:
  * API accesible en puerto 8800
  * Documentación interactiva disponible
  * Endpoints para gestión de cámaras y alertas
- Verificada integración completa entre componentes:
  * Base de datos y modelos
  * Sistema de eventos
  * API REST
  * WebSockets para tiempo real
- El sistema está listo para pruebas funcionales completas 

Fecha: 2023-10-12
Hora: 22:15

ACTUALIZACIÓN #7.11:
- Diagnóstico integral y corrección del sistema de autenticación:
  * Creada herramienta de diagnóstico completo
  * Corrección de hash de contraseñas en base de datos
  * Mejorado sistema de creación y actualización de usuarios
  * Implementado registro detallado de operaciones
- Solución robusta para el inicio de sesión:
  * Verificación correcta de credenciales
  * Manejo adecuado de roles y permisos
  * Tokens JWT configurados correctamente
- Documentación completa del proceso de autenticación:
  * Guía para obtener tokens mediante API
  * Explicación del flujo de autenticación
  * Procedimientos de gestión de usuarios
- Sistema completamente funcional y accesible 

Fecha: 2023-10-13
Hora: 08:30

ACTUALIZACIÓN #7.12:
- Corregido sistema de autenticación con tokens JWT:
  * Mejorado proceso de decodificación de tokens
  * Añadido registro detallado para depuración
  * Implementado manejo correcto de errores en autenticación
  * Compatibilidad con diferentes versiones de PyJWT
- Verificados endpoints protegidos de la API:
  * Estado del sistema
  * Gestión de usuarios
  * Gestión de cámaras y alertas
- Documentación actualizada para uso correcto de autenticación
- El sistema ahora funciona correctamente con todas las funciones protegidas 

Fecha: 2023-10-13
Hora: 09:15

ACTUALIZACIÓN #7.13:
- Depuración avanzada del sistema de autenticación JWT:
  * Implementado endpoint de diagnóstico de tokens
  * Corregida inconsistencia de tipo en ID de usuario (sub)
  * Mejorado manejo de errores con mensajes detallados
  * Logs detallados para seguimiento de autenticación
- Documentación actualizada para diagnóstico de problemas:
  * Instrucciones para verificar tokens
  * Guía para detectar problemas de autenticación
  * Ejemplos de uso correcto de la API
- Implementado sistema de recuperación automática:
  * Detección y manejo de tokens mal formados
  * Compatibilidad con diferentes versiones del cliente
- El sistema ahora es robusto ante problemas de autenticación 

Fecha: 2023-10-13
Hora: 10:00

ACTUALIZACIÓN #7.14:
- Correcciones para compatibilidad con clientes diversos:
  * Mejorado manejo de datos en formato JSON y formulario
  * Adaptación de rutas para acceso más intuitivo
  * Implementada documentación en español para API
  * Guía detallada para uso desde diferentes plataformas
- Script de prueba PowerShell completo y funcional:
  * Verificación paso a paso de todos los componentes
  * Identificación clara de éxitos y errores
  * Creación automática de usuarios de prueba
  * Demostración de todas las funcionalidades principales
- Mejoras de usabilidad para administradores:
  * Endpoints más descriptivos
  * Mensajes de error detallados y específicos
  * Registros mejorados para diagnóstico
- Sistema completamente funcional y probado 
```

### config.yaml
```yaml | 1414 bytes | Modificado: 2025-03-13 21:46:25.871082
```
# Crear un archivo config.yaml más completo
@"
# Configuración del Sistema vigIA
# ------------------------------

# Configuración general del sistema
system:
  name: "vigIA"
  version: "1.0.0"
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  timezone: "America/Argentina/Buenos_Aires"
  temp_dir: "/tmp/vigia"
  enable_debug: false
  
# Configuración de base de datos
database:
  type: "postgresql"
  host: "db"
  port: 5432
  database: "vigia"
  username: "vigia"
  password: "vigia"
  pool_size: 10
  max_connections: 20
  ssl_mode: "prefer"
  
# Configuración de Redis para eventos
redis:
  host: "redis"
  port: 6379
  db: 0
  password: null
  use_ssl: false
  retry_on_timeout: true
  
# Configuración de almacenamiento
storage:
  recordings_dir: "/app/data/recordings"
  max_disk_usage_percent: 90
  retention_days: 30
  auto_clean: true
  snapshots_dir: "/app/data/snapshots"
  models_dir: "/app/models"
  
# Configuración de API
api:
  host: "0.0.0.0"
  port: 8000
  enable_cors: true
  cors_origins: ["*"]
  jwt_expiration: 86400  # 24 horas en segundos
  
# Configuración de detección y análisis
detection:
  default_model: "yolov8n.pt"
  confidence_threshold: 0.25
  iou_threshold: 0.45
  max_detections: 100
  enable_gpu: true
  gpu_id: 0
  batch_size: 1
"@ | Out-File -FilePath "configs\config.yaml" -Encoding ascii
```

### docker-compose.yml
```yml | 917 bytes | Modificado: 2025-03-14 11:11:58.858947
```
version: '3.8'

services:
  app:
    build: .
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./configs:/app/configs
      - ./logs:/app/logs
      - ./models:/app/models
    environment:
      - DATABASE_URL=postgresql://vigia:vigia@db:5432/vigia
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - JWT_SECRET=supersecretkey_change_this_in_production
    depends_on:
      - db
      - redis

  db:
    image: postgres:13
    restart: unless-stopped
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=vigia
      - POSTGRES_PASSWORD=vigia
      - POSTGRES_DB=vigia
    ports:
      - "5432:5432"

  redis:
    image: redis:6
    restart: unless-stopped
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"

volumes:
  postgres_data:
  redis_data:
```

### documentar_proyecto.py
```py | 4148 bytes | Modificado: 2025-03-16 09:17:08.741822
```
#!/usr/bin/env python
"""
Script para documentar la estructura y contenido del proyecto vigIA
"""

import os
import datetime
import fnmatch

# Configuración
proyecto_dir = "E:/IA/motion_detector_clean"  # Ajusta esta ruta
archivo_salida = "vigia_proyecto_completo.txt"
ignorar_directorios = ["venv", "__pycache__", "node_modules", ".git", ".idea", ".vscode", "logs", "ByteTrack"]
ignorar_extensiones = [".pyc", ".pyo", ".so", ".dll", ".exe", ".bin", ".dat", ".db", ".jpg", ".jpeg", ".png", ".gif", ".mp4", ".avi"]
max_tamano_archivo = 1 * 1024 * 1024  # 1MB en bytes

# Inicializar estadísticas
archivos_procesados = 0
archivos_ignorados = 0
tamano_total = 0

# Crear o sobrescribir el archivo de salida
with open(archivo_salida, 'w', encoding='utf-8') as f:
    f.write("# PROYECTO vigIA - DOCUMENTACIÓN COMPLETA\n")
    f.write(f"# Generado el {datetime.datetime.now()}\n\n")
    
    # Estructura de directorios
    f.write("## ESTRUCTURA DE DIRECTORIOS\n\n```\n")
    
    def obtener_arbol_directorios(ruta, indentacion="", ignorar=None):
        elementos = sorted(os.listdir(ruta))
        for elemento in elementos:
            ruta_completa = os.path.join(ruta, elemento)
            if os.path.isdir(ruta_completa):
                if elemento in ignorar:
                    continue
                f.write(f"{indentacion}{elemento}/\n")
                obtener_arbol_directorios(ruta_completa, indentacion + "    ", ignorar)
            else:
                f.write(f"{indentacion}{elemento}\n")
    
    obtener_arbol_directorios(proyecto_dir, "", ignorar_directorios)
    f.write("```\n\n")
    
    # Contenido de archivos
    f.write("## CONTENIDO DE ARCHIVOS\n\n")
    
    for raiz, dirs, archivos in os.walk(proyecto_dir):
        # Filtrar directorios ignorados
        dirs[:] = [d for d in dirs if d not in ignorar_directorios]
        
        for archivo in sorted(archivos):
            ruta_completa = os.path.join(raiz, archivo)
            
            # Verificar si debemos ignorar este archivo
            ignorar = False
            
            # Verificar extensión
            _, extension = os.path.splitext(archivo)
            if extension.lower() in ignorar_extensiones:
                ignorar = True
            
            # Verificar tamaño
            tamano = os.path.getsize(ruta_completa)
            if tamano > max_tamano_archivo:
                ignorar = True
                
            if ignorar:
                archivos_ignorados += 1
                continue
                
            # Obtener ruta relativa
            ruta_relativa = os.path.relpath(ruta_completa, proyecto_dir)
            
            # Escribir información del archivo
            f.write(f"### {ruta_relativa}\n")
            f.write(f"```{extension[1:]} | {tamano} bytes | Modificado: {datetime.datetime.fromtimestamp(os.path.getmtime(ruta_completa))}\n")
            f.write("```\n")
            
            # Escribir contenido del archivo
            try:
                with open(ruta_completa, 'r', encoding='utf-8', errors='replace') as archivo_contenido:
                    contenido = archivo_contenido.read()
                    f.write(contenido)
            except Exception as e:
                f.write(f"ERROR: No se pudo leer el archivo: {str(e)}")
                
            f.write("\n```\n\n")
            
            archivos_procesados += 1
            tamano_total += tamano
    
    # Resumen
    f.write("## RESUMEN DE LA DOCUMENTACIÓN\n\n")
    f.write(f"- Archivos procesados: {archivos_procesados}\n")
    f.write(f"- Archivos ignorados: {archivos_ignorados}\n")
    f.write(f"- Tamaño total de archivos incluidos: {tamano_total / 1024:.2f} KB\n\n")
    f.write("Documentación generada con el script de documentación automática de vigIA.\n")

print(f"Documentación completa guardada en: {archivo_salida}")
print(f"Archivos procesados: {archivos_procesados}")
print(f"Archivos ignorados: {archivos_ignorados}")
print(f"Tamaño total: {tamano_total / 1024:.2f} KB")
```

### main.py
```py | 757 bytes | Modificado: 2025-03-05 13:50:24.348797
```
import asyncio
from pathlib import Path
from src.core.master_control.system_controller import SystemController
import signal
import sys

async def main():
    # Cargar configuración
    config_path = Path("data/configs/system_config.yaml")
    
    # Inicializar controlador
    controller = SystemController(config_path)
    
    # Manejar señales de terminación
    def signal_handler(sig, frame):
        print("\nDeteniendo sistema...")
        asyncio.create_task(controller.shutdown())
        sys.exit(0)
        
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # Iniciar sistema
    await controller.start()

if __name__ == "__main__":
    asyncio.run(main()) 
```

### requirements.txt
```txt | 517 bytes | Modificado: 2025-03-14 17:07:27.386709
```
# API y Web
fastapi==0.95.0
uvicorn==0.21.1
sqlalchemy==2.0.7
pydantic==1.10.7
python-dotenv==1.0.0
pyjwt==2.6.0
jinja2==3.1.2

# Base de datos
psycopg2-binary==2.9.5
redis==4.5.4
alembic==1.10.2

# Computer Vision
opencv-python==4.7.0.72
ultralytics==8.0.6
torch>=1.7.0
torchvision>=0.8.1
numpy==1.24.2
pillow==9.4.0

# Procesamiento
scikit-learn==1.2.2
scipy==1.10.1
matplotlib==3.7.1
pandas==1.5.3

# Utilidades
pyyaml==6.0
python-multipart==0.0.6
tenacity==8.2.2
aiofiles==23.1.0

```

### configs\config.yaml
```yaml | 4784 bytes | Modificado: 2025-03-15 10:20:12.448887
```
# Configuración del Sistema vigIA
# ------------------------------

# Configuración general del sistema
system:
  name: "vigIA"
  version: "1.0.0"
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  timezone: "America/Mexico_City"
  temp_dir: "/tmp/vigia"
  enable_debug: false
  
# Configuración de base de datos
database:
  type: "postgresql"  # postgresql, mysql, sqlite
  host: "localhost"
  port: 5432
  database: "vigia"
  username: "${DB_USER}"  # Se carga desde variable de entorno
  password: "${DB_PASSWORD}"  # Se carga desde variable de entorno
  pool_size: 10
  max_connections: 20
  ssl_mode: "prefer"

# Configuración de Redis para eventos
redis:
  host: "localhost"
  port: 6379
  db: 0
  password: null
  use_ssl: false
  retry_on_timeout: true
  
# Configuración de MLflow para tracking de experimentos
mlflow:
  tracking_uri: "mlruns"
  experiment_name: "vigia_model_training"
  registry_uri: "sqlite:///mlflow.db"
  
# Configuración de almacenamiento
storage:
  recordings_dir: "data/recordings"
  max_disk_usage_percent: 90
  retention_days: 30  # Días de retención para grabaciones
  auto_clean: true
  snapshots_dir: "data/snapshots"
  models_dir: "models"
  
# Configuración de API
api:
  host: "0.0.0.0"
  port: 8800
  debug: true
  cors_origins: ["*"]
  api_key_header: "X-API-Key"
  enable_rate_limiting: true
  rate_limit: 100  # Peticiones por minuto
  jwt_secret: "${JWT_SECRET}"  # Se carga desde variable de entorno
  jwt_expiration: 86400  # 24 horas en segundos
  
# Configuración de servidores de streaming
streaming:
  enable_rtsp: true
  rtsp_port: 8554
  enable_rtmp: false
  rtmp_port: 1935
  enable_hls: true
  hls_segment_duration: 4
  hls_dir: "data/hls"
  
# Configuración de detección y análisis
detection:
  default_model: "yolov8n.pt"
  confidence_threshold: 0.25
  iou_threshold: 0.45
  max_detections: 100
  enable_gpu: true
  gpu_id: 0
  batch_size: 1
  
# Configuración de tracking
tracking:
  algorithm: "bytetrack"  # bytetrack, deepsort, etc.
  max_age: 30  # Frames
  min_hits: 3
  iou_threshold: 0.3
  
# Configuración de análisis de comportamiento
behavior:
  enable_zone_intrusion: true
  enable_loitering: true
  enable_line_crossing: true
  enable_object_counting: true
  loitering_time_threshold: 10  # Segundos
  
# Configuración de notificaciones
notifications:
  enable_email: false
  smtp_server: "smtp.example.com"
  smtp_port: 587
  smtp_user: "${SMTP_USER}"
  smtp_password: "${SMTP_PASSWORD}"
  sender_email: "alerts@vigia.com"
  enable_sms: false
  enable_webhooks: true
  webhook_urls: ["https://webhook.example.com/vigia"]
  
# Configuración de cámaras (lista de cámaras)
cameras:
  - id: "cam_1"
    name: "Entrada Principal"
    enabled: true
    vendor: "hikvision"
    url: "rtsp://admin:password@192.168.1.100:554/Streaming/Channels/101"
    username: "admin"
    password: "${CAM1_PASSWORD}"
    fps: 15
    resolution: "1280x720"
    recording:
      enabled: true
      mode: "motion"  # continuous, motion, schedule
      pre_record: 5  # Segundos antes del evento
      post_record: 10  # Segundos después del evento
    zones:
      - name: "Entrada"
        type: "intrusion"
        points: [[100, 100], [300, 100], [300, 300], [100, 300]]
        color: "red"
      - name: "Línea de cruce"
        type: "line"
        points: [[400, 0], [400, 720]]
        direction: "left-to-right"
        color: "yellow"
        
  - id: "cam_2"
    name: "Estacionamiento"
    enabled: true
    vendor: "dahua"
    url: "rtsp://admin:password@192.168.1.101:554/cam/realmonitor?channel=1&subtype=0"
    username: "admin"
    password: "${CAM2_PASSWORD}"
    fps: 10
    resolution: "1920x1080"
    recording:
      enabled: true
      mode: "continuous"
      schedule:
        - days: ["mon", "tue", "wed", "thu", "fri"]
          periods: [["08:00", "18:00"]]
        - days: ["sat", "sun"]
          periods: [["10:00", "15:00"]]
    zones:
      - name: "Zona de vehículos"
        type: "intrusion"
        points: [[500, 500], [1500, 500], [1500, 1000], [500, 1000]]
        color: "blue"
        
# Configuración de agentes de análisis
agents:
  motion_detection:
    enabled: true
    sensitivity: 0.3
    min_area: 500
    history: 120
    
  face_recognition:
    enabled: false
    model: "face_recognition_v1"
    min_face_size: 30
    recognition_threshold: 0.6
    
  license_plate:
    enabled: false
    region: "mx"  # Región para optimizar reconocimiento
    confidence_threshold: 0.7
    
  crowd_analysis:
    enabled: false
    max_density_level: 3
    count_threshold: 10 
```

### data\configs\system_config.yaml
```yaml | 1021 bytes | Modificado: 2025-03-14 11:11:22.227279
```
# Configuración del Sistema vigIA
system:
  name: "vigIA"
  version: "1.0.0"
  log_level: "INFO"

logging:
  log_dir: "logs"
  log_level: "INFO"
  max_size_mb: 10
  backup_count: 5

database:
  url: "postgresql://vigia:vigia@db:5432/vigia"
  pool_size: 10
  max_overflow: 20

redis:
  host: "redis"
  port: 6379
  db: 0
  
cameras:
  cam_1:
    name: "Cámara Principal"
    url: "test_video.mp4"
    enabled: true
    detection:
      enabled: true
      confidence_threshold: 0.5
      classes: ["person", "car", "truck"]
    recording:
      enabled: true
      storage_path: "data/recordings"

access_points:
  point_1:
    name: "Entrada Principal"
    enabled: true
    
alerts:
  email:
    enabled: true
    smtp_server: "smtp.gmail.com"
    smtp_port: 587
    smtp_user: "alertas@ejemplo.com"
    smtp_pass: "password"
    recipients: ["admin@ejemplo.com"]
  
  sms:
    enabled: false
    
visitors:
  check_in_enabled: true
  storage_path: "data/visitors"
```

### docs\guia_usuario.md
```md | 12473 bytes | Modificado: 2025-03-13 20:42:07.280388
```
# Guía de Usuario - Sistema vigIA

## Índice
1. [Introducción](#introducción)
2. [Requisitos del Sistema](#requisitos-del-sistema)
3. [Instalación](#instalación)
4. [Configuración Inicial](#configuración-inicial)
5. [Acceso al Sistema](#acceso-al-sistema)
6. [Panel de Control](#panel-de-control)
7. [Gestión de Cámaras](#gestión-de-cámaras)
8. [Configuración de Zonas](#configuración-de-zonas)
9. [Alertas y Notificaciones](#alertas-y-notificaciones)
10. [Analítica de Video](#analítica-de-video)
11. [Entrenamiento de Modelos](#entrenamiento-de-modelos)
12. [Visualización en Tiempo Real](#visualización-en-tiempo-real)
13. [Grabaciones y Almacenamiento](#grabaciones-y-almacenamiento)
14. [Solución de Problemas](#solución-de-problemas)
15. [Preguntas Frecuentes](#preguntas-frecuentes)

## Introducción

vigIA es un sistema de videovigilancia inteligente que integra tecnologías de visión por computadora y aprendizaje automático para proporcionar capacidades avanzadas de detección y análisis. El sistema permite:

- Detección y seguimiento de objetos en tiempo real
- Análisis de comportamiento y patrones
- Generación automática de alertas
- Grabación inteligente basada en eventos
- Administración centralizada de múltiples cámaras
- Visualización en tiempo real y reproducción de grabaciones
- Entrenamiento de modelos personalizados

Esta guía le ayudará a instalar, configurar y utilizar todas las funcionalidades del sistema vigIA.

## Requisitos del Sistema

### Hardware Recomendado
- **CPU**: Intel Core i7 o superior (o equivalente AMD)
- **RAM**: 16GB mínimo, 32GB recomendado
- **GPU**: NVIDIA con soporte CUDA (GTX 1660 o superior)
- **Almacenamiento**: SSD de 250GB para el sistema, discos adicionales para grabaciones
- **Red**: Gigabit Ethernet

### Software Requerido
- Docker y Docker Compose
- Navegador web moderno (Chrome, Firefox, Edge)
- Cámaras compatibles con protocolos RTSP o ONVIF

## Instalación

vigIA se distribuye como un conjunto de contenedores Docker, lo que facilita su instalación en cualquier sistema compatible.

### Utilizando Docker Compose

1. Clone el repositorio de vigIA:
   ```bash
   git clone https://github.com/vigia/vigia-system.git
   cd vigia-system
   ```

2. Configure las variables de entorno (opcional):
   ```bash
   cp .env.example .env
   # Edite el archivo .env según sus necesidades
   ```

3. Inicie los servicios con Docker Compose:
   ```bash
   docker-compose up -d
   ```

4. Verifique que todos los servicios están en funcionamiento:
   ```bash
   docker-compose ps
   ```

### Instalación Manual

Para entornos sin Docker, consulte el archivo `docs/instalacion_manual.md`.

## Configuración Inicial

Después de la instalación, es necesario realizar la configuración inicial del sistema.

### Primer Acceso

1. Abra un navegador web y visite `http://localhost:80` (o la dirección IP del servidor donde instaló vigIA)
2. Inicie sesión con las credenciales predeterminadas:
   - Usuario: `admin`
   - Contraseña: `admin123`
3. Se le solicitará cambiar la contraseña inmediatamente

### Configuración Básica del Sistema

1. En el menú principal, vaya a **Configuración → Sistema**
2. Configure los parámetros generales:
   - Nombre del sistema
   - Zona horaria
   - Directorio de almacenamiento
   - Política de retención de grabaciones
3. Guarde los cambios haciendo clic en **Guardar Configuración**

## Acceso al Sistema

vigIA proporciona diferentes formas de acceso según las necesidades del usuario.

### Interfaz Web

La interfaz web es la forma principal de interactuar con el sistema:

1. Abra un navegador web y acceda a `http://[dirección-ip-del-servidor]:80`
2. Inicie sesión con sus credenciales
3. Se mostrará el panel de control principal

### API REST

Para integración con otros sistemas, vigIA proporciona una API REST completa:

1. La documentación de la API está disponible en `http://[dirección-ip-del-servidor]:8000/docs`
2. La autenticación se realiza mediante tokens JWT

### Acceso Móvil

La interfaz web es responsiva y se adapta a dispositivos móviles, pero para una mejor experiencia:

1. Descargue la aplicación móvil desde Google Play o App Store (si está disponible)
2. Configure la conexión al servidor vigIA
3. Inicie sesión con sus credenciales

## Panel de Control

El panel de control proporciona una visión general del sistema y acceso rápido a todas las funcionalidades.

### Elementos Principales

- **Vista General**: Muestra estadísticas y estado del sistema
- **Vista de Cámaras**: Visualización en vivo de todas las cámaras
- **Alertas Recientes**: Últimas alertas generadas por el sistema
- **Estado del Sistema**: Información sobre recursos y componentes

### Personalización

1. Para personalizar el panel, haga clic en **Personalizar**
2. Arrastre y suelte los widgets según sus preferencias
3. Configure cada widget según sus necesidades
4. Guarde la configuración

## Gestión de Cámaras

La gestión eficaz de cámaras es fundamental para sacar el máximo provecho de vigIA.

### Agregar una Nueva Cámara

1. Vaya a **Configuración → Cámaras**
2. Haga clic en **Agregar Cámara**
3. Complete el formulario con la información de la cámara:
   - Nombre descriptivo
   - Dirección IP
   - Modelo/fabricante
   - URL de streaming (RTSP u ONVIF)
   - Credenciales de acceso
4. Seleccione el modo de grabación:
   - Continua
   - Basada en movimiento
   - Programada
5. Haga clic en **Guardar**

### Configuración Avanzada de Cámaras

Para cada cámara, puede configurar parámetros avanzados:

1. Seleccione la cámara y haga clic en **Configuración Avanzada**
2. Configure:
   - Resolución y FPS
   - Filtros de calidad
   - Rotación y transformación
   - Parámetros de compresión

### Prueba de Conectividad

1. Seleccione la cámara y haga clic en **Probar Conexión**
2. El sistema verificará:
   - Accesibilidad
   - Autenticación
   - Calidad del streaming

## Configuración de Zonas

Las zonas permiten definir áreas de interés específicas dentro del campo visual de las cámaras.

### Crear una Nueva Zona

1. Vaya a **Configuración → Cámaras**
2. Seleccione la cámara deseada
3. Haga clic en **Zonas**
4. Seleccione **Nueva Zona**
5. Dibuje el polígono que define la zona sobre la imagen de la cámara
6. Configure las propiedades de la zona:
   - Nombre descriptivo
   - Tipo (intrusión, línea de cruce, área de conteo)
   - Color de visualización
   - Comportamientos a detectar
7. Guarde la configuración

### Tipos de Zonas

- **Zona de Intrusión**: Detecta objetos que ingresan al área definida
- **Línea de Cruce**: Detecta objetos que cruzan una línea virtual
- **Área de Conteo**: Cuenta objetos dentro de un área definida
- **Zona de Permanencia**: Detecta objetos que permanecen por tiempo prolongado

## Alertas y Notificaciones

vigIA ofrece un sistema flexible de alertas basado en los eventos detectados.

### Configuración de Alertas

1. Vaya a **Configuración → Alertas**
2. Haga clic en **Nueva Regla de Alerta**
3. Configure los criterios de activación:
   - Tipo de evento (intrusión, cruce de línea, etc.)
   - Cámara y zona específica
   - Clase de objeto (persona, vehículo, etc.)
   - Horario de activación
4. Configure las acciones a realizar:
   - Notificación en el sistema
   - Correo electrónico
   - Webhook
   - SMS (si está configurado)
5. Guarde la configuración

### Gestión de Alertas

1. Vaya a **Alertas** en el menú principal
2. Visualice todas las alertas generadas
3. Filtre por fecha, cámara o tipo
4. Marque las alertas como revisadas
5. Agregue comentarios a cada alerta

## Analítica de Video

La analítica de video es el núcleo de vigIA, proporcionando detección y análisis inteligente.

### Configuración de Analíticas

1. Vaya a **Configuración → Analíticas**
2. Configure los agentes de analítica:
   - Detector de objetos (seleccione modelo)
   - Seguimiento de objetos (seleccione algoritmo)
   - Análisis de comportamiento

### Analíticas Disponibles

- **Detección de Objetos**: Identifica y clasifica objetos (personas, vehículos, etc.)
- **Seguimiento**: Mantiene la identidad de los objetos a través de múltiples frames
- **Análisis de Comportamiento**:
  - Detección de merodeo
  - Análisis de multitudes
  - Abandono/retiro de objetos
  - Velocidad de movimiento

## Entrenamiento de Modelos

vigIA permite entrenar modelos personalizados para mejorar la precisión en su entorno específico.

### Creación de Datasets

1. Vaya a **Modelos → Datasets**
2. Haga clic en **Nuevo Dataset**
3. Seleccione el método de creación:
   - Desde grabaciones existentes
   - Subida manual de imágenes
   - Captura desde cámaras en vivo
4. Etiquete las imágenes:
   - Manualmente
   - Con asistencia de IA

### Entrenamiento de Modelo

1. Vaya a **Modelos → Entrenamiento**
2. Seleccione **Nuevo Entrenamiento**
3. Configure los parámetros:
   - Dataset a utilizar
   - Modelo base
   - Clases a detectar
   - Hiperparámetros
4. Inicie el entrenamiento
5. Monitorice el progreso y métricas

### Despliegue de Modelo

1. Una vez finalizado el entrenamiento, vaya a **Modelos → Despliegue**
2. Seleccione el modelo entrenado
3. Asigne el modelo a cámaras específicas
4. Active el nuevo modelo

## Visualización en Tiempo Real

vigIA ofrece potentes herramientas de visualización en tiempo real.

### Vista de Múltiples Cámaras

1. Vaya a **Monitoreo → Vista en Vivo**
2. Seleccione la disposición de visualización (2x2, 3x3, etc.)
3. Arrastre las cámaras deseadas a cada panel
4. Utilice los controles para:
   - Zoom digital
   - Control PTZ (si la cámara lo soporta)
   - Captura de instantáneas

### Visualización Avanzada

- **Overlays**: Muestra información en tiempo real sobre los objetos detectados
- **Trayectorias**: Visualiza el movimiento de objetos
- **Mapa de Calor**: Muestra áreas de mayor actividad
- **Contadores**: Visualiza conteos en tiempo real

## Grabaciones y Almacenamiento

vigIA gestiona eficientemente el almacenamiento de grabaciones.

### Búsqueda de Grabaciones

1. Vaya a **Grabaciones → Búsqueda**
2. Filtre por:
   - Cámara
   - Fecha y hora
   - Eventos detectados
   - Objetos específicos
3. Visualice los resultados en la línea de tiempo

### Reproducción

1. Seleccione la grabación deseada
2. Utilice los controles de reproducción:
   - Reproducir/Pausar
   - Avance rápido/lento
   - Salto a evento
3. Exporte segmentos específicos

### Gestión de Almacenamiento

1. Vaya a **Configuración → Almacenamiento**
2. Configure:
   - Política de retención
   - Límites de espacio
   - Limpieza automática
   - Ubicaciones de almacenamiento

## Solución de Problemas

### Diagnóstico del Sistema

1. Vaya a **Sistema → Diagnóstico**
2. Verifique:
   - Estado de componentes
   - Uso de recursos
   - Conectividad de cámaras
   - Logs del sistema

### Problemas Comunes

#### Cámara no conecta
- Verifique la URL de streaming
- Confirme credenciales
- Verifique conectividad de red

#### Rendimiento lento
- Revise uso de CPU/GPU
- Ajuste resolución de cámaras
- Verifique carga de red

#### Alertas no se generan
- Revise configuración de zonas
- Verifique modelo de detección
- Compruebe reglas de alertas

## Preguntas Frecuentes

### ¿Cuántas cámaras puede gestionar el sistema?
El número depende del hardware. Una configuración recomendada puede manejar entre 16-32 cámaras a 1080p.

### ¿Es compatible con mis cámaras existentes?
vigIA es compatible con cualquier cámara que soporte RTSP, ONVIF o HTTP.

### ¿Necesito una GPU para ejecutar el sistema?
Para un rendimiento óptimo, se recomienda una GPU NVIDIA con soporte CUDA, pero el sistema puede funcionar con CPU para cargas ligeras.

### ¿Cómo puedo ampliar el almacenamiento?
Puede añadir discos adicionales y configurarlos en la sección de Almacenamiento.

### ¿Puedo acceder al sistema desde Internet?
Sí, aunque se recomienda hacerlo mediante una VPN por seguridad. 
```

### src\main.py
```py | 11839 bytes | Modificado: 2025-03-15 10:54:04.772610
```
import os
import sys
import asyncio
import logging
import uvicorn
import argparse
from datetime import datetime
from pathlib import Path

# Configuración de logging antes de importar el resto de módulos
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f"logs/vigia_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    ]
)

logger = logging.getLogger("vigIA")

# Importar componentes del sistema
from src.config.config_loader import load_config
from src.database.db import init_db, get_db
from src.database.models import Camera, User, Role, Permission
from src.events.event_bus import EventBus
from src.processing.video_processor import VideoProcessor
from src.storage.storage_manager import StorageManager
from src.api.websocket import manager as ws_manager, WebSocketEventHandler
from src.api.api import app

class AsyncMock:
    """Un objeto simulado simple para funciones asíncronas"""
    async def __call__(self, *args, **kwargs):
        return None

class VigIASystem:
    """Sistema principal de vigIA que coordina todos los componentes"""
    
    def __init__(self, config_path="configs/config.yaml"):
        """Inicializa el sistema con la configuración especificada"""
        self.logger = logging.getLogger("VigIASystem")
        self.config_path = config_path
        self.config = None
        self.event_bus = None
        self.storage_manager = None
        self.ws_handler = None
        self.video_processors = {}
        self.is_running = False
        
        # Crear directorios necesarios
        os.makedirs("logs", exist_ok=True)
        
    async def initialize(self):
        """Inicializa todos los componentes del sistema"""
        try:
            # Cargar configuración
            self.logger.info("Cargando configuración...")
            self.config = load_config(self.config_path)
            
            # Configurar nivel de logging según configuración
            root_logger = logging.getLogger()
            root_logger.setLevel(getattr(logging, self.config["system"]["log_level"]))
            
            # Inicializar base de datos
            self.logger.info("Inicializando base de datos...")
            init_db()
            
            # Verificar datos iniciales
            await self._check_initial_data()
            
            # Inicializar bus de eventos
            self.logger.info("Inicializando bus de eventos...")
            try:
                self.event_bus = EventBus(
                    redis_host=self.config["redis"]["host"],
                    redis_port=self.config["redis"]["port"],
                    redis_db=self.config["redis"]["db"],
                    redis_password=self.config["redis"]["password"],
                )
                
                # Intenta conectar a Redis
                event_bus_connected = await self.event_bus.connect()
                if not event_bus_connected:
                    self.logger.warning("No se pudo conectar al bus de eventos. Continuando en modo limitado...")
                    # Seguir ejecutando aunque Redis no esté disponible
                else:
                    self.logger.info("Bus de eventos inicializado")
            except Exception as e:
                self.logger.warning(f"Error con el bus de eventos: {e}. Continuando en modo limitado...")
                # Crear un bus de eventos simulado para no romper el código que lo usa
                from unittest.mock import MagicMock
                self.event_bus = MagicMock()
                self.event_bus.publish = AsyncMock()
                self.event_bus.subscribe = AsyncMock()
            
            # Iniciar listener de eventos
            await self.event_bus.start_listener()
            
            # Inicializar gestor de almacenamiento
            self.logger.info("Inicializando gestor de almacenamiento...")
            self.storage_manager = StorageManager(self.config_path, self.event_bus)
            await self.storage_manager.initialize()
            self.logger.info("Gestor de almacenamiento inicializado")
            
            # Inicializar procesadores de video
            self.logger.info("Inicializando procesadores de video...")
            with get_db() as db:
                cameras = db.query(Camera).all()
                self.logger.info(f"Encontradas {len(cameras)} cámaras")
                
                for camera in cameras:
                    self.logger.info(f"Inicializando procesador para cámara {camera.id} ({camera.name})")
                    processor = VideoProcessor(camera.id, self.config_path, self.event_bus)
                    if await processor.initialize():
                        self.video_processors[camera.id] = processor
                    else:
                        self.logger.error(f"Error inicializando procesador para cámara {camera.id}")
            
            # Inicializar handler de WebSockets
            self.logger.info("Inicializando manejador de WebSockets...")
            self.ws_handler = WebSocketEventHandler(self.event_bus, ws_manager)
            await self.ws_handler.initialize()
            
            self.logger.info("Sistema vigIA inicializado correctamente")
            return True
            
        except Exception as e:
            self.logger.error(f"Error inicializando el sistema: {e}", exc_info=True)
            return False
    
    async def _check_initial_data(self):
        """Verificar y crear datos iniciales si no existen"""
        try:
            # Crear rol de administrador si no existe
            with get_db() as db:
                admin_role = db.query(Role).filter(Role.name == "admin").first()
                if not admin_role:
                    self.logger.info("Creando rol de administrador...")
                    admin_role = Role(
                        name="admin",
                        description="Administrador del sistema"
                    )
                    db.add(admin_role)
                    db.commit()
                    db.refresh(admin_role)
                    self.logger.info(f"Rol de administrador creado con ID: {admin_role.id}")
                
                # Crear usuario administrador si no existe
                admin = db.query(User).filter(User.username == "admin").first()
                if not admin:
                    self.logger.info("Creando usuario administrador por defecto...")
                    from werkzeug.security import generate_password_hash
                    
                    admin = User(
                        username="admin",
                        email="admin@vigia.local",
                        password_hash=generate_password_hash("admin123"),
                        first_name="Admin",
                        last_name="User",
                        role_id=admin_role.id,
                        is_active=True
                    )
                    db.add(admin)
                    db.commit()
                    self.logger.info(f"Usuario administrador creado: admin / admin123")
                elif admin and not admin.is_active:
                    admin.is_active = True
                    db.commit()
                    self.logger.info("Usuario administrador reactivado")
        except Exception as e:
            self.logger.error(f"Error inicializando datos: {e}")
            raise
    
    async def start(self):
        """Inicia la ejecución de todos los componentes del sistema"""
        if not await self.initialize():
            self.logger.error("Error inicializando el sistema, no se puede iniciar")
            return False
        
        self.is_running = True
        
        # Iniciar procesadores de video
        self.logger.info("Iniciando procesadores de video...")
        for camera_id, processor in self.video_processors.items():
            if not await processor.start():
                self.logger.error(f"Error iniciando procesador para cámara {camera_id}")
        
        # Publicar evento de inicio del sistema
        await self.event_bus.publish("system_started", {
            "version": self.config["system"]["version"],
            "cameras_active": len(self.video_processors),
            "timestamp": datetime.now().isoformat()
        })
        
        self.logger.info("Sistema vigIA en ejecución")
        return True
    
    async def stop(self):
        """Detiene todos los componentes del sistema de manera ordenada"""
        self.logger.info("Deteniendo sistema vigIA...")
        self.is_running = False
        
        # Detener procesadores de video
        for camera_id, processor in self.video_processors.items():
            await processor.stop()
        
        # Detener gestor de almacenamiento
        if self.storage_manager:
            await self.storage_manager.close()
        
        # Detener manejador de WebSockets
        if self.ws_handler:
            await self.ws_handler.close()
        
        # Detener bus de eventos
        if self.event_bus:
            await self.event_bus.close()
        
        self.logger.info("Sistema vigIA detenido")

async def main(config_path, args):
    """Función principal para iniciar el sistema"""
    # Crear e inicializar el sistema
    system = VigIASystem(config_path)
    
    # Iniciar el sistema
    if not await system.start():
        logger.error("Error iniciando el sistema")
        return 1
    
    # Configurar la API
    app.state.system = system
    app.state.event_bus = system.event_bus
    
    # Servir la API con Uvicorn
    config = uvicorn.Config(
        app=app,
        host=system.config["api"]["host"],
        port=system.config["api"]["port"],
        log_level=system.config["system"]["log_level"].lower(),
        reload=args.debug,
        workers=1  # Usar un solo worker debido a la naturaleza asíncrona
    )
    server = uvicorn.Server(config)
    
    # Manejar señales para apagado graceful
    import signal
    
    def signal_handler():
        """Manejador de señales para apagado graceful"""
        logger.info("Recibida señal de terminación")
        asyncio.create_task(system.stop())
    
    # Registrar manejadores de señales
    for sig in (signal.SIGINT, signal.SIGTERM):
        signal.signal(sig, lambda sig, frame: signal_handler())
    
    # Iniciar el servidor
    await server.serve()
    
    # Asegurar apagado completo
    await system.stop()
    return 0

if __name__ == "__main__":
    # Crear parser de argumentos
    parser = argparse.ArgumentParser(description="Sistema de Videovigilancia Inteligente vigIA")
    parser.add_argument("--config", type=str, default="configs/config.yaml", help="Ruta al archivo de configuración")
    parser.add_argument("--debug", action="store_true", help="Habilitar modo debug con recarga automática")
    args = parser.parse_args()
    
    # Verificar existencia del archivo de configuración
    if not os.path.exists(args.config):
        logger.error(f"Archivo de configuración no encontrado: {args.config}")
        sys.exit(1)
    
    # Ejecutar la función principal
    try:
        exit_code = asyncio.run(main(args.config, args))
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("Ejecución interrumpida por el usuario")
        sys.exit(0)
    except Exception as e:
        logger.error(f"Error inesperado: {e}", exc_info=True)
        sys.exit(1) 
```

### src\agent_modules\__init__.py
```py | 156 bytes | Modificado: 2025-03-05 19:19:16.234872
```
from .base import BaseAgent, AgentConfig
from .video_analytics import VideoAnalyticsAgent

__all__ = ['BaseAgent', 'AgentConfig', 'VideoAnalyticsAgent'] 
```

### src\agent_modules\base_agent.py
```py | 514 bytes | Modificado: 2025-03-05 13:19:26.395724
```
class SecurityAgent:
    def __init__(self, agent_id, location):
        self.agent_id = agent_id
        self.location = location
        self.status = "active"
        self.ml_model = None
        
    async def process_stream(self, video_stream):
        """Procesa el stream de video en tiempo real"""
        
    def detect_anomaly(self, frame):
        """Detecta anomalías usando ML"""
        
    def trigger_alert(self, event_type, data):
        """Dispara alertas al sistema central""" 
```

### src\agent_modules\access_control\access_agent.py
```py | 9899 bytes | Modificado: 2025-03-05 14:08:23.069305
```
from src.agent_modules.base.agent_base import BaseAgent, AgentConfig
from typing import Dict, Any, Optional, List
import cv2
import numpy as np
from datetime import datetime
import asyncio
from src.core.ml_engine.face_recognition import FaceRecognizer
from src.agent_modules.access_control.hardware_controller import AccessHardwareController
from src.core.ml_engine.plate_recognition import PlateRecognizer
from pathlib import Path
import json

class AccessControlAgent(BaseAgent):
    def __init__(self, config: Dict[str, Any], event_bus, logger):
        super().__init__(config, event_bus, logger)
        self.active_sessions = {}
        self.pending_authorizations = {}
        self.access_rules = self._load_access_rules()
        
        # Inicializar componentes
        self.face_recognizer = FaceRecognizer(config['face_recognition'])
        self.hardware = AccessHardwareController(config['hardware'])
        self.plate_recognizer = PlateRecognizer()
        
        # Hardware
        self.card_reader = RFIDReader(config['hardware']['card_reader'])
        self.gpio = GPIOController(config['hardware']['gpio'])
        
        # Estado
        self.failed_attempts: Dict[str, List[datetime]] = {}
        
        # Cache de usuarios autorizados
        self.authorized_users: Dict[str, Dict[str, Any]] = {}
        self._load_authorized_users()
        
    async def start(self):
        """Inicia el agente de control de acceso"""
        await super().start()
        
        try:
            # Inicializar hardware
            await self.card_reader.initialize()
            await self.gpio.initialize()
            
            # Iniciar loops de procesamiento
            self.tasks = [
                asyncio.create_task(self._process_card_reads()),
                asyncio.create_task(self._process_face_recognition()),
                asyncio.create_task(self._cleanup_expired_sessions())
            ]
            
            while self.running:
                await asyncio.sleep(0.1)
                
        except Exception as e:
            await self.handle_error(e)
            
        finally:
            for task in self.tasks:
                task.cancel()
            
    async def stop(self):
        """Detiene el agente"""
        self.running = False
        await self.card_reader.cleanup()
        await self.gpio.cleanup()
        await super().stop()
        
    async def _process_card_reads(self):
        """Procesa lecturas de tarjetas RFID"""
        while self.running:
            try:
                card_data = await self.card_reader.read()
                if card_data:
                    await self._handle_card_access(card_data)
                    
            except Exception as e:
                await self.handle_error(e)
                await asyncio.sleep(1)
                
    async def _process_face_recognition(self):
        """Procesa reconocimiento facial"""
        cap = cv2.VideoCapture(self.config['camera_source'])
        
        try:
            while self.running:
                ret, frame = cap.read()
                if not ret:
                    continue
                    
                # Detectar y reconocer rostros
                faces = await self.face_recognizer.identify_faces(frame)
                
                for face in faces:
                    await self._handle_face_access(face, frame)
                    
                await asyncio.sleep(0.1)
                
        finally:
            cap.release()
            
    async def _handle_card_access(self, card_data: str):
        """Maneja un intento de acceso con tarjeta"""
        user_id = self._get_user_by_card(card_data)
        
        if not user_id:
            await self._handle_unauthorized_access("card_invalid", card_data)
            return
            
        if not self._check_user_schedule(user_id):
            await self._handle_unauthorized_access("schedule_violation", user_id)
            return
            
        await self._grant_access(user_id, "card")
        
    async def _handle_face_access(self, face_data: Dict[str, Any], frame: np.ndarray):
        """Maneja un intento de acceso por reconocimiento facial"""
        user_id = face_data['user_id']
        confidence = face_data['confidence']
        
        if confidence < self.config['face_recognition']['min_confidence']:
            await self._handle_unauthorized_access("face_low_confidence", user_id)
            return
            
        if not self._check_user_schedule(user_id):
            await self._handle_unauthorized_access("schedule_violation", user_id)
            return
            
        # Guardar foto de verificación si está configurado
        if self.config.get('save_verification_photos', True):
            await self._save_verification_photo(frame, user_id)
            
        await self._grant_access(user_id, "face")
        
    async def _grant_access(self, user_id: str, method: str):
        """Concede acceso a un usuario"""
        user = self.authorized_users.get(user_id)
        if not user:
            return
            
        # Activar relé/barrera
        barrier_pin = self.config['hardware']['gpio']['barrier_pin']
        await self.gpio.set_pin(barrier_pin, True)
        
        # Registrar sesión
        session_id = f"{user_id}_{datetime.now():%Y%m%d_%H%M%S}"
        self.active_sessions[session_id] = {
            'user_id': user_id,
            'start_time': datetime.now(),
            'method': method
        }
        
        # Emitir evento
        await self.emit_event(
            "access_granted",
            {
                "user_id": user_id,
                "name": user['name'],
                "access_point": self.config['access_point_id'],
                "method": method,
                "timestamp": datetime.now().isoformat()
            }
        )
        
        # Programar cierre de barrera
        await asyncio.sleep(self.config['barrier_open_time'])
        await self.gpio.set_pin(barrier_pin, False)
        
    async def _handle_unauthorized_access(self, reason: str, identifier: str):
        """Maneja un intento de acceso no autorizado"""
        # Registrar intento fallido
        if identifier not in self.failed_attempts:
            self.failed_attempts[identifier] = []
            
        self.failed_attempts[identifier].append(datetime.now())
        
        # Verificar bloqueo
        if len(self.failed_attempts[identifier]) >= self.config['max_failed_attempts']:
            await self._handle_lockout(identifier)
            
        # Emitir evento
        await self.emit_event(
            "access_denied",
            {
                "identifier": identifier,
                "reason": reason,
                "access_point": self.config['access_point_id'],
                "timestamp": datetime.now().isoformat()
            },
            priority=3
        )
        
    def _check_user_schedule(self, user_id: str) -> bool:
        """Verifica si el usuario tiene permitido el acceso en el horario actual"""
        user = self.authorized_users.get(user_id)
        if not user:
            return False
            
        current_time = datetime.now()
        schedules = user.get('schedules', [])
        
        for schedule in schedules:
            if self._is_in_schedule(current_time, schedule):
                return True
                
        return False
        
    def _load_authorized_users(self):
        """Carga la lista de usuarios autorizados"""
        users_file = Path(self.config['users_db_path'])
        if not users_file.exists():
            self.logger.logger.warning("Base de datos de usuarios no encontrada")
            return
            
        with open(users_file) as f:
            users_data = json.load(f)
            
        self.authorized_users = {
            user['id']: user
            for user in users_data
        }
        
    async def _cleanup_expired_sessions(self):
        """Limpia sesiones expiradas"""
        while self.running:
            current_time = datetime.now()
            
            # Limpiar sesiones antiguas
            self.active_sessions = {
                session_id: session
                for session_id, session in self.active_sessions.items()
                if (current_time - session['start_time']).total_seconds() < 3600
            }
            
            # Limpiar intentos fallidos antiguos
            for identifier in list(self.failed_attempts.keys()):
                self.failed_attempts[identifier] = [
                    attempt
                    for attempt in self.failed_attempts[identifier]
                    if (current_time - attempt).total_seconds() < 3600
                ]
                
                if not self.failed_attempts[identifier]:
                    del self.failed_attempts[identifier]
                    
            await asyncio.sleep(60)
        
    def _load_access_rules(self) -> Dict[str, Any]:
        """Carga reglas de acceso desde la configuración"""
        return self.config.get('access_rules', {
            'vehicles': {'whitelist': set(), 'temporary': {}},
            'residents': set(),
            'visitors': {}
        }) 

    def _check_visitor_vehicle(self, plate: str) -> bool:
        """Verifica si el vehículo pertenece a un visitante autorizado"""
        for visitor in self.access_rules['visitors'].values():
            if visitor.get('vehicle_plate') == plate and visitor['status'] == 'active':
                return True
        return False 
```

### src\agent_modules\access_control\hardware_controller.py
```py | 2733 bytes | Modificado: 2025-03-05 13:46:31.251499
```
from typing import Dict, Any, Optional
import asyncio
from enum import Enum
import RPi.GPIO as GPIO  # Simularemos si no está en Raspberry Pi

class DeviceStatus(Enum):
    READY = "ready"
    BUSY = "busy"
    ERROR = "error"
    DISABLED = "disabled"

class AccessHardwareController:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.status = {}
        self._setup_gpio()
        
    def _setup_gpio(self):
        """Configura los pines GPIO"""
        try:
            GPIO.setmode(GPIO.BCM)
            
            # Configurar pines para barrera
            GPIO.setup(self.config['pins']['barrier'], GPIO.OUT)
            GPIO.setup(self.config['pins']['sensor'], GPIO.IN)
            
            # Configurar LED de estado
            GPIO.setup(self.config['pins']['status_led'], GPIO.OUT)
            
        except Exception as e:
            print(f"Error setting up GPIO: {e}")
            # Modo simulación si no hay GPIO
            self.simulation_mode = True
            
    async def open_barrier(self, duration: int = 15) -> bool:
        """Abre la barrera por un tiempo determinado"""
        try:
            # Activar relé de barrera
            GPIO.output(self.config['pins']['barrier'], GPIO.HIGH)
            
            # Esperar duración especificada
            await asyncio.sleep(duration)
            
            # Cerrar barrera
            GPIO.output(self.config['pins']['barrier'], GPIO.LOW)
            
            return True
            
        except Exception as e:
            print(f"Error controlling barrier: {e}")
            return False
            
    async def check_sensor(self) -> bool:
        """Verifica el estado del sensor de presencia"""
        try:
            return GPIO.input(self.config['pins']['sensor']) == GPIO.HIGH
        except:
            # Simulación
            return True
            
    def set_status_led(self, status: str):
        """Configura LED de estado"""
        try:
            if status == "ready":
                GPIO.output(self.config['pins']['status_led'], GPIO.HIGH)
            elif status == "error":
                self._blink_led()
            else:
                GPIO.output(self.config['pins']['status_led'], GPIO.LOW)
        except:
            pass
            
    async def _blink_led(self, times: int = 3):
        """Hace parpadear el LED"""
        for _ in range(times):
            GPIO.output(self.config['pins']['status_led'], GPIO.HIGH)
            await asyncio.sleep(0.5)
            GPIO.output(self.config['pins']['status_led'], GPIO.LOW)
            await asyncio.sleep(0.5) 
```

### src\agent_modules\base\__init__.py
```py | 89 bytes | Modificado: 2025-03-05 16:37:40.180201
```
from .agent_base import BaseAgent, AgentConfig

__all__ = ['BaseAgent', 'AgentConfig'] 
```

### src\agent_modules\base\agent_base.py
```py | 4086 bytes | Modificado: 2025-03-06 00:06:56.191480
```
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio
from src.utils.logging import SecurityLogger
from src.core.event_system import EventBus, Event

@dataclass
class AgentConfig:
    name: str
    type: str
    enabled: bool = True
    settings: Dict[str, Any] = None

@dataclass
class AgentStatus:
    status: str
    last_update: datetime
    details: Dict[str, Any]

class BaseAgent(ABC):
    def __init__(self, config: Dict[str, Any], event_bus: EventBus, logger: SecurityLogger):
        self.config = config
        self.event_bus = event_bus
        self.logger = logger
        self.status = AgentStatus(
            status="initialized",
            last_update=datetime.now(),
            details={}
        )
        self.running = False
        self._processing_lock = asyncio.Lock()
        
    async def start(self):
        """Inicia el agente"""
        self.running = True
        await self.logger.log_event(
            'agent_started',
            {'agent_name': self.config['name']}
        )
        await self.update_status("running")
        
    async def stop(self):
        """Detiene el agente"""
        self.running = False
        await self.logger.log_event(
            'agent_stopped',
            {'agent_name': self.config['name']}
        )
        await self.update_status("stopped")
        
    async def update_status(self, status: str, details: Dict[str, Any] = None):
        """Actualiza el estado del agente"""
        self.status = AgentStatus(
            status=status,
            last_update=datetime.now(),
            details=details or {}
        )
        
        # Emitir evento de cambio de estado
        await self.emit_event(
            "agent_status_changed",
            {
                "agent_id": self.config['name'],
                "status": status,
                "details": details or {}
            }
        )
        
    async def emit_event(self, event_type: str, data: Dict[str, Any], priority: int = 1):
        """Emite un evento al bus de eventos"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.now(),
            source=self.config['name'],
            priority=priority
        )
        
        await self.event_bus.emit(event)
        
    async def handle_error(self, error: Exception, context: Optional[Dict[str, Any]] = None):
        """Maneja errores del agente"""
        await self.logger.log_error(error, {
            'agent_name': self.config['name'],
            'agent_type': self.config['type'],
            **(context or {})
        })
        error_context = {"error": str(error)}
        if context:
            error_context.update(context)
        await self.update_status("error", error_context)
        
    @abstractmethod
    async def process_frame(self, frame, frame_id: int):
        """Procesa un frame de video"""
        pass
        
    async def validate_config(self) -> bool:
        """Valida la configuración del agente"""
        required_fields = ['name', 'type', 'enabled']
        
        for field in required_fields:
            if field not in self.config:
                await self.handle_error(
                    ValueError(f"Campo requerido faltante: {field}"),
                    {"config": self.config}
                )
                return False
                
        return True
        
    async def _safe_process(self, func, *args, **kwargs):
        """Ejecuta una función de manera segura con manejo de errores"""
        try:
            async with self._processing_lock:
                return await func(*args, **kwargs)
        except Exception as e:
            await self.handle_error(e, {
                "function": func.__name__,
                "args": args,
                "kwargs": kwargs
            })
            return None 
```

### src\agent_modules\video_analytics\__init__.py
```py | 81 bytes | Modificado: 2025-03-06 00:12:45.405500
```
from .video_agent import VideoAnalyticsAgent

__all__ = ['VideoAnalyticsAgent']
```

### src\agent_modules\video_analytics\video_agent.py
```py | 19452 bytes | Modificado: 2025-03-06 00:41:07.236804
```
import cv2
import numpy as np
from typing import List, Tuple, Optional, Dict, Any
from src.agent_modules.base.agent_base import BaseAgent, AgentConfig
from src.core.ml_engine.object_detection import ObjectDetector, Detection
from src.core.ml_engine.object_tracking import ObjectTracker, Track
from src.core.ml_engine.behavior_analyzer import BehaviorAnalyzer, BehaviorPattern
from src.core.event_system.event_bus import Event
from datetime import datetime
from pathlib import Path
from src.services.video_recorder.recorder import VideoRecorder

class VideoAnalyticsAgent(BaseAgent):
    def __init__(self, config: Dict[str, Any], event_bus=None, logger=None):
        # Crear objetos mock si no se proporcionan
        if event_bus is None:
            from src.core.event_system import EventBus
            event_bus = EventBus()
        
        if logger is None:
            from src.utils.logging import SecurityLogger
            logger = SecurityLogger({'log_dir': 'logs'})
        
        super().__init__(config, event_bus, logger)
        
        # Inicializar componentes con valores predeterminados si no existen
        self.detector = ObjectDetector(config.get('object_detection', {}), test_mode=True)
        self.tracker = ObjectTracker(config.get('object_tracking', {}))
        self.analyzer = BehaviorAnalyzer(config.get('behavior_analysis', {}))
        
        # Configuración de video con valores predeterminados
        self.video_config = config.get('video_processing', {
            'frame_skip': 1,
            'resize_width': 640,
            'resize_height': 480
        })
        
        # Inicializar recorder sólo si está en el config
        if 'recording' in config:
            self.recorder = VideoRecorder(config['recording'])
        else:
            # Usar valores predeterminados para grabación
            default_recording_config = {
                'storage_path': 'recordings',
                'fps': 15,
                'max_duration_minutes': 10,
                'enabled': False
            }
            self.recorder = VideoRecorder(default_recording_config)
        
        # Completar inicialización de variables restantes
        self.frame_count = 0
        self.cap = None
        self.zones = self._setup_zones(config.get('zones', []))
        
        # Estado del procesamiento
        self.active_tracks = {}
        self.last_frame_time = None
        
        self.current_recording = None
        self.recording_events = []
        
    async def start(self):
        """Inicia el procesamiento de video"""
        await super().start()
        
        try:
            self.cap = cv2.VideoCapture(self.config['video_source'])
            if not self.cap.isOpened():
                raise RuntimeError(f"No se pudo abrir la fuente de video: {self.config['video_source']}")
                
            self.logger.logger.info(f"Iniciando análisis de video en {self.config['video_source']}")
            
            while self.running:
                await self._process_frame()
                
        except Exception as e:
            await self.handle_error(e)
            
        finally:
            if self.cap:
                self.cap.release()
                
    async def _process_frame(self):
        """Procesa un frame de video"""
        # Saltar frames según configuración
        if self.frame_count % self.video_config['frame_skip'] != 0:
            self.frame_count += 1
            return
            
        ret, frame = self.cap.read()
        if not ret:
            await self.stop()
            return
            
        try:
            # Preprocesar frame
            frame = self._preprocess_frame(frame)
            
            # Detección de objetos
            detections = await self.detector.detect(frame, self.frame_count)
            
            # Tracking
            tracks = self.tracker.update(detections)
            
            # Analizar zonas y reglas
            await self._analyze_tracks(tracks, frame)
            
            # Analizar comportamientos
            patterns = self.analyzer.analyze_tracks(tracks, datetime.now())
            if patterns:
                await self._handle_behavior_patterns(patterns, frame)
            
            # Actualizar estado
            self._update_tracking_state(tracks)
            
            # Gestionar grabación
            await self._handle_recording(frame, tracks)
            
            # Guardar frame procesado si está configurado
            if self.config.get('save_processed_frames', False):
                await self._save_processed_frame(frame, tracks)
                
            self.frame_count += 1
            
        except Exception as e:
            await self.handle_error(e, {"frame_id": self.frame_count})
            
    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """Preprocesa el frame para análisis"""
        # Redimensionar si está configurado
        if 'resize_width' in self.video_config:
            frame = cv2.resize(
                frame,
                (self.video_config['resize_width'], self.video_config['resize_height'])
            )
            
        return frame
        
    async def _analyze_tracks(self, tracks: List[Track], frame: np.ndarray):
        """Analiza los tracks contra las reglas definidas"""
        current_time = datetime.now()
        
        for track in tracks:
            track_id = track.id
            detection = track.detection
            
            # Verificar cada zona
            for zone in self.zones:
                if self._is_in_zone(detection.bbox, zone['points']):
                    for rule in zone['rules']:
                        violation = await self._check_rule_violation(
                            track, rule, zone, current_time
                        )
                        
                        if violation:
                            await self._handle_violation(violation, track, frame, zone)
                            
    def _is_in_zone(self, bbox: tuple, zone_points: List[List[int]]) -> bool:
        """Verifica si un bbox está dentro de una zona"""
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) // 2
        center_y = (y1 + y2) // 2
        
        return cv2.pointPolygonTest(
            np.array(zone_points, np.int32),
            (center_x, center_y),
            False
        ) >= 0
        
    async def _check_rule_violation(
        self, track: Track, rule: Dict[str, Any],
        zone: Dict[str, Any], current_time: datetime
    ) -> Optional[Dict[str, Any]]:
        """Verifica violaciones de reglas"""
        if track.detection.class_name not in rule['classes']:
            return None
            
        if track.detection.confidence < rule.get('min_confidence', 0.5):
            return None
            
        violation = None
        
        if rule['type'] == 'intrusion':
            # Verificar horario si está definido
            if 'schedule' in rule:
                if self._is_in_schedule(current_time, rule['schedule']):
                    violation = {
                        'type': 'intrusion',
                        'zone': zone['name'],
                        'confidence': track.detection.confidence
                    }
                    
        elif rule['type'] == 'loitering':
            # Verificar tiempo de permanencia
            if track.id in self.active_tracks:
                track_data = self.active_tracks[track.id]
                duration = (current_time - track_data['first_seen']).total_seconds()
                
                if duration > rule['max_time']:
                    violation = {
                        'type': 'loitering',
                        'zone': zone['name'],
                        'duration': duration,
                        'confidence': track.detection.confidence
                    }
                    
        return violation
        
    async def _handle_violation(
        self, violation: Dict[str, Any],
        track: Track,
        frame: np.ndarray,
        zone: Dict[str, Any]
    ):
        """Maneja una violación de regla detectada"""
        # Guardar snapshot
        snapshot_path = await self._save_violation_snapshot(frame, track, violation)
        
        # Emitir evento
        await self.emit_event(
            "security_violation",
            {
                "violation_type": violation['type'],
                "zone": zone['name'],
                "object_class": track.detection.class_name,
                "confidence": violation['confidence'],
                "snapshot_path": str(snapshot_path),
                "details": violation
            },
            priority=3
        )
        
        # Añadir evento a la grabación actual
        if self.current_recording:
            self.recording_events.append({
                "type": "violation",
                "violation_type": violation['type'],
                "timestamp": datetime.now().isoformat(),
                "details": {
                    "zone": zone['name'],
                    "object_class": track.detection.class_name,
                    "confidence": violation['confidence']
                }
            })
        
    async def _save_violation_snapshot(
        self, frame: np.ndarray,
        track: Track,
        violation: Dict[str, Any]
    ) -> Path:
        """Guarda una imagen de la violación detectada"""
        snapshots_dir = Path(self.config['snapshots_dir'])
        snapshots_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{violation['type']}_{timestamp}.jpg"
        path = snapshots_dir / filename
        
        # Dibujar información en el frame
        frame_copy = frame.copy()
        self.detector.draw_detections([track.detection], frame_copy)
        
        # Guardar imagen
        cv2.imwrite(str(path), frame_copy)
        
        return path
        
    def _is_in_schedule(self, current_time: datetime, schedule: str) -> bool:
        """Verifica si la hora actual está dentro del horario especificado"""
        start_time, end_time = schedule.split('-')
        current_hour = current_time.hour + current_time.minute / 60
        
        start_hour = float(start_time.split(':')[0])
        end_hour = float(end_time.split(':')[0])
        
        if end_hour < start_hour:  # Horario nocturno
            return current_hour >= start_hour or current_hour <= end_hour
        else:
            return start_hour <= current_hour <= end_hour
            
    def _setup_zones(self, zones_config: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Configura las zonas de monitoreo"""
        if not zones_config:
            # Devolver una zona predeterminada si no hay configuración
            return [{
                'name': 'default_zone',
                'points': [[0, 0], [640, 0], [640, 480], [0, 480]],
                'rules': []
            }]
        return zones_config
        
    def _update_tracking_state(self, tracks: List[Track]):
        """Actualiza el estado de tracking"""
        current_time = datetime.now()
        
        # Actualizar tracks existentes
        for track in tracks:
            if track.id not in self.active_tracks:
                self.active_tracks[track.id] = {
                    'first_seen': current_time,
                    'last_seen': current_time,
                    'frames_visible': 1
                }
            else:
                self.active_tracks[track.id]['last_seen'] = current_time
                self.active_tracks[track.id]['frames_visible'] += 1
                
        # Limpiar tracks antiguos
        self.active_tracks = {
            track_id: data
            for track_id, data in self.active_tracks.items()
            if (current_time - data['last_seen']).total_seconds() < 60
        } 
        
    async def _handle_behavior_patterns(self, 
                                      patterns: List[BehaviorPattern],
                                      frame: np.ndarray):
        """Maneja patrones de comportamiento detectados"""
        for pattern in patterns:
            # Guardar snapshot
            snapshot_path = await self._save_pattern_snapshot(
                frame, pattern
            )
            
            # Emitir evento
            await self.emit_event(
                "suspicious_behavior",
                {
                    "pattern_type": pattern.pattern_type,
                    "confidence": pattern.confidence,
                    "details": pattern.details,
                    "track_ids": pattern.track_ids,
                    "snapshot_path": str(snapshot_path)
                },
                priority=4 if pattern.confidence > 0.8 else 3
            )
            
    async def _save_pattern_snapshot(self,
                                   frame: np.ndarray,
                                   pattern: BehaviorPattern) -> Path:
        """Guarda una imagen del patrón detectado"""
        snapshots_dir = Path(self.config['snapshots_dir'])
        snapshots_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"behavior_{pattern.pattern_type}_{timestamp}.jpg"
        path = snapshots_dir / filename
        
        # Dibujar información en el frame
        frame_copy = frame.copy()
        
        # Añadir texto descriptivo
        cv2.putText(
            frame_copy,
            f"{pattern.pattern_type.upper()} ({pattern.confidence:.2f})",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            (0, 0, 255),
            2
        )
        
        # Guardar imagen
        cv2.imwrite(str(path), frame_copy)
        
        return path 

    async def _handle_recording(self, frame: np.ndarray, tracks: List[Track]):
        """Gestiona la grabación de video"""
        should_record = self._should_record(tracks)
        
        if should_record and not self.current_recording:
            # Iniciar nueva grabación
            self.current_recording = await self.recorder.start_recording(
                camera_id=self.config['camera_id'],
                trigger_type='motion',
                frame=frame
            )
            self.recording_events = []
            
        if self.current_recording:
            # Añadir frame y eventos
            await self.recorder.add_frame(
                self.current_recording,
                frame,
                self.recording_events
            )
            self.recording_events = []
            
            if not should_record:
                # Detener grabación si ya no hay actividad
                await self.recorder.stop_recording(self.current_recording)
                self.current_recording = None
                
    def _should_record(self, tracks: List[Track]) -> bool:
        """Determina si se debe grabar basado en la actividad detectada"""
        if not self.config['recording'].get('enabled', True):
            return False
            
        # Verificar si hay suficientes objetos de interés
        relevant_tracks = [
            t for t in tracks
            if t.detection.class_name in self.config['recording'].get('trigger_classes', ['person'])
            and t.detection.confidence >= self.config['recording'].get('min_confidence', 0.5)
        ]
        
        return len(relevant_tracks) >= self.config['recording'].get('min_objects', 1) 

    async def process_event(self, event: Event):
        """Procesa eventos recibidos"""
        if event.event_type == 'zone_violation':
            # Procesar violación de zona
            await self._handle_zone_violation(event.data)
        elif event.event_type == 'suspicious_behavior':
            # Procesar comportamiento sospechoso
            await self._handle_suspicious_behavior(event.data) 

    async def _handle_zone_violation(self, data: Dict[str, Any]):
        """Maneja eventos de violación de zona"""
        try:
            # Registrar el evento
            await self.logger.log_event(
                'zone_violation_processed',
                {
                    'zone': data.get('zone'),
                    'violation_type': data.get('violation_type'),
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            # Si hay una grabación activa, añadir el evento
            if self.current_recording:
                self.recording_events.append({
                    'type': 'zone_violation',
                    'timestamp': datetime.now().isoformat(),
                    'details': data
                })
                
        except Exception as e:
            await self.handle_error(e, {'event_data': data})

    async def _handle_suspicious_behavior(self, data: Dict[str, Any]):
        """Maneja eventos de comportamiento sospechoso"""
        try:
            # Registrar el evento
            await self.logger.log_event(
                'suspicious_behavior_processed',
                {
                    'pattern_type': data.get('pattern_type'),
                    'confidence': data.get('confidence'),
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            # Si hay una grabación activa, añadir el evento
            if self.current_recording:
                self.recording_events.append({
                    'type': 'suspicious_behavior',
                    'timestamp': datetime.now().isoformat(),
                    'details': data
                })
                
        except Exception as e:
            await self.handle_error(e, {'event_data': data}) 

    async def process_frame(self, frame: np.ndarray, frame_id: int) -> Tuple[List[Detection], List[Track], List[BehaviorPattern]]:
        """Procesa un frame de video"""
        # Detección de objetos
        detections = await self.detector.detect(frame, frame_id)
        
        # Tracking de objetos
        tracks = self.tracker.update(detections)
        
        # Análisis de comportamiento
        patterns = self.analyzer.analyze_tracks(tracks, datetime.now())
        
        # Emitir eventos si se detectan patrones y tenemos event_bus
        if hasattr(self, 'event_bus') and self.event_bus:
            for pattern in patterns:
                await self.emit_event(
                    'behavior_detected',
                    {
                        'pattern': pattern.pattern_type,
                        'confidence': pattern.confidence,
                        'details': pattern.details,
                        'track_ids': pattern.track_ids
                    }
                )
            
        return detections, tracks, patterns 
```

### src\ai\behavior_analyzer.py
```py | 12734 bytes | Modificado: 2025-03-07 01:19:32.561797
```
    def _draw_event(self, frame, event):
        """Dibujar evento detectado"""
        event_type = event['type']
        bbox = event['bbox']
        position = event.get('position', (0, 0))
        
        # Colores según tipo de evento
        colors = {
            'loitering': (0, 0, 255),      # Rojo
            'intrusion': (0, 0, 255),      # Rojo
            'tailgating': (255, 165, 0),   # Azul claro
            'abandoned_object': (0, 255, 255), # Amarillo
            'default': (255, 255, 255)     # Blanco
        }
        
        # Obtener color para este tipo de evento
        color = colors.get(event_type, colors['default'])
        
        # Dibujar rectángulo de alerta
        x1, y1, x2, y2 = bbox
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
        
        # Dibujar texto de alerta
        alert_text = event_type.upper()
        cv2.putText(frame, alert_text, (x1, y1 - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                   
        # Dibujar líneas o marcadores específicos según el tipo de evento
        if event_type == 'tailgating':
            # Para tailgating, dibujar una línea entre líder y seguidor
            if 'leader_id' in event and 'follower_id' in event:
                leader_id = event['leader_id']
                follower_id = event['follower_id']
                
                if leader_id in self.tracked_objects and follower_id in self.tracked_objects:
                    leader = self.tracked_objects[leader_id]
                    follower = self.tracked_objects[follower_id]
                    
                    leader_pos = leader.path[-1]
                    follower_pos = follower.path[-1]
                    
                    cv2.line(frame, leader_pos, follower_pos, color, 2)
                    cv2.putText(frame, "TAILGATING", 
                              (int((leader_pos[0] + follower_pos[0])/2), 
                               int((leader_pos[1] + follower_pos[1])/2)),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                              
        elif event_type == 'loitering':
            # Para loitering, dibujar el área de permanencia
            radius = event.get('radius', 50)
            cv2.circle(frame, position, radius, color, 2)
            cv2.putText(frame, f"LOITERING ({event.get('duration', 0)/30:.1f}s)", 
                      (position[0], position[1] - 30),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                      
        elif event_type == 'intrusion':
            # Para intrusión, resaltar la zona violada
            zone_name = event.get('zone', '')
            if zone_name in self.config['zones']:
                zone_info = self.config['zones'][zone_name]
                polygon = zone_info['polygon']
                
                # Dibujar polígono con color de alerta
                points = np.array(polygon, np.int32)
                points = points.reshape((-1, 1, 2))
                cv2.polylines(frame, [points], True, color, 3)
                
                # Rellenar con transparencia
                overlay = frame.copy()
                cv2.fillPoly(overlay, [points], color)
                alpha = 0.3  # Transparencia
                cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)
                
        elif event_type == 'abandoned_object':
            # Para objeto abandonado, dibujar un círculo y tiempo
            cv2.circle(frame, position, 30, color, 2)
            duration = event.get('duration', 0) / 30  # Convertir frames a segundos
            cv2.putText(frame, f"ABANDONED ({duration:.1f}s)", 
                      (position[0], position[1] - 30),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                      
        return frame
        
    def _point_in_polygon(self, point, polygon):
        """Comprobar si un punto está dentro de un polígono"""
        x, y = point
        n = len(polygon)
        inside = False
        
        p1x, p1y = polygon[0]
        for i in range(n + 1):
            p2x, p2y = polygon[i % n]
            if y > min(p1y, p2y):
                if y <= max(p1y, p2y):
                    if x <= max(p1x, p2x):
                        if p1y != p2y:
                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                        if p1x == p2x or x <= xinters:
                            inside = not inside
            p1x, p1y = p2x, p2y
            
        return inside
        
    def _check_zones(self, obj):
        """Comprobar en qué zonas está un objeto"""
        zones = set()
        
        # Obtener posición actual (centro del objeto)
        if not obj.path:
            return zones
            
        point = obj.path[-1]
        
        # Comprobar cada zona
        for zone_name, zone_info in self.config['zones'].items():
            polygon = zone_info['polygon']
            if self._point_in_polygon(point, polygon):
                zones.add(zone_name)
                
        return zones
        
    def _register_object(self, centroid, bbox, class_info, confidence):
        """Registrar un nuevo objeto para seguimiento"""
        class_id, class_name = class_info
        object_id = self._generate_unique_id()
        
        # Generar color único basado en ID para visualización
        color_hash = sum(ord(c) for c in object_id) % 256
        color = (
            (color_hash * 71) % 256,  # B
            (color_hash * 237) % 256, # G
            (color_hash * 157) % 256  # R
        )
        
        # Crear objeto de seguimiento
        tracked_object = TrackedObject(
            object_id=object_id,
            class_id=class_id,
            class_name=class_name,
            positions=deque([(self.frame_id, bbox[0], bbox[1], bbox[2], bbox[3], confidence)],
                           maxlen=self.config['max_history']),
            last_seen=self.frame_id,
            color=color,
            first_seen=self.frame_id,
            path=[centroid],
            speed=0.0,
            direction=(0.0, 0.0),
            zones=set(),
            meta={}
        )
        
        # Comprobar zonas
        tracked_object.zones = self._check_zones(tracked_object)
        
        # Registrar objeto
        self.tracked_objects[object_id] = tracked_object
        
        return object_id
        
    def _update_object(self, object_id, centroid, bbox, confidence):
        """Actualizar información de un objeto rastreado"""
        obj = self.tracked_objects[object_id]
        
        # Actualizar posiciones y trayectoria
        obj.positions.append((self.frame_id, bbox[0], bbox[1], bbox[2], bbox[3], confidence))
        obj.path.append(centroid)
        
        # Actualizar timestamp de última visualización
        obj.last_seen = self.frame_id
        
        # Actualizar velocidad y dirección si hay suficientes posiciones
        if len(obj.path) >= 2:
            p1 = obj.path[-2]
            p2 = obj.path[-1]
            
            # Calcular velocidad (pixels/frame)
            distance = math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)
            obj.speed = distance
            
            # Calcular dirección (vector unitario)
            if distance > 0:
                obj.direction = ((p2[0] - p1[0]) / distance, (p2[1] - p1[1]) / distance)
                
        # Actualizar zonas
        obj.zones = self._check_zones(obj)
        
        # Reiniciar contador de desaparición
        self.disappeared[object_id] = 0
        
    def _deregister_object(self, object_id):
        """Eliminar un objeto del seguimiento"""
        del self.tracked_objects[object_id]
        del self.disappeared[object_id]
        
    def reset(self):
        """Reiniciar el estado del tracker"""
        self.tracked_objects.clear()
        self.disappeared.clear()
        self.alerts.clear()
        self.frame_id = 0
        
    def get_object_count(self, class_filter=None):
        """
        Obtener número de objetos rastreados, opcionalmente filtrados por clase
        
        Args:
            class_filter: Nombre de clase para filtrar o lista de clases
            
        Returns:
            Número de objetos que coinciden con el filtro
        """
        if class_filter is None:
            return len(self.tracked_objects)
            
        if isinstance(class_filter, str):
            class_filter = [class_filter]
            
        return sum(1 for obj in self.tracked_objects.values() 
                  if obj.class_name in class_filter)
                  
    def get_zone_counts(self):
        """
        Obtener conteo de objetos por zona
        
        Returns:
            Diccionario {zone_name: {class_name: count}}
        """
        counts = {zone: defaultdict(int) for zone in self.config['zones']}
        
        for obj in self.tracked_objects.values():
            for zone in obj.zones:
                if zone in counts:
                    counts[zone][obj.class_name] += 1
                    
        return counts
        
    def get_tracked_objects(self, class_filter=None, zone_filter=None):
        """
        Obtener objetos rastreados con filtros opcionales
        
        Args:
            class_filter: Filtrar por clase o lista de clases
            zone_filter: Filtrar por zona o lista de zonas
            
        Returns:
            Lista de objetos rastreados que coinciden con los filtros
        """
        result = list(self.tracked_objects.values())
        
        # Filtrar por clase
        if class_filter:
            if isinstance(class_filter, str):
                class_filter = [class_filter]
            result = [obj for obj in result if obj.class_name in class_filter]
            
        # Filtrar por zona
        if zone_filter:
            if isinstance(zone_filter, str):
                zone_filter = [zone_filter]
            result = [obj for obj in result if any(zone in obj.zones for zone in zone_filter)]
            
        return result
        
    def get_events_history(self, limit=100, event_type=None):
        """
        Obtener historial de eventos/alertas
        
        Args:
            limit: Número máximo de eventos a retornar
            event_type: Filtrar por tipo de evento
            
        Returns:
            Lista de eventos ordenados por tiempo (más reciente primero)
        """
        if event_type:
            filtered_events = [event for event in self.alerts if event['type'] == event_type]
        else:
            filtered_events = self.alerts
            
        # Ordenar por frame_id (descendente)
        sorted_events = sorted(filtered_events, key=lambda e: e['frame_id'], reverse=True)
        
        return sorted_events[:limit]
        
    def set_zone_definition(self, zone_name, polygon, color=None):
        """
        Definir o actualizar una zona
        
        Args:
            zone_name: Nombre de la zona
            polygon: Lista de puntos [(x1,y1), (x2,y2), ...]
            color: Tupla BGR (opcional)
        """
        if zone_name not in self.config['zones']:
            # Crear nueva zona
            self.config['zones'][zone_name] = {
                'polygon': polygon,
                'color': color or (0, 255, 0)  # Verde por defecto
            }
        else:
            # Actualizar zona existente
            self.config['zones'][zone_name]['polygon'] = polygon
            if color:
                self.config['zones'][zone_name]['color'] = color
                
        self.logger.info(f"Zona '{zone_name}' configurada con {len(polygon)} puntos")
        
    def delete_zone(self, zone_name):
        """Eliminar una zona definida"""
        if zone_name in self.config['zones']:
            del self.config['zones'][zone_name]
            self.logger.info(f"Zona '{zone_name}' eliminada")
            return True
        return False
        
    def export_config(self):
        """Exportar configuración actual"""
        return self.config
        
    def import_config(self, config):
        """Importar configuración"""
        self.config = config
        self.logger.info("Configuración importada")
        
        # Reiniciar tracker para aplicar nueva configuración
        self._init_tracker() 
```

### src\ai\face_recognition_system.py
```py | 26554 bytes | Modificado: 2025-03-07 02:04:45.375247
```
import os
import cv2
import numpy as np
import logging
import time
import pickle
import threading
import json
from datetime import datetime
import uuid
from pathlib import Path
import tensorflow as tf
from sklearn.preprocessing import Normalizer
from sklearn.neighbors import NearestNeighbors

class FaceRecognitionSystem:
    """
    Sistema de reconocimiento facial para identificación de personas
    
    Detecta, extrae características y compara rostros con una base de datos
    de personas conocidas para identificación en tiempo real.
    """
    
    def __init__(self, config=None):
        """
        Inicializar sistema de reconocimiento facial
        
        Args:
            config: Configuración del sistema con parámetros como:
                - model_path: Ruta al modelo de detección/reconocimiento
                - face_db_path: Ruta a la base de datos de rostros conocidos
                - detection_threshold: Umbral para detección (0-1)
                - recognition_threshold: Umbral para reconocimiento (0-1)
                - min_face_size: Tamaño mínimo de rostro en píxeles
                - use_gpu: Usar aceleración GPU si está disponible
        """
        self.logger = logging.getLogger('FaceRecognitionSystem')
        self.config = config or {}
        
        # Directorio para modelos
        self.models_dir = self.config.get('models_dir', 'models/face')
        os.makedirs(self.models_dir, exist_ok=True)
        
        # Parámetros de detección y reconocimiento
        self.detection_threshold = self.config.get('detection_threshold', 0.7)
        self.recognition_threshold = self.config.get('recognition_threshold', 0.6)
        self.min_face_size = self.config.get('min_face_size', 80)
        
        # Base de datos de rostros
        self.face_db_path = self.config.get('face_db_path', 'data/faces')
        os.makedirs(self.face_db_path, exist_ok=True)
        
        # Cargar base de datos de rostros
        self.face_database = {}
        self.face_embeddings = []
        self.face_identities = []
        self.knn_model = None
        
        # Mutex para acceso a BD de rostros
        self.db_lock = threading.Lock()
        
        # Inicializar modelos
        self.detector = None
        self.recognizer = None
        self._load_models()
        
        # Cargar base de datos de rostros
        self._load_face_database()
        
        self.logger.info("Sistema de reconocimiento facial inicializado")
    
    def _load_models(self):
        """Cargar modelos de detección y reconocimiento facial"""
        try:
            # Cargar modelo de detección facial
            detector_path = self.config.get('detector_model_path')
            if not detector_path:
                detector_path = os.path.join(self.models_dir, 'face_detection_model')
                
            if not os.path.exists(detector_path):
                self.logger.warning(f"Modelo de detección no encontrado en {detector_path}")
                self._download_detection_model(detector_path)
                
            self.detector = cv2.FaceDetectorYN.create(
                detector_path,
                "",
                (320, 320),
                self.detection_threshold,
                0,
                self.config.get('nms_threshold', 0.3)
            )
            
            # Cargar modelo de embeddings faciales
            recognizer_path = self.config.get('recognizer_model_path')
            if not recognizer_path:
                recognizer_path = os.path.join(self.models_dir, 'face_recognition_model')
                
            if not os.path.exists(recognizer_path):
                self.logger.warning(f"Modelo de reconocimiento no encontrado en {recognizer_path}")
                self._download_recognition_model(recognizer_path)
            
            # Cargar modelo para extracción de embeddings
            self.recognizer = tf.saved_model.load(recognizer_path)
            
            self.logger.info("Modelos de detección y reconocimiento facial cargados")
            
        except Exception as e:
            self.logger.error(f"Error al cargar modelos de reconocimiento facial: {e}")
            raise
            
    def _download_detection_model(self, target_path):
        """Descargar modelo de detección facial pre-entrenado"""
        try:
            # URL para YuNet (modelo ligero de OpenCV)
            url = "https://github.com/opencv/opencv_zoo/raw/master/models/face_detection_yunet/face_detection_yunet_2023mar.onnx"
            
            os.makedirs(os.path.dirname(target_path), exist_ok=True)
            
            import urllib.request
            self.logger.info(f"Descargando modelo de detección facial desde {url}")
            urllib.request.urlretrieve(url, target_path)
            
            self.logger.info(f"Modelo de detección facial descargado en {target_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error al descargar modelo de detección facial: {e}")
            return False
            
    def _download_recognition_model(self, target_path):
        """Descargar modelo de reconocimiento facial pre-entrenado"""
        try:
            # En una aplicación real, descargaríamos el modelo desde un repositorio seguro
            # Para este ejemplo, informamos que no se puede descargar automáticamente
            self.logger.error(f"El modelo de reconocimiento facial debe ser instalado manualmente en {target_path}")
            
            # Instrucciones para el usuario
            print(f"""
            ====== ATENCIÓN: MODELO DE RECONOCIMIENTO FACIAL REQUERIDO ======
            
            Por favor, descargue el modelo de reconocimiento facial y colóquelo en:
            {target_path}
            
            Opciones recomendadas:
            1. FaceNet: https://github.com/davidsandberg/facenet
            2. ArcFace: https://github.com/deepinsight/insightface
            3. DeepFace: https://github.com/serengil/deepface
            
            Luego reinicie el sistema.
            ==============================================================
            """)
            
            return False
            
        except Exception as e:
            self.logger.error(f"Error en descarga de modelo de reconocimiento: {e}")
            return False
    
    def _load_face_database(self):
        """Cargar base de datos de rostros conocidos"""
        try:
            with self.db_lock:
                db_file = os.path.join(self.face_db_path, 'face_database.pkl')
                embeddings_file = os.path.join(self.face_db_path, 'face_embeddings.pkl')
                
                # Cargar metadatos de personas
                if os.path.exists(db_file):
                    with open(db_file, 'rb') as f:
                        self.face_database = pickle.load(f)
                    self.logger.info(f"Base de datos de rostros cargada: {len(self.face_database)} personas")
                
                # Cargar embeddings para búsqueda rápida
                if os.path.exists(embeddings_file):
                    with open(embeddings_file, 'rb') as f:
                        data = pickle.load(f)
                        self.face_embeddings = data.get('embeddings', [])
                        self.face_identities = data.get('identities', [])
                    
                    # Inicializar KNN para búsqueda eficiente
                    if len(self.face_embeddings) > 0:
                        self._init_knn_model()
                        
                    self.logger.info(f"Embeddings faciales cargados: {len(self.face_embeddings)} rostros")
                
        except Exception as e:
            self.logger.error(f"Error al cargar base de datos de rostros: {e}")
            
    def _init_knn_model(self):
        """Inicializar modelo KNN para búsqueda eficiente de rostros similares"""
        try:
            if len(self.face_embeddings) > 0:
                X = np.array(self.face_embeddings)
                self.knn_model = NearestNeighbors(n_neighbors=min(5, len(X)), 
                                                 algorithm='auto', 
                                                 metric='euclidean')
                self.knn_model.fit(X)
                self.logger.info("Modelo KNN inicializado para búsqueda de rostros")
            else:
                self.knn_model = None
                
        except Exception as e:
            self.logger.error(f"Error al inicializar modelo KNN: {e}")
            self.knn_model = None
    
    def _save_face_database(self):
        """Guardar base de datos de rostros"""
        try:
            with self.db_lock:
                db_file = os.path.join(self.face_db_path, 'face_database.pkl')
                embeddings_file = os.path.join(self.face_db_path, 'face_embeddings.pkl')
                
                # Guardar metadatos de personas
                with open(db_file, 'wb') as f:
                    pickle.dump(self.face_database, f)
                
                # Guardar embeddings para búsqueda rápida
                with open(embeddings_file, 'wb') as f:
                    data = {
                        'embeddings': self.face_embeddings,
                        'identities': self.face_identities
                    }
                    pickle.dump(data, f)
                    
                self.logger.info(f"Base de datos de rostros guardada: {len(self.face_database)} personas")
                return True
                
        except Exception as e:
            self.logger.error(f"Error al guardar base de datos de rostros: {e}")
            return False
    
    def detect_faces(self, frame):
        """
        Detectar rostros en un frame
        
        Args:
            frame: Imagen de entrada (array de OpenCV)
            
        Returns:
            Lista de rostros detectados con sus coordenadas
        """
        if self.detector is None:
            self.logger.error("Detector facial no inicializado")
            return []
            
        try:
            # Preparar imagen para detección
            height, width, _ = frame.shape
            self.detector.setInputSize((width, height))
            
            # Detectar rostros
            faces, landmarks = self.detector.detect(frame)
            
            if faces is None:
                return []
                
            # Preparar resultados
            detections = []
            for i, face in enumerate(faces):
                x, y, w, h, confidence = face
                
                if confidence < self.detection_threshold:
                    continue
                    
                if w < self.min_face_size or h < self.min_face_size:
                    continue
                
                # Convertir a enteros
                x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)
                
                # Guardar landmarks si están disponibles
                face_landmarks = None
                if landmarks is not None and i < len(landmarks):
                    face_landmarks = landmarks[i]
                
                # Añadir a resultados
                detections.append({
                    'bbox': (x1, y1, x2, y2),
                    'confidence': float(confidence),
                    'landmarks': face_landmarks
                })
                
            return detections
            
        except Exception as e:
            self.logger.error(f"Error en detección facial: {e}")
            return []
    
    def extract_face_embedding(self, frame, face_detection):
        """
        Extraer características faciales (embedding)
        
        Args:
            frame: Imagen de entrada
            face_detection: Diccionario con datos de detección (bbox, etc.)
            
        Returns:
            Vector de embedding facial (características)
        """
        if self.recognizer is None:
            self.logger.error("Modelo de reconocimiento no inicializado")
            return None
            
        try:
            # Obtener coordenadas del rostro
            x1, y1, x2, y2 = face_detection['bbox']
            
            # Extraer rostro y preprocesar
            face_img = frame[y1:y2, x1:x2]
            
            # Redimensionar a tamaño esperado por el modelo
            face_img = cv2.resize(face_img, (160, 160))
            
            # Normalizar imagen para el modelo
            face_img = face_img.astype(np.float32) / 255.0
            face_img = np.expand_dims(face_img, axis=0)  # Añadir dimensión de batch
            
            # Extraer embedding usando el modelo
            embedding = self.recognizer(face_img)
            
            # Normalizar embedding
            l2_normalizer = Normalizer('l2')
            embedding = l2_normalizer.transform(embedding.numpy())
            
            return embedding[0]  # Retornar solo el primer embedding
            
        except Exception as e:
            self.logger.error(f"Error al extraer embedding facial: {e}")
            return None
    
    def identify_face(self, embedding):
        """
        Identificar rostro a partir de su embedding
        
        Args:
            embedding: Vector de características del rostro
            
        Returns:
            Información de la persona identificada o None si es desconocida
        """
        if self.knn_model is None or len(self.face_identities) == 0:
            return None
            
        try:
            # Buscar rostros similares con KNN
            distances, indices = self.knn_model.kneighbors([embedding])
            
            # Verificar si la distancia es menor al umbral de reconocimiento
            if distances[0][0] > self.recognition_threshold:
                return None  # Rostro desconocido
                
            # Obtener ID de la persona más similar
            person_id = self.face_identities[indices[0][0]]
            
            # Obtener información completa de la persona
            person_info = self.face_database.get(person_id, None)
            if person_info:
                # Añadir distancia (confianza) al resultado
                result = person_info.copy()
                result['distance'] = float(distances[0][0])
                result['confidence'] = 1.0 - float(distances[0][0])
                return result
                
            return None
            
        except Exception as e:
            self.logger.error(f"Error al identificar rostro: {e}")
            return None
    
    def process_frame(self, frame):
        """
        Procesar frame para detectar y reconocer rostros
        
        Args:
            frame: Imagen de entrada (array de OpenCV)
            
        Returns:
            Lista de rostros detectados con identidades asociadas
        """
        # Detectar rostros
        face_detections = self.detect_faces(frame)
        
        # Procesar cada rostro detectado
        processed_faces = []
        for face in face_detections:
            # Extraer embedding
            embedding = self.extract_face_embedding(frame, face)
            
            if embedding is None:
                continue
                
            # Buscar identidad
            identity = self.identify_face(embedding)
            
            # Preparar resultado
            result = {
                'detection': face,
                'bbox': face['bbox'],
                'embedding': embedding.tolist(),
                'identity': identity,
                'is_known': identity is not None
            }
            
            processed_faces.append(result)
            
        return processed_faces
    
    def register_new_face(self, frame, face_detection, person_info):
        """
        Registrar nuevo rostro en la base de datos
        
        Args:
            frame: Imagen que contiene el rostro
            face_detection: Detección del rostro a registrar
            person_info: Diccionario con información de la persona (nombre, etc.)
            
        Returns:
            ID de la persona registrada o None si falla
        """
        try:
            # Extraer embedding del rostro
            embedding = self.extract_face_embedding(frame, face_detection)
            
            if embedding is None:
                self.logger.error("No se pudo extraer embedding del rostro")
                return None
                
            # Generar ID único para la persona si no se proporcionó
            person_id = person_info.get('id', str(uuid.uuid4()))
            
            # Complementar información de la persona
            full_info = person_info.copy()
            full_info['id'] = person_id
            
            if 'registration_time' not in full_info:
                full_info['registration_time'] = datetime.now().isoformat()
                
            # Guardar imagen del rostro
            self._save_face_image(frame, face_detection, person_id)
            
            # Actualizar base de datos
            with self.db_lock:
                # Añadir a la base de datos
                self.face_database[person_id] = full_info
                
                # Añadir embedding a la lista
                self.face_embeddings.append(embedding)
                self.face_identities.append(person_id)
                
                # Reinicializar KNN
                self._init_knn_model()
                
                # Guardar base de datos
                self._save_face_database()
                
            self.logger.info(f"Rostro registrado para persona {person_id}")
            return person_id
            
        except Exception as e:
            self.logger.error(f"Error al registrar nuevo rostro: {e}")
            return None
    
    def _save_face_image(self, frame, face_detection, person_id):
        """Guardar imagen recortada del rostro"""
        try:
            # Crear directorio para imágenes de rostros
            person_dir = os.path.join(self.face_db_path, 'images', person_id)
            os.makedirs(person_dir, exist_ok=True)
            
            # Recortar rostro
            x1, y1, x2, y2 = face_detection['bbox']
            face_img = frame[y1:y2, x1:x2]
            
            # Generar nombre de archivo único
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{person_id}_{timestamp}.jpg"
            filepath = os.path.join(person_dir, filename)
            
            # Guardar imagen
            cv2.imwrite(filepath, face_img)
            
            return filepath
            
        except Exception as e:
            self.logger.error(f"Error al guardar imagen del rostro: {e}")
            return None
    
    def delete_person(self, person_id):
        """
        Eliminar persona de la base de datos
        
        Args:
            person_id: ID de la persona a eliminar
            
        Returns:
            True si se eliminó correctamente, False en caso contrario
        """
        try:
            with self.db_lock:
                # Verificar si la persona existe
                if person_id not in self.face_database:
                    self.logger.warning(f"Persona {person_id} no encontrada en la base de datos")
                    return False
                    
                # Eliminar de la base de datos
                del self.face_database[person_id]
                
                # Eliminar embeddings asociados
                indices_to_remove = []
                for i, identity in enumerate(self.face_identities):
                    if identity == person_id:
                        indices_to_remove.append(i)
                
                # Eliminar desde el final para evitar cambios en índices
                for i in sorted(indices_to_remove, reverse=True):
                    del self.face_embeddings[i]
                    del self.face_identities[i]
                
                # Reinicializar KNN si hay embeddings
                self._init_knn_model()
                
                # Guardar cambios
                self._save_face_database()
                
                # Intentar eliminar directorio de imágenes
                person_dir = os.path.join(self.face_db_path, 'images', person_id)
                if os.path.exists(person_dir):
                    import shutil
                    shutil.rmtree(person_dir)
                
                self.logger.info(f"Persona {person_id} eliminada de la base de datos")
                return True
                
        except Exception as e:
            self.logger.error(f"Error al eliminar persona {person_id}: {e}")
            return False
    
    def get_all_persons(self):
        """
        Obtener lista de todas las personas registradas
        
        Returns:
            Lista de diccionarios con información de las personas
        """
        try:
            with self.db_lock:
                return list(self.face_database.values())
                
        except Exception as e:
            self.logger.error(f"Error al obtener lista de personas: {e}")
            return []
    
    def get_person(self, person_id):
        """
        Obtener información de una persona específica
        
        Args:
            person_id: ID de la persona
            
        Returns:
            Diccionario con información de la persona o None si no existe
        """
        try:
            with self.db_lock:
                return self.face_database.get(person_id, None)
                
        except Exception as e:
            self.logger.error(f"Error al obtener información de persona {person_id}: {e}")
            return None
    
    def update_person_info(self, person_id, updated_info):
        """
        Actualizar información de una persona
        
        Args:
            person_id: ID de la persona
            updated_info: Diccionario con información actualizada
            
        Returns:
            True si se actualizó correctamente, False en caso contrario
        """
        try:
            with self.db_lock:
                # Verificar si la persona existe
                if person_id not in self.face_database:
                    self.logger.warning(f"Persona {person_id} no encontrada")
                    return False
                    
                # Obtener información actual
                current_info = self.face_database[person_id]
                
                # Actualizar campos (sin cambiar id ni tiempo de registro)
                for key, value in updated_info.items():
                    if key not in ['id', 'registration_time']:
                        current_info[key] = value
                
                # Guardar cambios
                self._save_face_database()
                
                self.logger.info(f"Información de persona {person_id} actualizada")
                return True
                
        except Exception as e:
            self.logger.error(f"Error al actualizar información de persona {person_id}: {e}")
            return False
    
    def annotate_frame(self, frame, processed_faces, include_unknown=True):
        """
        Anotar frame con rostros detectados e identidades
        
        Args:
            frame: Imagen de entrada
            processed_faces: Lista de rostros procesados con identidades
            include_unknown: Incluir rostros desconocidos en la anotación
            
        Returns:
            Imagen anotada con cuadros y nombres
        """
        try:
            # Crear copia de la imagen para no modificar la original
            vis_image = frame.copy()
            
            # Colores para mostrar (BGR)
            known_color = (0, 255, 0)  # Verde para personas conocidas
            unknown_color = (0, 0, 255)  # Rojo para personas desconocidas
            
            # Anotar cada rostro
            for face in processed_faces:
                # Obtener coordenadas
                x1, y1, x2, y2 = face['bbox']
                
                # Verificar si es persona conocida
                identity = face.get('identity')
                is_known = identity is not None
                
                # Si no incluimos desconocidos y esta persona es desconocida, saltamos
                if not include_unknown and not is_known:
                    continue
                    
                # Seleccionar color
                color = known_color if is_known else unknown_color
                
                # Dibujar rectángulo
                cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)
                
                # Preparar texto
                if is_known:
                    name = identity.get('name', 'Sin nombre')
                    confidence = identity.get('confidence', 0) * 100
                    text = f"{name} ({confidence:.1f}%)"
                else:
                    text = "Desconocido"
                    
                # Fondo para el texto
                text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                cv2.rectangle(vis_image, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), color, -1)
                
                # Dibujar texto
                cv2.putText(vis_image, text, (x1, y1 - 5), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                          
            return vis_image
            
        except Exception as e:
            self.logger.error(f"Error al anotar frame: {e}")
            return frame 
```

### src\ai\object_detector.py
```py | 24273 bytes | Modificado: 2025-03-07 01:14:35.256105
```
import cv2
import numpy as np
import logging
import time
import os
from threading import Thread, Lock
import tensorflow as tf

class ObjectDetector:
    """
    Detector de objetos basado en modelos pre-entrenados.
    Soporta diferentes backends: TensorFlow, OpenCV DNN, YOLOv5
    """
    
    def __init__(self, config=None):
        """
        Inicializar detector con configuración especificada
        
        Args:
            config: Diccionario de configuración con los siguientes campos:
                - model_type: 'tensorflow', 'opencv_dnn', 'yolov5'
                - model_path: Ruta al modelo
                - confidence_threshold: Umbral de confianza (0-1)
                - classes_of_interest: Lista de clases a detectar
                - device: 'cpu' o 'gpu'
        """
        self.logger = logging.getLogger('ObjectDetector')
        
        # Configuración por defecto
        default_config = {
            'model_type': 'tensorflow',
            'model_path': 'models/ssd_mobilenet_v2_coco',
            'confidence_threshold': 0.5,
            'classes_of_interest': ['person', 'car', 'truck', 'bicycle', 'motorcycle', 'bus'],
            'device': 'cpu',
            'max_batch_size': 4
        }
        
        # Aplicar configuración
        self.config = default_config.copy()
        if config:
            self.config.update(config)
            
        self.model = None
        self.running = False
        self.detection_queue = []
        self.queue_lock = Lock()
        self.processing_thread = None
        self.class_names = []
        
        # Inicializar modelo
        self._load_model()
        
    def _load_model(self):
        """Cargar el modelo de detección según la configuración"""
        try:
            model_type = self.config['model_type']
            
            self.logger.info(f"Cargando modelo de detección tipo: {model_type}")
            
            if model_type == 'tensorflow':
                self._load_tensorflow_model()
            elif model_type == 'opencv_dnn':
                self._load_opencv_dnn_model()
            elif model_type == 'yolov5':
                self._load_yolov5_model()
            else:
                raise ValueError(f"Tipo de modelo no soportado: {model_type}")
                
            self.logger.info("Modelo de detección cargado correctamente")
            
        except Exception as e:
            self.logger.error(f"Error al cargar modelo de detección: {e}")
            raise
            
    def _load_tensorflow_model(self):
        """Cargar modelo TensorFlow/TF-Lite"""
        model_path = self.config['model_path']
        
        # Configurar dispositivo
        if self.config['device'] == 'gpu':
            # Permitir crecimiento de memoria GPU según necesidad
            physical_devices = tf.config.list_physical_devices('GPU')
            if physical_devices:
                tf.config.experimental.set_memory_growth(physical_devices[0], True)
        else:
            # Forzar CPU
            os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
            
        # Cargar modelo según extensión
        if model_path.endswith('.tflite'):
            # Modelo TF-Lite
            self.interpreter = tf.lite.Interpreter(model_path=model_path)
            self.interpreter.allocate_tensors()
            
            # Obtener detalles del modelo
            self.input_details = self.interpreter.get_input_details()
            self.output_details = self.interpreter.get_output_details()
            
            # Dimensiones de entrada esperadas
            self.input_shape = self.input_details[0]['shape']
            
            # Cargar nombres de clases
            labels_path = os.path.join(os.path.dirname(model_path), 'labelmap.txt')
            if os.path.exists(labels_path):
                with open(labels_path, 'r') as f:
                    self.class_names = [line.strip() for line in f.readlines()]
            
        else:
            # Modelo SavedModel
            self.model = tf.saved_model.load(model_path)
            self.detect_fn = self.model.signatures['serving_default']
            
            # Cargar nombres de clases
            labels_path = os.path.join(model_path, 'label_map.pbtxt')
            if os.path.exists(labels_path):
                self.class_names = self._parse_labelmap(labels_path)
                
    def _parse_labelmap(self, labelmap_path):
        """Parsear archivo de mapeo de etiquetas de TensorFlow"""
        class_names = {}
        with open(labelmap_path, 'r') as f:
            content = f.read()
            
        for item in content.split('item {')[1:]:
            id_match = re.search(r'id: (\d+)', item)
            name_match = re.search(r'display_name: [\'"](.+?)[\'"]', item)
            if not name_match:
                name_match = re.search(r'name: [\'"](.+?)[\'"]', item)
                
            if id_match and name_match:
                class_id = int(id_match.group(1))
                class_name = name_match.group(1)
                class_names[class_id] = class_name
                
        return [class_names.get(i, f"class_{i}") for i in range(1, max(class_names.keys()) + 1)]
    
    def _load_opencv_dnn_model(self):
        """Cargar modelo usando OpenCV DNN"""
        model_path = self.config['model_path']
        config_path = self.config.get('config_path', 
                                      os.path.join(os.path.dirname(model_path), 'config.pbtxt'))
        
        # Cargar modelo
        self.model = cv2.dnn.readNetFromTensorflow(model_path, config_path)
        
        # Configurar dispositivo
        if self.config['device'] == 'gpu':
            self.model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
            self.model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
        else:
            self.model.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            
        # Cargar nombres de clases
        labels_path = self.config.get('labels_path', 
                                      os.path.join(os.path.dirname(model_path), 'labels.txt'))
        if os.path.exists(labels_path):
            with open(labels_path, 'r') as f:
                self.class_names = [line.strip() for line in f.readlines()]
                
    def _load_yolov5_model(self):
        """Cargar modelo YOLOv5 usando PyTorch"""
        try:
            import torch
            
            model_path = self.config['model_path']
            
            # Cargar modelo desde archivo o hub
            if os.path.exists(model_path):
                self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)
            else:
                # Cargar desde hub (e.g., 'yolov5s', 'yolov5m', etc.)
                self.model = torch.hub.load('ultralytics/yolov5', model_path)
                
            # Configurar dispositivo
            device = 'cuda' if self.config['device'] == 'gpu' and torch.cuda.is_available() else 'cpu'
            self.model.to(device)
            
            # Configurar umbral de confianza
            self.model.conf = self.config['confidence_threshold']
            
            # Las clases están incluidas en el modelo YOLOv5
            self.class_names = self.model.names
            
        except ImportError:
            self.logger.error("No se pudo cargar PyTorch. Instale con: pip install torch")
            raise
            
    def start_detection_thread(self):
        """Iniciar hilo de procesamiento para detección en segundo plano"""
        if self.processing_thread is not None and self.processing_thread.is_alive():
            self.logger.warning("El hilo de detección ya está en ejecución")
            return
            
        self.running = True
        self.processing_thread = Thread(target=self._detection_worker, daemon=True)
        self.processing_thread.start()
        self.logger.info("Hilo de detección iniciado")
        
    def stop_detection_thread(self):
        """Detener hilo de procesamiento de detección"""
        self.running = False
        if self.processing_thread:
            self.processing_thread.join(timeout=5.0)
            if self.processing_thread.is_alive():
                self.logger.warning("El hilo de detección no se detuvo correctamente")
                
        self.logger.info("Hilo de detección detenido")
        
    def _detection_worker(self):
        """Función de trabajo para el hilo de detección"""
        while self.running:
            # Procesar cola en lotes para mejorar eficiencia
            batch = []
            callbacks = []
            
            with self.queue_lock:
                # Obtener hasta max_batch_size imágenes de la cola
                batch_size = min(len(self.detection_queue), self.config['max_batch_size'])
                if batch_size > 0:
                    batch_items = self.detection_queue[:batch_size]
                    self.detection_queue = self.detection_queue[batch_size:]
                    
                    for item in batch_items:
                        batch.append(item[0])  # Imagen
                        callbacks.append(item[1])  # Callback
            
            # Procesar lote si no está vacío
            if batch:
                try:
                    # Detectar objetos en todas las imágenes
                    results = self.detect_batch(batch)
                    
                    # Llamar a los callbacks con los resultados
                    for i, (result, callback) in enumerate(zip(results, callbacks)):
                        if callback:
                            try:
                                callback(result)
                            except Exception as e:
                                self.logger.error(f"Error en callback de detección #{i}: {e}")
                                
                except Exception as e:
                    self.logger.error(f"Error procesando lote de detección: {e}")
                    # Informar error a los callbacks
                    for callback in callbacks:
                        if callback:
                            try:
                                callback(None)  # Indicar error con None
                            except Exception as cb_err:
                                pass
            else:
                # Si no hay nada que procesar, dormir para reducir uso de CPU
                time.sleep(0.01)
                
    def detect_async(self, image, callback=None):
        """
        Solicitar detección asíncrona de objetos
        
        Args:
            image: Imagen numpy (BGR) o ruta a imagen
            callback: Función a llamar con los resultados
        """
        # Cargar imagen si es una ruta
        if isinstance(image, str):
            image = cv2.imread(image)
            if image is None:
                raise ValueError(f"No se pudo cargar la imagen: {image}")
                
        # Encolar solicitud
        with self.queue_lock:
            self.detection_queue.append((image, callback))
            
        # Iniciar hilo de procesamiento si no está corriendo
        if not self.running or self.processing_thread is None or not self.processing_thread.is_alive():
            self.start_detection_thread()
            
    def detect(self, image):
        """
        Detectar objetos en una imagen (síncrono)
        
        Args:
            image: Imagen numpy (BGR) o ruta a imagen
            
        Returns:
            Lista de detecciones, cada una con:
            {
                'class_id': ID de clase,
                'class_name': Nombre de la clase,
                'confidence': Confianza (0-1),
                'bbox': [x1, y1, x2, y2] en píxeles
            }
        """
        # Cargar imagen si es una ruta
        if isinstance(image, str):
            image = cv2.imread(image)
            if image is None:
                raise ValueError(f"No se pudo cargar la imagen: {image}")
                
        return self.detect_batch([image])[0]
        
    def detect_batch(self, images):
        """
        Detectar objetos en un lote de imágenes
        
        Args:
            images: Lista de imágenes numpy (BGR)
            
        Returns:
            Lista de resultados, uno por imagen
        """
        if not images:
            return []
            
        model_type = self.config['model_type']
        
        if model_type == 'tensorflow':
            return self._detect_tensorflow_batch(images)
        elif model_type == 'opencv_dnn':
            return [self._detect_opencv_dnn(img) for img in images]
        elif model_type == 'yolov5':
            return self._detect_yolov5_batch(images)
        else:
            raise ValueError(f"Tipo de modelo no soportado: {model_type}")
            
    def _detect_tensorflow_batch(self, images):
        """Detección con TensorFlow"""
        results = []
        
        # Verificar si es modelo TFLite
        if hasattr(self, 'interpreter'):
            # Procesamiento individual para TFLite
            for image in images:
                results.append(self._detect_tflite(image))
        else:
            # Procesamiento por lotes para SavedModel
            batch_tensor = tf.convert_to_tensor(
                [self._preprocess_tf_image(img) for img in images]
            )
            
            detections = self.detect_fn(batch_tensor)
            
            # Procesar cada imagen en el lote
            for i, image in enumerate(images):
                height, width = image.shape[:2]
                
                # Extraer resultados para esta imagen
                boxes = detections['detection_boxes'][i].numpy()
                scores = detections['detection_scores'][i].numpy()
                classes = detections['detection_classes'][i].numpy().astype(np.int32)
                
                # Filtrar por umbral de confianza
                threshold = self.config['confidence_threshold']
                mask = scores >= threshold
                
                filtered_boxes = boxes[mask]
                filtered_scores = scores[mask]
                filtered_classes = classes[mask]
                
                # Convertir a formato común
                detections_list = []
                
                for j in range(len(filtered_scores)):
                    # Convertir coordenadas relativas [0,1] a píxeles
                    y1, x1, y2, x2 = filtered_boxes[j]
                    x1, y1, x2, y2 = int(x1 * width), int(y1 * height), int(x2 * width), int(y2 * height)
                    
                    class_id = filtered_classes[j]
                    class_name = self.class_names[class_id - 1] if class_id <= len(self.class_names) else f"class_{class_id}"
                    
                    # Filtrar por clases de interés
                    if class_name in self.config['classes_of_interest'] or not self.config['classes_of_interest']:
                        detections_list.append({
                            'class_id': int(class_id),
                            'class_name': class_name,
                            'confidence': float(filtered_scores[j]),
                            'bbox': [x1, y1, x2, y2]
                        })
                
                results.append(detections_list)
                
        return results
        
    def _detect_tflite(self, image):
        """Detección con TF-Lite"""
        # Redimensionar imagen según el modelo
        height, width = image.shape[:2]
        input_h, input_w = self.input_shape[1], self.input_shape[2]
        
        resized = cv2.resize(image, (input_w, input_h))
        resized_rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # Normalizar y preparar input
        input_data = np.expand_dims(resized_rgb, axis=0)
        if input_data.dtype != np.float32:
            input_data = input_data.astype(np.float32) / 255.0
            
        # Ejecutar inferencia
        self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
        self.interpreter.invoke()
        
        # Obtener resultados
        boxes = self.interpreter.get_tensor(self.output_details[0]['index'])[0]
        classes = self.interpreter.get_tensor(self.output_details[1]['index'])[0]
        scores = self.interpreter.get_tensor(self.output_details[2]['index'])[0]
        
        # Filtrar por umbral de confianza
        threshold = self.config['confidence_threshold']
        mask = scores >= threshold
        
        filtered_boxes = boxes[mask]
        filtered_scores = scores[mask]
        filtered_classes = classes[mask].astype(np.int32)
        
        # Convertir a formato común
        detections_list = []
        
        for i in range(len(filtered_scores)):
            # Convertir coordenadas relativas [0,1] a píxeles
            y1, x1, y2, x2 = filtered_boxes[i]
            x1, y1, x2, y2 = int(x1 * width), int(y1 * height), int(x2 * width), int(y2 * height)
            
            class_id = filtered_classes[i]
            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
            
            # Filtrar por clases de interés
            if class_name in self.config['classes_of_interest'] or not self.config['classes_of_interest']:
                detections_list.append({
                    'class_id': int(class_id),
                    'class_name': class_name,
                    'confidence': float(filtered_scores[i]),
                    'bbox': [x1, y1, x2, y2]
                })
        
        return detections_list
        
    def _preprocess_tf_image(self, image):
        """Preprocesar imagen para TensorFlow"""
        # Convertir BGR a RGB (TensorFlow espera RGB)
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Mantener los valores como están - el modelo se encarga de la normalización
        return rgb_image
        
    def _detect_opencv_dnn(self, image):
        """Detección con OpenCV DNN"""
        height, width = image.shape[:2]
        
        # Preparar blob de entrada
        blob = cv2.dnn.blobFromImage(image, size=(300, 300), swapRB=True, crop=False)
        
        # Ejecutar inferencia
        self.model.setInput(blob)
        detections = self.model.forward()
        
        # Procesar resultados
        results = []
        
        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            
            # Filtrar por umbral de confianza
            if confidence < self.config['confidence_threshold']:
                continue
                
            # Extraer índice de clase
            class_id = int(detections[0, 0, i, 1])
            
            # Obtener nombre de clase
            if 0 <= class_id < len(self.class_names):
                class_name = self.class_names[class_id]
            else:
                class_name = f"class_{class_id}"
                
            # Filtrar por clases de interés
            if class_name not in self.config['classes_of_interest'] and self.config['classes_of_interest']:
                continue
                
            # Extraer coordenadas de la caja
            x1 = int(detections[0, 0, i, 3] * width)
            y1 = int(detections[0, 0, i, 4] * height)
            x2 = int(detections[0, 0, i, 5] * width)
            y2 = int(detections[0, 0, i, 6] * height)
            
            # Agregar a resultados
            results.append({
                'class_id': class_id,
                'class_name': class_name,
                'confidence': float(confidence),
                'bbox': [x1, y1, x2, y2]
            })
            
        return results
        
    def _detect_yolov5_batch(self, images):
        """Detección con YOLOv5"""
        # YOLOv5 espera RGB
        rgb_images = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in images]
        
        # Ejecutar inferencia
        detections = self.model(rgb_images)
        
        # Procesar resultados
        results = []
        
        # Convertir a pandas y filtrar por clases de interés
        for i, img_dets in enumerate(detections.pandas().xyxy):
            height, width = images[i].shape[:2]
            img_results = []
            
            for _, detection in img_dets.iterrows():
                class_id = int(detection['class'])
                class_name = detection['name']
                
                # Filtrar por clases de interés
                if class_name in self.config['classes_of_interest'] or not self.config['classes_of_interest']:
                    img_results.append({
                        'class_id': class_id,
                        'class_name': class_name,
                        'confidence': float(detection['confidence']),
                        'bbox': [
                            int(detection['xmin']),
                            int(detection['ymin']),
                            int(detection['xmax']),
                            int(detection['ymax'])
                        ]
                    })
                    
            results.append(img_results)
            
        return results
        
    def visualize_detections(self, image, detections, output_path=None):
        """
        Visualizar detecciones en una imagen
        
        Args:
            image: Imagen numpy o ruta
            detections: Lista de detecciones del método detect()
            output_path: Ruta para guardar la imagen con detecciones
            
        Returns:
            Imagen con detecciones dibujadas
        """
        # Cargar imagen si es una ruta
        if isinstance(image, str):
            image = cv2.imread(image)
            if image is None:
                raise ValueError(f"No se pudo cargar la imagen: {image}")
                
        # Crear copia para no modificar la original
        vis_image = image.copy()
        
        # Colores para diferentes clases (BGR)
        colors = {
            'person': (0, 128, 255),    # Naranja
            'car': (0, 255, 0),         # Verde
            'truck': (0, 255, 128),     # Verde claro
            'bicycle': (255, 0, 0),     # Azul
            'motorcycle': (255, 0, 128),# Púrpura
            'bus': (255, 128, 0),       # Cian
            'default': (0, 255, 255)    # Amarillo
        }
        
        # Dibujar cada detección
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            class_name = det['class_name']
            confidence = det['confidence']
            
            # Obtener color para esta clase
            color = colors.get(class_name, colors['default'])
            
            # Dibujar rectángulo
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)
            
            # Preparar texto
            text = f"{class_name} {confidence:.2f}"
            
            # Fondo para el texto
            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(vis_image, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), color, -1)
            
            # Dibujar texto
            cv2.putText(vis_image, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
            
        # Guardar imagen si se especificó una ruta
        if output_path:
            cv2.imwrite(output_path, vis_image)
            
        return vis_image 
```

### src\alerts\alert_prioritizer.py
```py | 536 bytes | Modificado: 2025-03-07 00:39:22.029239
```
class AlertPrioritizer:
    def __init__(self, rules_config="configs/alert_priority_rules.json"):
        self.rules = self._load_rules(rules_config)
        
    def prioritize(self, alert_data, context=None):
        # Evaluar prioridad basada en tipo de alerta, ubicación, hora del día
        # Considerar factores como: 
        # - Valor de artículos en retail
        # - Nivel de acceso en zonas residenciales
        # - Historiales de alertas previas
        # ...
        return priority_level, priority_reason 
```

### src\analytics\behavior_analyzer.py
```py | 15112 bytes | Modificado: 2025-03-07 00:42:24.517431
```
import json
import numpy as np
from datetime import datetime
import os
from collections import defaultdict

class BehaviorAnalyzer:
    def __init__(self, rules_config="configs/behavior_rules.json"):
        self.rules = self._load_rules(rules_config)
        self.state_history = {}  # Historial de estados para cada objeto rastreado
        self.zone_definitions = {}  # Definiciones de zonas en la escena
        self.event_history = defaultdict(list)  # Historial de eventos detectados
        
    def _load_rules(self, config_path):
        """Cargar reglas de comportamiento desde archivo JSON"""
        if not os.path.exists(config_path):
            # Si no existe el archivo, usar reglas predeterminadas
            return {
                "retail": {
                    "loitering": {
                        "time_threshold": 60,  # segundos
                        "zone_ids": ["high_value_area", "cashier_area"]
                    },
                    "item_concealment": {
                        "pattern": "pick_and_conceal",
                        "detection_confidence": 0.7
                    },
                    "erratic_movement": {
                        "direction_changes_threshold": 6,
                        "time_window": 30  # segundos
                    }
                },
                "residential": {
                    "perimeter_breach": {
                        "zone_ids": ["perimeter"],
                        "time_threshold": 10  # segundos
                    },
                    "tailgating": {
                        "time_threshold": 5,  # segundos
                        "distance_threshold": 2.0  # metros
                    },
                    "loitering": {
                        "time_threshold": 120,  # segundos
                        "zone_ids": ["entrance", "restricted_area"]
                    }
                }
            }
            
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            print(f"Error loading rules configuration: {e}")
            return {}
            
    def set_zone_definitions(self, zones):
        """Establecer definiciones de zonas en la escena"""
        self.zone_definitions = zones
        
    def _is_in_zone(self, position, zone_id):
        """Determinar si una posición está dentro de una zona definida"""
        if zone_id not in self.zone_definitions:
            return False
            
        zone = self.zone_definitions[zone_id]
        if zone['type'] == 'polygon':
            # Comprobar si el punto está dentro del polígono
            import cv2
            point = np.array(position, dtype=np.int32)
            polygon = np.array(zone['coordinates'], dtype=np.int32)
            result = cv2.pointPolygonTest(polygon, (point[0], point[1]), False)
            return result >= 0
        elif zone['type'] == 'rectangle':
            # Comprobar si el punto está dentro del rectángulo
            x, y = position
            x1, y1, x2, y2 = zone['coordinates']
            return (x1 <= x <= x2) and (y1 <= y <= y2)
            
        return False
        
    def _update_track_state(self, track_id, current_data, timestamp):
        """Actualizar historial de estado para un objeto rastreado"""
        if track_id not in self.state_history:
            self.state_history[track_id] = []
            
        # Añadir nueva entrada al historial
        self.state_history[track_id].append({
            'timestamp': timestamp,
            'position': current_data.get('centroid', current_data.get('position')),
            'bbox': current_data.get('bbox'),
            'velocity': current_data.get('velocity'),
            'activity': current_data.get('activity')
        })
        
        # Mantener solo el historial reciente (últimos 2 minutos)
        cutoff_time = timestamp - 120  # 2 minutos en segundos
        self.state_history[track_id] = [
            state for state in self.state_history[track_id] 
            if state['timestamp'] >= cutoff_time
        ]
        
    def analyze(self, track_id, track_data, scene_context):
        """Analizar comportamiento de un objeto rastreado"""
        # Actualizar estado del objeto
        timestamp = scene_context.get('timestamp', datetime.now().timestamp())
        self._update_track_state(track_id, track_data, timestamp)
        
        # Analizar comportamientos basados en el contexto de la escena
        scene_type = scene_context.get('type', 'retail')  # Por defecto, asumir retail
        
        detected_behaviors = []
        
        if scene_type == 'retail':
            retail_behaviors = self._analyze_retail_behaviors(track_id, scene_context)
            detected_behaviors.extend(retail_behaviors)
        elif scene_type == 'residential':
            residential_behaviors = self._analyze_residential_behaviors(track_id, scene_context)
            detected_behaviors.extend(residential_behaviors)
            
        # Registrar comportamientos detectados
        if detected_behaviors:
            self.event_history[track_id].extend([
                {'behavior': b, 'timestamp': timestamp} for b in detected_behaviors
            ])
            
        return detected_behaviors
        
    def _analyze_retail_behaviors(self, track_id, scene_context):
        """Analizar comportamientos específicos de retail"""
        behaviors = []
        history = self.state_history.get(track_id, [])
        
        if not history:
            return behaviors
            
        # Comprobar permanencia (loitering)
        loitering = self._detect_loitering(track_id, 'retail', scene_context)
        if loitering:
            behaviors.append({
                'type': 'loitering',
                'confidence': loitering['confidence'],
                'zone': loitering['zone'],
                'duration': loitering['duration']
            })
            
        # Comprobar movimiento errático
        erratic = self._detect_erratic_movement(track_id, scene_context)
        if erratic:
            behaviors.append({
                'type': 'erratic_movement',
                'confidence': erratic['confidence'],
                'changes': erratic['changes']
            })
            
        return behaviors
        
    def _analyze_residential_behaviors(self, track_id, scene_context):
        """Analizar comportamientos específicos de áreas residenciales"""
        behaviors = []
        history = self.state_history.get(track_id, [])
        
        if not history:
            return behaviors
            
        # Comprobar violación de perímetro
        breach = self._detect_perimeter_breach(track_id, scene_context)
        if breach:
            behaviors.append({
                'type': 'perimeter_breach',
                'confidence': breach['confidence'],
                'zone': breach['zone']
            })
            
        # Comprobar permanencia (loitering)
        loitering = self._detect_loitering(track_id, 'residential', scene_context)
        if loitering:
            behaviors.append({
                'type': 'loitering',
                'confidence': loitering['confidence'],
                'zone': loitering['zone'],
                'duration': loitering['duration']
            })
            
        return behaviors
        
    def _detect_loitering(self, track_id, scene_type, scene_context):
        """Detectar permanencia prolongada en un área"""
        history = self.state_history.get(track_id, [])
        if len(history) < 2:
            return None
            
        # Obtener configuración según el tipo de escena
        if scene_type not in self.rules:
            return None
            
        loitering_config = self.rules[scene_type].get('loitering', {})
        time_threshold = loitering_config.get('time_threshold', 60)  # segundos
        zone_ids = loitering_config.get('zone_ids', [])
        
        # Determinar zona actual del objeto
        current_position = history[-1]['position']
        current_zone = None
        
        for zone_id in zone_ids:
            if self._is_in_zone(current_position, zone_id):
                current_zone = zone_id
                break
                
        if not current_zone:
            return None
            
        # Verificar cuánto tiempo ha estado en esta zona
        zone_entry_time = None
        for state in reversed(history):
            pos = state['position']
            if self._is_in_zone(pos, current_zone):
                zone_entry_time = state['timestamp']
            else:
                break
                
        if zone_entry_time is None:
            return None
            
        current_time = scene_context.get('timestamp', datetime.now().timestamp())
        duration = current_time - zone_entry_time
        
        if duration >= time_threshold:
            confidence = min(1.0, duration / (time_threshold * 2))  # Mayor duración, mayor confianza
            return {
                'confidence': confidence,
                'zone': current_zone,
                'duration': duration
            }
            
        return None
        
    def _detect_erratic_movement(self, track_id, scene_context):
        """Detectar movimiento errático (cambios frecuentes de dirección)"""
        history = self.state_history.get(track_id, [])
        if len(history) < 4:  # Necesitamos al menos 4 puntos para detectar cambios de dirección
            return None
            
        erratic_config = self.rules.get('retail', {}).get('erratic_movement', {})
        direction_threshold = erratic_config.get('direction_changes_threshold', 6)
        time_window = erratic_config.get('time_window', 30)  # segundos
        
        # Filtrar historial para obtener solo los últimos N segundos
        current_time = scene_context.get('timestamp', datetime.now().timestamp())
        cutoff_time = current_time - time_window
        recent_history = [state for state in history if state['timestamp'] >= cutoff_time]
        
        if len(recent_history) < 4:
            return None
            
        # Calcular cambios de dirección
        directions = []
        for i in range(1, len(recent_history)):
            prev_pos = recent_history[i-1]['position']
            curr_pos = recent_history[i]['position']
            dx = curr_pos[0] - prev_pos[0]
            dy = curr_pos[1] - prev_pos[1]
            angle = np.arctan2(dy, dx)  # Ángulo en radianes
            directions.append(angle)
            
        # Contar cambios significativos de dirección
        direction_changes = 0
        for i in range(1, len(directions)):
            # Detectar cambio de dirección significativo (más de 45 grados)
            diff = abs(directions[i] - directions[i-1])
            if diff > np.pi:
                diff = 2 * np.pi - diff  # Manejar el caso especial alrededor de -pi/pi
            if diff > np.pi / 4:  # Cambio de más de 45 grados
                direction_changes += 1
                
        if direction_changes >= direction_threshold:
            confidence = min(1.0, direction_changes / (direction_threshold * 1.5))
            return {
                'confidence': confidence,
                'changes': direction_changes
            }
            
        return None
        
    def _detect_perimeter_breach(self, track_id, scene_context):
        """Detectar violación de perímetro"""
        history = self.state_history.get(track_id, [])
        if len(history) < 2:
            return None
            
        perimeter_config = self.rules.get('residential', {}).get('perimeter_breach', {})
        zone_ids = perimeter_config.get('zone_ids', ['perimeter'])
        time_threshold = perimeter_config.get('time_threshold', 10)  # segundos
        
        # Verificar si el objeto está en una zona de perímetro
        current_position = history[-1]['position']
        current_zone = None
        
        for zone_id in zone_ids:
            if self._is_in_zone(current_position, zone_id):
                current_zone = zone_id
                break
                
        if not current_zone:
            return None
            
        # Verificar cuánto tiempo ha estado en la zona de perímetro
        zone_entry_time = None
        for state in reversed(history):
            pos = state['position']
            if self._is_in_zone(pos, current_zone):
                zone_entry_time = state['timestamp']
            else:
                break
                
        if zone_entry_time is None:
            return None
            
        current_time = scene_context.get('timestamp', datetime.now().timestamp())
        duration = current_time - zone_entry_time
        
        if duration >= time_threshold:
            confidence = min(1.0, duration / (time_threshold * 2))
            return {
                'confidence': confidence,
                'zone': current_zone
            }
            
        return None
        
    def detect_theft_patterns(self, tracks, scene):
        """Detectar patrones específicos de hurto en retail"""
        theft_patterns = []
        
        # Iterar sobre todos los objetos rastreados
        for track in tracks:
            track_id = track['id']
            
            # Analizar comportamiento individual
            behaviors = self.analyze(track_id, track, scene)
            
            # Si hay comportamientos sospechosos, evaluar como posible hurto
            suspicious_behaviors = [b for b in behaviors if b['confidence'] > 0.6]
            
            if len(suspicious_behaviors) >= 2:
                # Múltiples comportamientos sospechosos indican mayor probabilidad de hurto
                theft_patterns.append({
                    'track_id': track_id,
                    'confidence': max(b['confidence'] for b in suspicious_behaviors),
                    'behaviors': suspicious_behaviors,
                    'timestamp': scene.get('timestamp', datetime.now().timestamp())
                })
            elif any(b['type'] == 'item_concealment' for b in behaviors):
                # Ocultamiento de artículos es un fuerte indicador de hurto
                theft_patterns.append({
                    'track_id': track_id,
                    'confidence': next(b['confidence'] for b in behaviors if b['type'] == 'item_concealment'),
                    'behaviors': [b for b in behaviors if b['type'] == 'item_concealment'],
                    'timestamp': scene.get('timestamp', datetime.now().timestamp())
                })
                
        return theft_patterns 
```

### src\api\__init__.py
```py | 45 bytes | Modificado: 2025-03-06 00:51:14.304919
```
from .server import app

__all__ = ['app'] 
```

### src\api\api.py
```py | 23913 bytes | Modificado: 2025-03-15 14:09:13.925589
```
import os
import logging
import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta

import jwt
from fastapi import FastAPI, Depends, HTTPException, status, Query, Path, Header, BackgroundTasks, Request
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse, RedirectResponse
from pydantic import BaseModel, Field, EmailStr

from src.config.config_loader import load_config
from src.database.db import get_db
from src.database.models import User, Camera, Zone, Alert, Recording
from src.events.event_bus import EventBus, EventTypes
from src.camera_vendors.hikvision import HikvisionVendor
from src.camera_vendors.dahua import DahuaVendor

# Cargar configuración
config = load_config("configs/config.yaml")

# Configurar logger
logging.basicConfig(
    level=getattr(logging, config["system"]["log_level"]),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("API")

# Inicializar FastAPI
app = FastAPI(
    title="vigIA API",
    description="API para sistema de videovigilancia inteligente",
    version=config["system"]["version"],
)

# Siempre habilitar CORS si hay orígenes definidos
if "cors_origins" in config["api"] and config["api"]["cors_origins"]:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=config["api"]["cors_origins"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Configurar autenticación
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")
JWT_SECRET = os.environ.get("JWT_SECRET", config["api"]["jwt_secret"])
JWT_ALGORITHM = "HS256"
JWT_EXPIRATION_SECONDS = config["api"]["jwt_expiration"]

# Inicializar bus de eventos
event_bus = EventBus(
    redis_host=config["redis"]["host"],
    redis_port=config["redis"]["port"],
    redis_db=config["redis"]["db"],
    redis_password=config["redis"]["password"],
)

# Inicializar vendors de cámaras
camera_vendors = {
    "hikvision": HikvisionVendor(),
    "dahua": DahuaVendor(),
}

# Modelos de datos para la API
class TokenResponse(BaseModel):
    access_token: str
    token_type: str
    expires_in: int
    user_id: int
    username: str

class UserCreate(BaseModel):
    username: str
    email: EmailStr
    password: str
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    role_id: int = 2  # Por defecto rol básico

class UserResponse(BaseModel):
    id: int
    username: str
    email: str
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    role_id: int
    is_active: bool
    last_login: Optional[datetime] = None
    created_at: datetime

class CameraCreate(BaseModel):
    camera_id: str
    name: str
    location: Optional[str] = None
    url: str
    username: Optional[str] = None
    password: Optional[str] = None
    vendor: str
    model: Optional[str] = None
    resolution_width: Optional[int] = None
    resolution_height: Optional[int] = None
    fps: Optional[int] = None
    is_enabled: bool = True
    config: Optional[Dict[str, Any]] = None

class CameraResponse(BaseModel):
    id: int
    camera_id: str
    name: str
    location: Optional[str] = None
    vendor: str
    model: Optional[str] = None
    resolution_width: Optional[int] = None
    resolution_height: Optional[int] = None
    fps: Optional[int] = None
    is_enabled: bool
    created_at: datetime
    updated_at: datetime

class ZoneCreate(BaseModel):
    camera_id: int
    name: str
    type: str
    points: List[List[int]]
    color: Optional[str] = None
    is_active: bool = True

class ZoneResponse(BaseModel):
    id: int
    camera_id: int
    name: str
    type: str
    points: List[List[int]]
    color: Optional[str] = None
    is_active: bool
    created_at: datetime
    updated_at: datetime

class AlertResponse(BaseModel):
    id: int
    camera_id: int
    event_type: str
    priority: str
    timestamp: datetime
    screenshot_path: Optional[str] = None
    is_acknowledged: bool
    created_at: datetime

# Funciones auxiliares
async def get_current_user(token: str = Depends(oauth2_scheme)):
    """Obtiene el usuario actual a partir del token JWT"""
    try:
        # Log detallado para depuración
        logger.debug(f"Token recibido: {token[:15]}...")
        
        # Decodificar token con manejo de errores específicos
        try:
            payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        except jwt.ExpiredSignatureError:
            logger.warning("Token expirado")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Token expirado",
                headers={"WWW-Authenticate": "Bearer"},
            )
        except jwt.InvalidTokenError as e:
            logger.warning(f"Token inválido: {e}")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail=f"Token inválido: {e}",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        # Extraer y convertir el ID de usuario
        user_id = payload.get("sub")
        if user_id is None:
            logger.warning("Token sin ID de usuario (sub)")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Token inválido: falta ID de usuario",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        # Convertir ID si es necesario
        if isinstance(user_id, str) and user_id.isdigit():
            user_id = int(user_id)
        
        logger.debug(f"ID obtenido del token: {user_id}")
        
        # Obtener usuario de la base de datos
        with get_db() as db:
            user = db.query(User).filter(User.id == user_id).first()
            
            if not user:
                logger.warning(f"Usuario no encontrado: ID {user_id}")
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Usuario no encontrado",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            if not user.is_active:
                logger.warning(f"Usuario inactivo: {user.username}")
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Usuario inactivo",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
        logger.debug(f"Usuario autenticado: {user.username} (ID: {user_id})")
        return user
            
    except HTTPException:
        # Re-lanzar excepciones HTTP
        raise
    except Exception as e:
        logger.error(f"Error inesperado validando token: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Error interno del servidor",
            headers={"WWW-Authenticate": "Bearer"},
        )

def create_access_token(user_id: int, username: str) -> str:
    """Crea un token JWT para el usuario"""
    try:
        expires_delta = timedelta(seconds=JWT_EXPIRATION_SECONDS)
        expire = datetime.utcnow() + expires_delta
        
        # Necesitamos que sub sea un string según el estándar JWT
        user_id_str = str(user_id)
        
        to_encode = {
            "sub": user_id_str,  # Siempre como string
            "username": username,
            "exp": expire,
        }
        
        logger.debug(f"Creando token para usuario: {username} (ID: {user_id})")
        logger.debug(f"Payload para codificar: {to_encode}")
        
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        
        # Manejar diferencias entre versiones de PyJWT
        if isinstance(encoded_jwt, bytes):
            encoded_jwt = encoded_jwt.decode('utf-8')
            
        logger.debug(f"Token generado: {encoded_jwt[:20]}...")
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creando token: {e}", exc_info=True)
        raise

# Evento de inicio y cierre
@app.on_event("startup")
async def startup_event():
    # Conectar al bus de eventos
    await event_bus.connect()
    logger.info("API iniciada correctamente")

@app.on_event("shutdown")
async def shutdown_event():
    # Cerrar conexiones
    await event_bus.close()
    logger.info("API cerrada correctamente")

# Endpoints de autenticación
@app.post("/token", response_model=TokenResponse)
async def login_for_access_token(
    form_data: OAuth2PasswordRequestForm = Depends(),
    request: Request = None
):
    """Endpoint para obtener un token de acceso"""
    try:
        logger.info(f"Intento de inicio de sesión: {form_data.username}")
        
        with get_db() as db:
            user = db.query(User).filter(User.username == form_data.username).first()
            
            if not user:
                logger.warning(f"Usuario no encontrado: {form_data.username}")
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Usuario o contraseña incorrectos",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            if not user.is_active:
                logger.warning(f"Intento de acceso con usuario inactivo: {form_data.username}")
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Usuario inactivo",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            # Verificar contraseña
            from werkzeug.security import check_password_hash
            password_valid = check_password_hash(user.password_hash, form_data.password)
            
            if not password_valid:
                logger.warning(f"Contraseña incorrecta para usuario: {form_data.username}")
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Usuario o contraseña incorrectos",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            # Actualizar último login
            user.last_login = datetime.utcnow()
            db.commit()
            
            # Crear token
            access_token = create_access_token(user.id, user.username)
            
            logger.info(f"Inicio de sesión exitoso: {form_data.username}")
            return {
                "access_token": access_token,
                "token_type": "bearer",
                "expires_in": JWT_EXPIRATION_SECONDS,
                "user_id": user.id,
                "username": user.username,
            }
    
    except HTTPException:
        # Re-lanzar excepciones HTTP
        raise
    except Exception as e:
        logger.error(f"Error durante la autenticación: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Error interno del servidor",
        )

# Endpoints de usuarios
@app.post("/api/users", response_model=UserResponse)
async def create_user(user: UserCreate, current_user: User = Depends(get_current_user)):
    # Verificar permisos (simplificado)
    if current_user.role_id != 1:  # Asumir que rol 1 es admin
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="No tienes permiso para crear usuarios",
        )
    
    with get_db() as db:
        # Verificar si el usuario ya existe
        existing_user = db.query(User).filter(
            (User.username == user.username) | (User.email == user.email)
        ).first()
        
        if existing_user:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="El usuario o email ya existe",
            )
        
        # Crear nuevo usuario
        # En un sistema real se haría hash de la contraseña
        new_user = User(
            username=user.username,
            email=user.email,
            password_hash=user.password,  # En realidad se guardaría el hash
            first_name=user.first_name,
            last_name=user.last_name,
            role_id=user.role_id,
        )
        
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
        
        return new_user

# Endpoints de cámaras
@app.get("/api/cameras", response_model=List[CameraResponse])
async def get_cameras(
    skip: int = 0,
    limit: int = 100,
    name: Optional[str] = None,
    enabled: Optional[bool] = None,
    current_user: User = Depends(get_current_user),
):
    with get_db() as db:
        query = db.query(Camera)
        
        # Aplicar filtros
        if name:
            query = query.filter(Camera.name.ilike(f"%{name}%"))
        if enabled is not None:
            query = query.filter(Camera.is_enabled == enabled)
        
        # Ejecutar consulta con paginación
        cameras = query.offset(skip).limit(limit).all()
        return cameras

@app.post("/api/cameras", response_model=CameraResponse)
async def create_camera(camera: CameraCreate, current_user: User = Depends(get_current_user)):
    # Verificar permisos
    if current_user.role_id != 1:  # Admin
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="No tienes permiso para crear cámaras",
        )
    
    with get_db() as db:
        # Verificar si ya existe cámara con mismo ID
        existing_camera = db.query(Camera).filter(Camera.camera_id == camera.camera_id).first()
        if existing_camera:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Ya existe una cámara con ID {camera.camera_id}",
            )
        
        # Crear nueva cámara
        new_camera = Camera(
            camera_id=camera.camera_id,
            name=camera.name,
            location=camera.location,
            url=camera.url,
            username=camera.username,
            password=camera.password,
            vendor=camera.vendor,
            model=camera.model,
            resolution_width=camera.resolution_width,
            resolution_height=camera.resolution_height,
            fps=camera.fps,
            is_enabled=camera.is_enabled,
            config=camera.config or {},
        )
        
        db.add(new_camera)
        db.commit()
        db.refresh(new_camera)
        
        # Notificar a través del bus de eventos
        await event_bus.publish("camera_created", {
            "camera_id": new_camera.id,
            "camera_name": new_camera.name,
            "created_by": current_user.id,
        })
        
        return new_camera

@app.get("/api/cameras/{camera_id}", response_model=CameraResponse)
async def get_camera(camera_id: int, current_user: User = Depends(get_current_user)):
    with get_db() as db:
        camera = db.query(Camera).filter(Camera.id == camera_id).first()
        if not camera:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Cámara con ID {camera_id} no encontrada",
            )
        return camera

# Endpoints de zonas
@app.get("/api/cameras/{camera_id}/zones", response_model=List[ZoneResponse])
async def get_zones(
    camera_id: int,
    current_user: User = Depends(get_current_user),
):
    with get_db() as db:
        # Verificar que la cámara existe
        camera = db.query(Camera).filter(Camera.id == camera_id).first()
        if not camera:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Cámara con ID {camera_id} no encontrada",
            )
        
        # Obtener zonas de la cámara
        zones = db.query(Zone).filter(Zone.camera_id == camera_id).all()
        return zones

@app.post("/api/cameras/{camera_id}/zones", response_model=ZoneResponse)
async def create_zone(
    camera_id: int,
    zone: ZoneCreate,
    current_user: User = Depends(get_current_user),
):
    # Verificar que camera_id en la ruta coincide con el de la zona
    if zone.camera_id != camera_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="camera_id en la ruta no coincide con el de la zona",
        )
    
    with get_db() as db:
        # Verificar que la cámara existe
        camera = db.query(Camera).filter(Camera.id == camera_id).first()
        if not camera:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Cámara con ID {camera_id} no encontrada",
            )
        
        # Crear nueva zona
        new_zone = Zone(
            camera_id=zone.camera_id,
            name=zone.name,
            type=zone.type,
            points=zone.points,
            color=zone.color,
            is_active=zone.is_active,
        )
        
        db.add(new_zone)
        db.commit()
        db.refresh(new_zone)
        
        # Notificar a través del bus de eventos
        await event_bus.publish("zone_created", {
            "zone_id": new_zone.id,
            "zone_name": new_zone.name,
            "camera_id": camera_id,
            "created_by": current_user.id,
        })
        
        return new_zone

# Endpoints de alertas
@app.get("/api/alerts", response_model=List[AlertResponse])
async def get_alerts(
    skip: int = 0,
    limit: int = 100,
    camera_id: Optional[int] = None,
    event_type: Optional[str] = None,
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None,
    acknowledged: Optional[bool] = None,
    current_user: User = Depends(get_current_user),
):
    with get_db() as db:
        query = db.query(Alert)
        
        # Aplicar filtros
        if camera_id:
            query = query.filter(Alert.camera_id == camera_id)
        if event_type:
            query = query.filter(Alert.event_type == event_type)
        if start_date:
            query = query.filter(Alert.timestamp >= start_date)
        if end_date:
            query = query.filter(Alert.timestamp <= end_date)
        if acknowledged is not None:
            query = query.filter(Alert.is_acknowledged == acknowledged)
        
        # Ordenar por timestamp descendente
        query = query.order_by(Alert.timestamp.desc())
        
        # Ejecutar consulta con paginación
        alerts = query.offset(skip).limit(limit).all()
        return alerts

@app.post("/api/alerts/{alert_id}/acknowledge")
async def acknowledge_alert(
    alert_id: int,
    notes: Optional[str] = None,
    current_user: User = Depends(get_current_user),
):
    with get_db() as db:
        # Buscar alerta
        alert = db.query(Alert).filter(Alert.id == alert_id).first()
        if not alert:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Alerta con ID {alert_id} no encontrada",
            )
        
        # Actualizar alerta
        alert.is_acknowledged = True
        alert.acknowledged_by = current_user.id
        alert.acknowledged_at = datetime.utcnow()
        if notes:
            alert.notes = notes
        
        db.commit()
        
        # Notificar a través del bus de eventos
        await event_bus.publish("alert_acknowledged", {
            "alert_id": alert.id,
            "acknowledged_by": current_user.id,
            "camera_id": alert.camera_id,
        })
        
        return {"message": "Alerta confirmada correctamente"}

# Endpoint de estado del sistema
@app.get("/api/system/status")
async def get_system_status(current_user: User = Depends(get_current_user)):
    # En un sistema real, se obtendrían datos reales
    return {
        "status": "online",
        "version": config["system"]["version"],
        "uptime": "10h 23m",
        "cpu_usage": 35.2,
        "memory_usage": 42.7,
        "disk_usage": 68.4,
        "cameras_online": 5,
        "cameras_offline": 1,
        "alerts_today": 12,
        "alerts_pending": 3,
    }

# Añadir este endpoint al inicio de los endpoints
@app.get("/")
async def root():
    """Redirecciona a la documentación de la API"""
    return {
        "name": "vigIA API",
        "version": config["system"]["version"],
        "documentation": "/docs",
        "status": "online",
        "endpoints": [
            {"path": "/api/system/status", "method": "GET", "description": "Estado del sistema"},
            {"path": "/api/cameras", "method": "GET", "description": "Listar cámaras"},
            {"path": "/api/alerts", "method": "GET", "description": "Listar alertas"},
            {"path": "/token", "method": "POST", "description": "Obtener token de autenticación"}
        ]
    }

@app.post("/verify-token")
async def verify_token(authorization: str = Header(...)):
    try:
        # Extraer el token del header
        scheme, token = authorization.split()
        if scheme.lower() != 'bearer':
            return {"status": "error", "message": "Se requiere autenticación Bearer"}
        
        # Información sobre el token
        token_info = {
            "token_length": len(token),
            "token_prefix": token[:20] + "...",
        }
        
        # Intentar decodificar el token
        try:
            payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
            decoded = {
                "status": "success",
                "payload": payload,
                "user_id": payload.get("sub"),
                "username": payload.get("username"),
                "expiration": datetime.fromtimestamp(payload.get("exp")).isoformat() if "exp" in payload else None,
            }
            
            # Verificar usuario en la base de datos
            user_id = payload.get("sub")
            with get_db() as db:
                if isinstance(user_id, str) and user_id.isdigit():
                    user_id = int(user_id)
                
                user = db.query(User).filter(User.id == user_id).first()
                if user:
                    decoded["user_found"] = True
                    decoded["user_details"] = {
                        "id": user.id,
                        "username": user.username,
                        "email": user.email,
                        "is_active": user.is_active,
                    }
                else:
                    decoded["user_found"] = False
            
            return {**token_info, **decoded}
        except Exception as e:
            return {
                **token_info,
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__,
            }
    except Exception as e:
        return {"status": "error", "message": f"Error al procesar: {str(e)}"}

# Devolver la API
app = app 

if __name__ == "__main__":
    import uvicorn
    # Cambiar el puerto aquí
    uvicorn.run(app, host="0.0.0.0", port=8800) 
```

### src\api\auth.py
```py | 632 bytes | Modificado: 2025-03-15 08:39:59.230431
```
import jwt
from fastapi import Depends, HTTPException, status, WebSocket
from typing import Optional

# Variables para configuración
SECRET_KEY = "tu_clave_secreta_para_pruebas"  # Cambia esto en producción
ALGORITHM = "HS256"

async def get_current_user_ws(websocket: WebSocket) -> Optional[dict]:
    """
    Función simplificada para autenticación en WebSockets
    Para pruebas, siempre devuelve un usuario de prueba
    """
    # En modo prueba, devolvemos un usuario ficticio
    return {
        "id": 1,
        "username": "test_user",
        "email": "test@example.com",
        "role_id": 1
    } 
```

### src\api\server.py
```py | 13251 bytes | Modificado: 2025-03-06 00:51:14.304919
```
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Query
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import os
from pathlib import Path
import asyncio
import logging
from pydantic import BaseModel

# Modelos
from src.core.ml_engine.object_detection import Detection
from src.core.ml_engine.object_tracking import Track
from src.core.ml_engine.behavior_analyzer import BehaviorPattern
from src.core.event_system import Event, EventBus
from src.agent_modules.video_analytics import VideoAnalyticsAgent
from src.agent_modules.base import AgentConfig
from src.utils.logging import SecurityLogger

# Modelos de datos para la API
class EventData(BaseModel):
    event_id: str
    event_type: str
    timestamp: str
    priority: int
    data: Dict[str, Any]

class AgentStatus(BaseModel):
    agent_id: str
    agent_type: str
    status: str
    uptime: Optional[float] = None
    last_event: Optional[str] = None
    events_processed: int = 0
    config: Dict[str, Any]

class SystemStatus(BaseModel):
    status: str
    version: str
    agents: List[AgentStatus]
    total_events: int

# Configuración de la aplicación
app = FastAPI(
    title="Sistema de Videovigilancia Inteligente",
    description="API para el sistema de análisis de video con inteligencia artificial",
    version="1.0.0"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producción, específica los orígenes permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Estado del sistema
system_state = {
    "agents": {},
    "event_bus": None,
    "logger": None,
    "events": [],
    "max_events": 1000,  # Máximo de eventos a almacenar en memoria
}

# Configuración
config_path = os.environ.get("CONFIG_PATH", "config/system_config.json")

# Inicialización del sistema
@app.on_event("startup")
async def startup_event():
    # Configurar logger
    system_state["logger"] = SecurityLogger({"log_dir": "logs"})
    
    # Configurar event bus
    system_state["event_bus"] = EventBus()
    
    # Suscribirse a eventos
    system_state["event_bus"].subscribe("*", store_event)
    
    # Cargar configuración
    # TODO: Implementar carga de configuración desde archivo

async def store_event(event: Event):
    """Almacena eventos en memoria para consulta a través de la API"""
    system_state["events"].append(event)
    # Limitar la cantidad de eventos almacenados
    if len(system_state["events"]) > system_state["max_events"]:
        system_state["events"] = system_state["events"][-system_state["max_events"]:]

# Rutas de la API
@app.get("/", response_model=Dict[str, str])
async def root():
    """Punto de entrada principal de la API"""
    return {
        "name": "Sistema de Videovigilancia Inteligente",
        "version": "1.0.0",
        "status": "online"
    }

@app.get("/status", response_model=SystemStatus)
async def get_system_status():
    """Obtiene el estado actual del sistema"""
    agent_statuses = []
    
    for agent_id, agent in system_state["agents"].items():
        status = "running" if agent.running else "stopped"
        uptime = None
        if hasattr(agent, "start_time") and agent.start_time:
            uptime = (datetime.now() - agent.start_time).total_seconds()
            
        agent_statuses.append(AgentStatus(
            agent_id=agent_id,
            agent_type=agent.__class__.__name__,
            status=status,
            uptime=uptime,
            events_processed=getattr(agent, "events_processed", 0),
            config=agent.config
        ))
    
    return SystemStatus(
        status="online",
        version="1.0.0",
        agents=agent_statuses,
        total_events=len(system_state["events"])
    )

@app.get("/agents", response_model=List[AgentStatus])
async def get_agents():
    """Obtiene la lista de agentes registrados"""
    agent_statuses = []
    
    for agent_id, agent in system_state["agents"].items():
        status = "running" if agent.running else "stopped"
        uptime = None
        if hasattr(agent, "start_time") and agent.start_time:
            uptime = (datetime.now() - agent.start_time).total_seconds()
            
        agent_statuses.append(AgentStatus(
            agent_id=agent_id,
            agent_type=agent.__class__.__name__,
            status=status,
            uptime=uptime,
            events_processed=getattr(agent, "events_processed", 0),
            config=agent.config
        ))
    
    return agent_statuses

@app.post("/agents/video", response_model=Dict[str, str])
async def create_video_agent(
    background_tasks: BackgroundTasks,
    agent_id: str,
    video_source: str,
    camera_id: Optional[str] = None,
    confidence_threshold: float = 0.5
):
    """Crea un nuevo agente de análisis de video"""
    if agent_id in system_state["agents"]:
        raise HTTPException(status_code=400, detail=f"Agente con ID {agent_id} ya existe")
        
    # Configuración básica
    config = {
        "agent_id": agent_id,
        "video_source": video_source,
        "camera_id": camera_id or agent_id,
        "object_detection": {
            "model_path": "models/yolov5s.pt",
            "confidence_threshold": confidence_threshold,
            "device": "cpu"
        },
        "object_tracking": {
            "max_age": 30,
            "min_hits": 3,
            "iou_threshold": 0.3
        },
        "behavior_analysis": {
            "max_history_seconds": 30,
            "loitering_area_threshold": 5000,
            "group_distance_threshold": 100
        },
        "snapshots_dir": "data/snapshots",
        "recording": {
            "enabled": True,
            "storage_path": "data/recordings",
            "fps": 15,
            "max_duration_minutes": 10
        }
    }
    
    # Crear agente
    agent = VideoAnalyticsAgent(
        config=config,
        event_bus=system_state["event_bus"],
        logger=system_state["logger"]
    )
    
    # Registrar agente
    system_state["agents"][agent_id] = agent
    
    # Iniciar en segundo plano
    background_tasks.add_task(agent.start)
    
    return {"status": "success", "message": f"Agente {agent_id} creado y en proceso de inicialización"}

@app.post("/agents/{agent_id}/start")
async def start_agent(agent_id: str, background_tasks: BackgroundTasks):
    """Inicia un agente existente"""
    if agent_id not in system_state["agents"]:
        raise HTTPException(status_code=404, detail=f"Agente {agent_id} no encontrado")
        
    agent = system_state["agents"][agent_id]
    
    if agent.running:
        return {"status": "warning", "message": f"Agente {agent_id} ya está en ejecución"}
        
    background_tasks.add_task(agent.start)
    
    return {"status": "success", "message": f"Agente {agent_id} iniciado"}

@app.post("/agents/{agent_id}/stop")
async def stop_agent(agent_id: str):
    """Detiene un agente en ejecución"""
    if agent_id not in system_state["agents"]:
        raise HTTPException(status_code=404, detail=f"Agente {agent_id} no encontrado")
        
    agent = system_state["agents"][agent_id]
    
    if not agent.running:
        return {"status": "warning", "message": f"Agente {agent_id} ya está detenido"}
        
    await agent.stop()
    
    return {"status": "success", "message": f"Agente {agent_id} detenido"}

@app.delete("/agents/{agent_id}")
async def delete_agent(agent_id: str):
    """Elimina un agente"""
    if agent_id not in system_state["agents"]:
        raise HTTPException(status_code=404, detail=f"Agente {agent_id} no encontrado")
        
    agent = system_state["agents"][agent_id]
    
    # Detener si está en ejecución
    if agent.running:
        await agent.stop()
        
    # Eliminar de registro
    del system_state["agents"][agent_id]
    
    return {"status": "success", "message": f"Agente {agent_id} eliminado"}

@app.get("/events", response_model=List[EventData])
async def get_events(
    limit: int = Query(50, gt=0, le=1000),
    offset: int = Query(0, ge=0),
    event_type: Optional[str] = None,
    min_priority: Optional[int] = None,
    from_time: Optional[str] = None,
    to_time: Optional[str] = None
):
    """Obtiene el historial de eventos con filtros opcionales"""
    events = system_state["events"]
    
    # Aplicar filtros
    if event_type:
        events = [e for e in events if e.event_type == event_type]
        
    if min_priority is not None:
        events = [e for e in events if e.priority >= min_priority]
        
    if from_time:
        from_dt = datetime.fromisoformat(from_time)
        events = [e for e in events if datetime.fromisoformat(e.timestamp) >= from_dt]
        
    if to_time:
        to_dt = datetime.fromisoformat(to_time)
        events = [e for e in events if datetime.fromisoformat(e.timestamp) <= to_dt]
    
    # Paginación
    total = len(events)
    events = events[offset:offset + limit]
    
    # Convertir a formato de respuesta
    result = []
    for event in events:
        result.append(EventData(
            event_id=event.id,
            event_type=event.event_type,
            timestamp=event.timestamp,
            priority=event.priority,
            data=event.data
        ))
    
    return result

@app.get("/snapshots")
async def get_snapshots(
    limit: int = Query(50, gt=0, le=1000),
    offset: int = Query(0, ge=0),
    pattern_type: Optional[str] = None
):
    """Obtiene la lista de snapshots disponibles"""
    snapshots_dir = Path("data/snapshots")
    if not snapshots_dir.exists():
        return []
        
    # Listar archivos
    files = list(snapshots_dir.glob("*.jpg"))
    
    # Filtrar por tipo si se especifica
    if pattern_type:
        files = [f for f in files if pattern_type in f.stem]
        
    # Ordenar por fecha (más reciente primero)
    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    # Paginación
    files = files[offset:offset + limit]
    
    # Construir resultado
    result = []
    for file in files:
        stat = file.stat()
        result.append({
            "filename": file.name,
            "path": str(file),
            "size": stat.st_size,
            "created": datetime.fromtimestamp(stat.st_ctime).isoformat(),
            "url": f"/snapshots/{file.name}"
        })
    
    return result

@app.get("/snapshots/{filename}")
async def get_snapshot(filename: str):
    """Descarga un snapshot específico"""
    file_path = Path(f"data/snapshots/{filename}")
    
    if not file_path.exists() or file_path.suffix != ".jpg":
        raise HTTPException(status_code=404, detail="Snapshot no encontrado")
        
    return FileResponse(file_path)

@app.get("/recordings")
async def get_recordings(
    limit: int = Query(50, gt=0, le=1000),
    offset: int = Query(0, ge=0),
    camera_id: Optional[str] = None
):
    """Obtiene la lista de grabaciones disponibles"""
    recordings_dir = Path("data/recordings")
    if not recordings_dir.exists():
        return []
        
    # Listar archivos
    files = list(recordings_dir.glob("*.mp4"))
    
    # Filtrar por cámara si se especifica
    if camera_id:
        files = [f for f in files if camera_id in f.stem]
        
    # Ordenar por fecha (más reciente primero)
    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    # Paginación
    files = files[offset:offset + limit]
    
    # Construir resultado
    result = []
    for file in files:
        stat = file.stat()
        
        # Intentar cargar metadatos
        metadata = {}
        metadata_path = file.with_name(f"{file.stem}_metadata.json")
        if metadata_path.exists():
            try:
                import json
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
            except:
                pass
                
        result.append({
            "filename": file.name,
            "path": str(file),
            "size": stat.st_size,
            "created": datetime.fromtimestamp(stat.st_ctime).isoformat(),
            "url": f"/recordings/{file.name}",
            "metadata": metadata
        })
    
    return result

@app.get("/recordings/{filename}")
async def get_recording(filename: str):
    """Descarga una grabación específica"""
    file_path = Path(f"data/recordings/{filename}")
    
    if not file_path.exists() or file_path.suffix != ".mp4":
        raise HTTPException(status_code=404, detail="Grabación no encontrada")
        
    return FileResponse(file_path)

# Ejecutar la aplicación
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 
```

### src\api\surveillance_api.py
```py | 81129 bytes | Modificado: 2025-03-07 02:25:56.026365
```
"""
vigIA - Sistema de Vigilancia Inteligente con IA
Versión PMV (Proyecto MOTION_DETECTOR)

© 2025 Gustavo Mayorga. Todos los derechos reservados.

Este código es propiedad exclusiva de Gustavo Mayorga y está protegido por leyes de 
propiedad intelectual. Ninguna parte de este software puede ser reproducida, distribuida, 
o utilizada para crear trabajos derivados sin autorización explícita por escrito.

Contacto legal: gustavo.mayorga.gm@gmail.com

AVISO: El uso no autorizado de este código o sus conceptos está estrictamente prohibido
y será perseguido en la máxima medida permitida por la ley.
"""

import time
import logging
import os
import json
from flask import Flask, request, jsonify, Response, send_file
from flask_cors import CORS
import cv2
import threading
import queue
import numpy as np
from datetime import datetime, timedelta
import uuid

# Importar componentes del sistema
from src.ai.object_detector import ObjectDetector
from src.ai.behavior_analyzer import BehaviorAnalyzer
from src.storage.video_indexer import VideoIndexer
from src.storage.storage_manager import StorageManager
from src.notifications.notification_manager import NotificationManager
from src.response.active_response import ActiveResponseManager
from src.training.adaptive_learning import AdaptiveLearningSystem

# Configurar logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('SurveillanceAPI')

class SurveillanceAPI:
    """API REST para el sistema de vigilancia inteligente"""
    
    def __init__(self, config_path="configs/system.json"):
        """Inicializar API con configuración"""
        self.logger = logger
        self.config = self._load_config(config_path)
        
        # Inicializar Flask
        self.app = Flask(__name__)
        CORS(self.app)  # Habilitar CORS para frontend
        
        # Registrar rutas
        self._register_routes()
        
        # Estado del sistema
        self.cameras = {}
        self.detectors = {}
        self.analyzers = {}
        self.camera_streams = {}
        self.event_history = []
        self.active_alerts = []
        
        # Cola para eventos
        self.event_queue = queue.Queue(maxsize=100)
        
        # Inicializar componentes
        self._init_components()
        
        # Iniciar procesamiento en segundo plano
        self.running = True
        self.bg_thread = threading.Thread(target=self._background_processing)
        self.bg_thread.daemon = True
        self.bg_thread.start()
        
    def _load_config(self, config_path):
        """Cargar configuración desde archivo JSON"""
        try:
            with open(config_path, 'r') as f:
                config = json.load(f)
            return config
        except Exception as e:
            self.logger.error(f"Error al cargar configuración: {e}")
            # Usar configuración por defecto
            return {
                "api": {
                    "host": "0.0.0.0",
                    "port": 5000,
                    "debug": False
                },
                "storage": {
                    "recordings_path": "data/recordings",
                    "database_path": "data/surveillance.db",
                    "s3_enabled": False
                },
                "ai": {
                    "default_detector": "tensorflow",
                    "default_models_path": "models",
                    "batch_processing": True
                },
                "notifications": {
                    "email_enabled": False,
                    "sms_enabled": False,
                    "push_enabled": False
                },
                "cameras": {}
            }
            
    def _init_components(self):
        """Inicializar componentes del sistema"""
        try:
            # Inicializar gestor de almacenamiento
            storage_config = self.config.get("storage", {})
            self.storage_manager = StorageManager(storage_config)
            
            # Inicializar indexador de videos
            self.video_indexer = VideoIndexer(
                db_path=storage_config.get("database_path", "data/surveillance.db")
            )
            self.storage_manager.video_indexer = self.video_indexer
            
            # Inicializar gestor de notificaciones
            notification_config = self.config.get("notifications", {})
            self.notification_manager = NotificationManager(notification_config)
            
            # Inicializar gestor de respuestas activas
            response_config = self.config.get("responses", {})
            self.response_manager = ActiveResponseManager(response_config)
            
            # Inicializar cámaras configuradas
            self._init_cameras()
            
            # Inicializar sistema de aprendizaje adaptativo
            learning_config = self.config.get("learning", {})
            if not learning_config.get("client_id"):
                learning_config["client_id"] = "client_" + str(uuid.uuid4())[:8]
            self.learning_system = AdaptiveLearningSystem(learning_config)
            
            self.logger.info("Componentes del sistema inicializados correctamente")
            
        except Exception as e:
            self.logger.error(f"Error al inicializar componentes: {e}")
            raise
            
    def _init_cameras(self):
        """Inicializar cámaras configuradas"""
        cameras_config = self.config.get("cameras", {})
        
        for camera_id, camera_config in cameras_config.items():
            try:
                # Registrar cámara
                self.cameras[camera_id] = {
                    "id": camera_id,
                    "name": camera_config.get("name", f"Camera {camera_id}"),
                    "url": camera_config.get("url", ""),
                    "type": camera_config.get("type", "rtsp"),
                    "location": camera_config.get("location", ""),
                    "status": "offline",
                    "last_error": None,
                    "frame_count": 0,
                    "resolution": camera_config.get("resolution", "640x480"),
                    "fps": camera_config.get("fps", 10),
                    "recording": camera_config.get("auto_record", False),
                    "alerts_enabled": camera_config.get("alerts_enabled", True)
                }
                
                # Inicializar detector para esta cámara
                detector_config = camera_config.get("detector", {})
                if not detector_config:
                    # Usar configuración por defecto
                    ai_config = self.config.get("ai", {})
                    detector_config = {
                        "model_type": ai_config.get("default_detector", "tensorflow"),
                        "model_path": os.path.join(
                            ai_config.get("default_models_path", "models"),
                            "ssd_mobilenet_v2_coco"
                        ),
                        "confidence_threshold": 0.5,
                        "classes_of_interest": ["person", "car", "truck"]
                    }
                    
                self.detectors[camera_id] = ObjectDetector(detector_config)
                
                # Inicializar analizador de comportamiento
                analyzer_config = camera_config.get("analyzer", {})
                self.analyzers[camera_id] = BehaviorAnalyzer(analyzer_config)
                
                self.logger.info(f"Cámara {camera_id} ({self.cameras[camera_id]['name']}) inicializada")
                
            except Exception as e:
                self.logger.error(f"Error al inicializar cámara {camera_id}: {e}")
                
    def _register_routes(self):
        """Registrar rutas de la API REST"""
        
        # Rutas de estado del sistema
        self.app.route('/api/status')(self.get_system_status)
        
        # Rutas de cámaras
        self.app.route('/api/cameras')(self.get_cameras)
        self.app.route('/api/cameras/<camera_id>')(self.get_camera)
        self.app.route('/api/cameras/<camera_id>', methods=['PUT'])(self.update_camera)
        self.app.route('/api/cameras/<camera_id>/stream')(self.get_camera_stream)
        self.app.route('/api/cameras/<camera_id>/snapshot')(self.get_camera_snapshot)
        self.app.route('/api/cameras/<camera_id>/start_recording', methods=['POST'])(self.start_recording)
        self.app.route('/api/cameras/<camera_id>/stop_recording', methods=['POST'])(self.stop_recording)
        
        # Rutas de alertas y eventos
        self.app.route('/api/alerts')(self.get_alerts)
        self.app.route('/api/alerts/<alert_id>')(self.get_alert)
        self.app.route('/api/alerts/<alert_id>/acknowledge', methods=['POST'])(self.acknowledge_alert)
        self.app.route('/api/events')(self.get_events)
        
        # Rutas de grabaciones
        self.app.route('/api/recordings')(self.get_recordings)
        self.app.route('/api/recordings/<recording_id>')(self.get_recording)
        self.app.route('/api/recordings/<recording_id>/download')(self.download_recording)
        self.app.route('/api/recordings/<recording_id>', methods=['DELETE'])(self.delete_recording)
        
        # Rutas de configuración
        self.app.route('/api/config')(self.get_config)
        self.app.route('/api/config', methods=['PUT'])(self.update_config)
        self.app.route('/api/config/<section>')(self.get_config_section)
        self.app.route('/api/config/<section>', methods=['PUT'])(self.update_config_section)
        
        # Rutas de analítica
        self.app.route('/api/stats')(self.get_statistics)
        self.app.route('/api/stats/<stat_type>')(self.get_specific_statistics)
        
        # Ruta de gestión de zonas
        self.app.route('/api/cameras/<camera_id>/zones')(self.get_zones)
        self.app.route('/api/cameras/<camera_id>/zones', methods=['POST'])(self.create_zone)
        self.app.route('/api/cameras/<camera_id>/zones/<zone_id>', methods=['PUT'])(self.update_zone)
        self.app.route('/api/cameras/<camera_id>/zones/<zone_id>', methods=['DELETE'])(self.delete_zone)
        
        # Rutas para sistema de aprendizaje adaptativo
        self.app.route('/api/learning/status')(self.get_learning_status)
        self.app.route('/api/learning/train', methods=['POST'])(self.train_models)
        self.app.route('/api/learning/parameters')(self.get_optimized_parameters)
        self.app.route('/api/learning/simulation', methods=['POST'])(self.run_simulation)
        self.app.route('/api/learning/feedback/<event_id>', methods=['POST'])(self.register_feedback)
        
        # Rutas para reconocimiento facial
        self.app.route('/api/faces')(self.get_registered_faces)
        self.app.route('/api/faces/<person_id>')(self.get_person_info)
        self.app.route('/api/faces/<person_id>', methods=['DELETE'])(self.delete_person)
        self.app.route('/api/faces/<person_id>', methods=['PUT'])(self.update_person_info)
        self.app.route('/api/faces/register', methods=['POST'])(self.register_face)
        self.app.route('/api/cameras/<camera_id>/detect_faces')(self.detect_faces_in_camera)
        self.app.route('/api/faces/watchlist', methods=['GET'])(self.get_watchlist)
        self.app.route('/api/faces/<person_id>/watchlist', methods=['POST'])(self.add_to_watchlist)
        self.app.route('/api/faces/<person_id>/watchlist', methods=['DELETE'])(self.remove_from_watchlist)
        
    def _background_processing(self):
        """Procesamiento en segundo plano para detección y análisis"""
        self.logger.info("Iniciando hilo de procesamiento en segundo plano")
        
        while self.running:
            # Procesar cámaras activas
            for camera_id, camera_info in self.cameras.items():
                try:
                    # Solo procesar cámaras activas
                    if camera_info.get("status") != "online":
                        continue
                    
                    # Obtener stream de la cámara
                    stream = self.camera_streams.get(camera_id)
                    if not stream or not stream.get("cap"):
                        continue
                    
                    cap = stream.get("cap")
                    ret, frame = cap.read()
                    
                    if not ret or frame is None:
                        # Error al leer frame
                        self.logger.warning(f"Error al leer frame de la cámara {camera_id}")
                        continue
                    
                    # Incrementar contador de frames
                    camera_info["frame_count"] += 1
                    
                    # Decidir si procesar este frame (reducir carga)
                    frame_count = camera_info["frame_count"]
                    if frame_count % 5 != 0:  # Procesar cada 5 frames
                        continue
                    
                    # Detectar objetos
                    detector = self.detectors.get(camera_id)
                    if detector:
                        detections = detector.detect(frame)
                        
                        # Analizar comportamiento
                        analyzer = self.analyzers.get(camera_id)
                        if analyzer and detections:
                            events, annotated_frame = analyzer.process_frame(frame, detections)
                            
                            # Procesar eventos detectados
                            if events:
                                for event in events:
                                    self._process_event(camera_id, event, frame)
                    
                    # Grabar si está en modo grabación
                    if camera_info.get("recording"):
                        self._record_frame(camera_id, frame)
                        
                except Exception as e:
                    self.logger.error(f"Error en procesamiento de cámara {camera_id}: {e}")
            
            # Pequeña pausa para evitar consumo excesivo de CPU
            time.sleep(0.01)
    
    def _process_event(self, camera_id, event, frame):
        """Procesar un evento detectado"""
        # Generar ID único para el evento
        event_id = str(uuid.uuid4())
        
        # Enriquecer evento con metadatos
        event_data = {
            "id": event_id,
            "camera_id": camera_id,
            "camera_name": self.cameras[camera_id]["name"],
            "timestamp": datetime.now().isoformat(),
            "type": event["type"],
            "confidence": event.get("confidence", 1.0),
            "details": event,
            "status": "new"
        }
        
        # Guardar snapshot del evento
        snapshot_path = self._save_event_snapshot(camera_id, event_id, frame, event)
        if snapshot_path:
            event_data["snapshot"] = snapshot_path
        
        # Agregar a historial
        self.event_history.append(event_data)
        
        # Si es una alerta activa
        if event["type"] in ["intrusion", "tailgating", "abandoned_object"]:
            self.active_alerts.append(event_data)
            
            # Enviar notificación
            self._send_alert_notification(event_data)
            
        # Si es una alerta activa que requiere respuesta inmediata
        if event["type"] in ["intrusion", "tailgating"] and \
           self.config.get("responses", {}).get("auto_respond", False):
            # Enviar advertencia por altavoz
            self.response_manager.queue_audio_warning(
                message=None,  # Usar mensaje predeterminado
                event_data=event_data,
                device=self.cameras[camera_id].get("speaker_device", "default")
            )
        
        # Poner en cola para WebSocket
        try:
            self.event_queue.put_nowait(event_data)
        except queue.Full:
            # Si la cola está llena, eliminar el evento más antiguo
            try:
                self.event_queue.get_nowait()
                self.event_queue.put_nowait(event_data)
            except:
                pass
        
        # Registrar evento para aprendizaje
        self.learning_system.register_event(event_data)
    
    def _save_event_snapshot(self, camera_id, event_id, frame, event):
        """Guardar imagen del evento"""
        try:
            # Crear directorio si no existe
            snapshots_dir = os.path.join(
                self.config["storage"].get("recordings_path", "data/recordings"),
                "snapshots"
            )
            os.makedirs(snapshots_dir, exist_ok=True)
            
            # Construir ruta del archivo
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{camera_id}_{event['type']}_{timestamp}_{event_id[:8]}.jpg"
            filepath = os.path.join(snapshots_dir, filename)
            
            # Guardar imagen
            cv2.imwrite(filepath, frame)
            
            return filepath
        except Exception as e:
            self.logger.error(f"Error al guardar snapshot de evento: {e}")
            return None
    
    def _send_alert_notification(self, alert_data):
        """Enviar notificación de alerta"""
        try:
            # Preparar mensaje
            camera_name = alert_data["camera_name"]
            alert_type = alert_data["type"]
            timestamp = datetime.fromisoformat(alert_data["timestamp"]).strftime("%H:%M:%S")
            
            subject = f"Alerta de seguridad: {alert_type.upper()} detectado"
            message = (
                f"Se ha detectado un evento de {alert_type} en la cámara {camera_name} "
                f"a las {timestamp}.\n\n"
                f"ID de alerta: {alert_data['id']}\n"
                f"Confianza: {alert_data['confidence']:.2f}"
            )
            
            # Añadir detalles específicos según tipo
            if alert_type == "intrusion":
                zone = alert_data["details"].get("zone", "desconocida")
                message += f"\nZona de intrusión: {zone}"
            elif alert_type == "tailgating":
                message += "\nPosible acceso no autorizado por seguimiento."
            
            # Enviar notificación
            self.notification_manager.send_alert(
                subject=subject,
                message=message,
                priority="high",
                attachment=alert_data.get("snapshot"),
                metadata=alert_data
            )
            
        except Exception as e:
            self.logger.error(f"Error al enviar notificación: {e}")
    
    def _record_frame(self, camera_id, frame):
        """Guardar frame para grabación"""
        try:
            camera_stream = self.camera_streams.get(camera_id, {})
            recorder = camera_stream.get("recorder")
            
            if recorder and hasattr(recorder, "write"):
                recorder.write(frame)
            
        except Exception as e:
            self.logger.error(f"Error al grabar frame: {e}")
    
    # Métodos de la API REST
    
    def get_system_status(self):
        """Obtener estado general del sistema"""
        try:
            # Recopilar estadísticas
            camera_count = len(self.cameras)
            online_cameras = sum(1 for c in self.cameras.values() if c.get("status") == "online")
            active_alerts = len(self.active_alerts)
            
            disk_usage = self.storage_manager.get_storage_usage()
            
            # Estado general
            status = {
                "status": "operational" if online_cameras > 0 else "degraded",
                "timestamp": datetime.now().isoformat(),
                "version": "1.0.0",  # Versión del sistema
                "statistics": {
                    "cameras": {
                        "total": camera_count,
                        "online": online_cameras,
                        "offline": camera_count - online_cameras
                    },
                    "alerts": {
                        "active": active_alerts,
                        "total": len(self.event_history)
                    },
                    "storage": disk_usage
                }
            }
            
            return jsonify(status)
        except Exception as e:
            self.logger.error(f"Error al obtener estado del sistema: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_cameras(self):
        """Obtener lista de cámaras"""
        try:
            # Filtrar información sensible como URLs internas
            cameras_info = []
            for camera_id, camera in self.cameras.items():
                cameras_info.append({
                    "id": camera_id,
                    "name": camera.get("name", ""),
                    "location": camera.get("location", ""),
                    "status": camera.get("status", "offline"),
                    "recording": camera.get("recording", False),
                    "alerts_enabled": camera.get("alerts_enabled", True),
                    "resolution": camera.get("resolution", ""),
                    "frame_count": camera.get("frame_count", 0)
                })
            
            return jsonify(cameras_info)
        except Exception as e:
            self.logger.error(f"Error al obtener lista de cámaras: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_camera(self, camera_id):
        """Obtener información de una cámara específica"""
        try:
            if camera_id not in self.cameras:
                return jsonify({"error": "Cámara no encontrada"}), 404
            
            camera = self.cameras[camera_id]
            
            # Incluir estadísticas específicas
            camera_stats = {
                "id": camera_id,
                "name": camera.get("name", ""),
                "location": camera.get("location", ""),
                "status": camera.get("status", "offline"),
                "type": camera.get("type", "rtsp"),
                "resolution": camera.get("resolution", ""),
                "fps": camera.get("fps", 0),
                "recording": camera.get("recording", False),
                "alerts_enabled": camera.get("alerts_enabled", True),
                "frame_count": camera.get("frame_count", 0),
                "uptime": camera.get("uptime", 0),
                "last_error": camera.get("last_error")
            }
            
            # Si hay analizador, incluir zona y conteos
            analyzer = self.analyzers.get(camera_id)
            if analyzer:
                camera_stats["zones"] = list(analyzer.config.get("zones", {}).keys())
                camera_stats["object_counts"] = {
                    "person": analyzer.get_object_count("person"),
                    "vehicle": analyzer.get_object_count(["car", "truck", "bus"]),
                    "total": analyzer.get_object_count()
                }
                camera_stats["zone_counts"] = analyzer.get_zone_counts()
            
            return jsonify(camera_stats)
        except Exception as e:
            self.logger.error(f"Error al obtener información de cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def update_camera(self, camera_id):
        """Actualizar configuración de una cámara"""
        try:
            if camera_id not in self.cameras:
                return jsonify({"error": "Cámara no encontrada"}), 404
            
            # Obtener datos del request
            data = request.json
            if not data:
                return jsonify({"error": "Datos no válidos"}), 400
            
            # Campos permitidos para actualizar
            allowed_fields = [
                "name", "location", "alerts_enabled", "fps", 
                "resolution", "type", "url"
            ]
            
            # Actualizar campos permitidos
            for field in allowed_fields:
                if field in data:
                    self.cameras[camera_id][field] = data[field]
            
            # Si se actualiza la URL, reiniciar conexión
            if "url" in data:
                self._reconnect_camera(camera_id)
                
            # Guardar configuración actualizada
            self._save_config()
            
            return jsonify({"status": "success", "message": "Cámara actualizada correctamente"})
        
        except Exception as e:
            self.logger.error(f"Error al actualizar cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def _reconnect_camera(self, camera_id):
        """Reconectar a una cámara (cerrar y abrir stream)"""
        try:
            # Cerrar stream si existe
            if camera_id in self.camera_streams:
                stream_info = self.camera_streams[camera_id]
                if "cap" in stream_info and stream_info["cap"]:
                    stream_info["cap"].release()
                
                if "recorder" in stream_info and stream_info["recorder"]:
                    stream_info["recorder"].release()
                    
                del self.camera_streams[camera_id]
            
            # Marcar como offline
            self.cameras[camera_id]["status"] = "connecting"
            
            # Iniciar nuevo stream
            self._connect_camera(camera_id)
            
        except Exception as e:
            self.logger.error(f"Error al reconectar cámara {camera_id}: {e}")
            self.cameras[camera_id]["status"] = "error"
            self.cameras[camera_id]["last_error"] = str(e)
    
    def _connect_camera(self, camera_id):
        """Conectar a una cámara y abrir stream"""
        try:
            camera = self.cameras[camera_id]
            url = camera.get("url", "")
            
            if not url:
                self.logger.error(f"URL no especificada para cámara {camera_id}")
                camera["status"] = "error"
                camera["last_error"] = "URL no especificada"
                return False
                
            # Crear thread para conexión (evitar bloqueo)
            thread = threading.Thread(
                target=self._camera_connection_thread,
                args=(camera_id, url)
            )
            thread.daemon = True
            thread.start()
            
            return True
            
        except Exception as e:
            self.logger.error(f"Error al conectar con cámara {camera_id}: {e}")
            self.cameras[camera_id]["status"] = "error"
            self.cameras[camera_id]["last_error"] = str(e)
            return False
    
    def _camera_connection_thread(self, camera_id, url):
        """Thread para conectar a cámara sin bloquear"""
        try:
            # Determinar fuente (URL o número de cámara)
            if url.isdigit():
                # Cámara local
                source = int(url)
            else:
                # URL de cámara
                source = url
                
            # Intentar abrir la cámara
            cap = cv2.VideoCapture(source)
            
            if not cap.isOpened():
                raise Exception("No se pudo abrir la cámara")
                
            # Configurar parámetros
            camera = self.cameras[camera_id]
            
            # Establecer resolución si está especificada
            resolution = camera.get("resolution", "")
            if resolution:
                try:
                    width, height = map(int, resolution.split("x"))
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
                except:
                    self.logger.warning(f"Formato de resolución inválido: {resolution}")
                    
            # Establecer FPS si está especificado
            fps = camera.get("fps", 0)
            if fps > 0:
                cap.set(cv2.CAP_PROP_FPS, fps)
                
            # Leer frame para verificar conexión
            ret, frame = cap.read()
            if not ret:
                raise Exception("No se pudo leer frame de la cámara")
                
            # Guardar resolución real
            real_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            real_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            camera["resolution"] = f"{real_width}x{real_height}"
            
            # Guardar FPS real
            real_fps = cap.get(cv2.CAP_PROP_FPS)
            camera["fps"] = real_fps
                
            # Guardar stream
            self.camera_streams[camera_id] = {
                "cap": cap,
                "recorder": None,
                "last_frame": frame,
                "last_updated": time.time()
            }
            
            # Actualizar estado
            camera["status"] = "online"
            camera["last_error"] = None
            camera["connected_at"] = time.time()
            
            self.logger.info(f"Cámara {camera_id} conectada correctamente ({real_width}x{real_height} @ {real_fps}fps)")
            
            # Iniciar grabación si está configurada
            if camera.get("auto_record", False):
                self.start_recording(camera_id)
                
        except Exception as e:
            self.logger.error(f"Error al conectar con cámara {camera_id}: {e}")
            self.cameras[camera_id]["status"] = "error"
            self.cameras[camera_id]["last_error"] = str(e)
    
    def get_camera_stream(self, camera_id):
        """Obtener stream MJPEG de una cámara"""
        if camera_id not in self.cameras:
            return jsonify({"error": "Cámara no encontrada"}), 404
            
        if self.cameras[camera_id].get("status") != "online":
            return jsonify({"error": "Cámara no disponible"}), 503
            
        # Stream MJPEG
        return Response(
            self._generate_camera_stream(camera_id),
            mimetype='multipart/x-mixed-replace; boundary=frame'
        )
        
    def _generate_camera_stream(self, camera_id):
        """Generador para stream MJPEG"""
        try:
            while True:
                # Obtener stream
                stream = self.camera_streams.get(camera_id)
                if not stream:
                    yield (b'--frame\r\n'
                          b'Content-Type: text/plain\r\n\r\n'
                          b'Camera Offline\r\n\r\n')
                    time.sleep(1)
                    continue
                
                # Obtener último frame o leer nuevo
                if time.time() - stream.get("last_updated", 0) > 0.1:
                    # Leer nuevo frame
                    cap = stream.get("cap")
                    if not cap:
                        yield (b'--frame\r\n'
                              b'Content-Type: text/plain\r\n\r\n'
                              b'Camera Offline\r\n\r\n')
                        time.sleep(1)
                        continue
                        
                    ret, frame = cap.read()
                    if not ret:
                        yield (b'--frame\r\n'
                              b'Content-Type: text/plain\r\n\r\n'
                              b'Error reading frame\r\n\r\n')
                        time.sleep(1)
                        continue
                        
                    # Actualizar último frame
                    stream["last_frame"] = frame
                    stream["last_updated"] = time.time()
                else:
                    # Usar último frame
                    frame = stream.get("last_frame")
                    if frame is None:
                        yield (b'--frame\r\n'
                              b'Content-Type: text/plain\r\n\r\n'
                              b'No frame available\r\n\r\n')
                        time.sleep(1)
                        continue
                
                # Redimensionar para stream (opcional)
                # frame = cv2.resize(frame, (640, 480))
                
                # Convertir a JPG
                ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                jpg_bytes = buffer.tobytes()
                
                # Enviar frame
                yield (b'--frame\r\n'
                      b'Content-Type: image/jpeg\r\n\r\n' + jpg_bytes + b'\r\n')
                
                # Pausa para controlar FPS del stream
                time.sleep(0.03)  # ~30fps
                
        except GeneratorExit:
            # Cliente cerró la conexión
            pass
        except Exception as e:
            self.logger.error(f"Error en stream de cámara {camera_id}: {e}")
            yield (b'--frame\r\n'
                  b'Content-Type: text/plain\r\n\r\n'
                  f'Error: {str(e)}\r\n\r\n'.encode())
    
    def get_camera_snapshot(self, camera_id):
        """Obtener snapshot/imagen actual de una cámara"""
        if camera_id not in self.cameras:
            return jsonify({"error": "Cámara no encontrada"}), 404
            
        if self.cameras[camera_id].get("status") != "online":
            return jsonify({"error": "Cámara no disponible"}), 503
            
        try:
            # Obtener stream
            stream = self.camera_streams.get(camera_id)
            if not stream:
                return jsonify({"error": "Stream no disponible"}), 503
                
            # Obtener último frame o leer nuevo
            if time.time() - stream.get("last_updated", 0) > 0.5:
                # Leer nuevo frame
                cap = stream.get("cap")
                if not cap:
                    return jsonify({"error": "Cámara no disponible"}), 503
                    
                ret, frame = cap.read()
                if not ret:
                    return jsonify({"error": "Error al leer frame"}), 500
                    
                # Actualizar último frame
                stream["last_frame"] = frame
                stream["last_updated"] = time.time()
            else:
                # Usar último frame
                frame = stream.get("last_frame")
                if frame is None:
                    return jsonify({"error": "Frame no disponible"}), 500
            
            # Convertir a JPG
            ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
            jpg_bytes = buffer.tobytes()
            
            # Devolver imagen
            return Response(jpg_bytes, mimetype='image/jpeg')
            
        except Exception as e:
            self.logger.error(f"Error al obtener snapshot de cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def start_recording(self, camera_id):
        """Iniciar grabación de una cámara"""
        if camera_id not in self.cameras:
            return jsonify({"error": "Cámara no encontrada"}), 404
            
        if self.cameras[camera_id].get("status") != "online":
            return jsonify({"error": "Cámara no disponible"}), 503
            
        try:
            # Verificar si ya está grabando
            if self.cameras[camera_id].get("recording", False):
                return jsonify({"status": "success", "message": "La cámara ya está grabando"})
                
            # Obtener stream
            stream = self.camera_streams.get(camera_id)
            if not stream or not stream.get("cap"):
                return jsonify({"error": "Stream no disponible"}), 503
                
            # Crear directorio para grabaciones
            recordings_dir = os.path.join(
                self.config["storage"].get("recordings_path", "data/recordings"),
                camera_id
            )
            os.makedirs(recordings_dir, exist_ok=True)
            
            # Nombre de archivo con timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{camera_id}_{timestamp}.mp4"
            filepath = os.path.join(recordings_dir, filename)
            
            # Obtener fps y resolución
            cap = stream.get("cap")
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            if fps == 0:
                fps = 30  # Valor por defecto
                
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # Crear objeto de grabación
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            recorder = cv2.VideoWriter(filepath, fourcc, fps, (width, height))
            
            if not recorder.isOpened():
                return jsonify({"error": "No se pudo crear grabación"}), 500
                
            # Guardar referencia
            stream["recorder"] = recorder
            stream["recording_start"] = time.time()
            stream["recording_file"] = filepath
            
            # Actualizar estado
            self.cameras[camera_id]["recording"] = True
            self.cameras[camera_id]["current_recording"] = {
                "id": timestamp,
                "filename": filename,
                "filepath": filepath,
                "start_time": datetime.now().isoformat()
            }
            
            # Registrar en indexador
            recording_id = self.video_indexer.register_recording(
                camera_id=camera_id,
                filepath=filepath,
                timestamp=datetime.now(),
                duration=0,  # Se actualizará al finalizar
                metadata={
                    "resolution": f"{width}x{height}",
                    "fps": fps,
                    "size": 0  # Se actualizará al finalizar
                }
            )
            
            stream["recording_id"] = recording_id
            
            self.logger.info(f"Iniciada grabación de cámara {camera_id}: {filepath}")
            
            return jsonify({
                "status": "success", 
                "message": "Grabación iniciada",
                "recording_id": timestamp,
                "file": filename
            })
            
        except Exception as e:
            self.logger.error(f"Error al iniciar grabación de cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def stop_recording(self, camera_id):
        """Detener grabación de una cámara"""
        if camera_id not in self.cameras:
            return jsonify({"error": "Cámara no encontrada"}), 404
            
        try:
            # Verificar si está grabando
            if not self.cameras[camera_id].get("recording", False):
                return jsonify({"status": "success", "message": "La cámara no está grabando"})
                
            # Obtener stream
            stream = self.camera_streams.get(camera_id)
            if not stream:
                return jsonify({"error": "Stream no disponible"}), 503
                
            # Obtener grabadora
            recorder = stream.get("recorder")
            if recorder:
                # Liberar grabadora
                recorder.release()
                
                # Actualizar metadatos en indexador
                recording_id = stream.get("recording_id")
                if recording_id:
                    filepath = stream.get("recording_file", "")
                    if os.path.exists(filepath):
                        # Calcular duración y tamaño
                        duration = time.time() - stream.get("recording_start", time.time())
                        size = os.path.getsize(filepath)
                        
                        # Actualizar en indexador
                        self.video_indexer.update_recording(
                            recording_id=recording_id,
                            duration=duration,
                            metadata={
                                "size": size
                            }
                        )
                
            # Limpiar referencias
            stream["recorder"] = None
            stream["recording_start"] = None
            stream["recording_file"] = None
            stream["recording_id"] = None
            
            # Actualizar estado
            current_recording = self.cameras[camera_id].get("current_recording", {})
            self.cameras[camera_id]["recording"] = False
            self.cameras[camera_id]["current_recording"] = None
            
            self.logger.info(f"Detenida grabación de cámara {camera_id}")
            
            return jsonify({
                "status": "success", 
                "message": "Grabación detenida",
                "recording": current_recording
            })
            
        except Exception as e:
            self.logger.error(f"Error al detener grabación de cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_alerts(self):
        """Obtener lista de alertas activas"""
        try:
            # Obtener parámetros de filtrado
            status = request.args.get('status', 'active')
            limit = int(request.args.get('limit', 100))
            offset = int(request.args.get('offset', 0))
            
            # Filtrar alertas según estado
            if status == 'active':
                alerts = self.active_alerts
            elif status == 'all':
                alerts = self.event_history
            else:
                alerts = [a for a in self.event_history if a.get("status") == status]
                
            # Ordenar por timestamp (más reciente primero)
            sorted_alerts = sorted(
                alerts, 
                key=lambda a: a.get("timestamp", ""), 
                reverse=True
            )
            
            # Aplicar paginación
            paginated = sorted_alerts[offset:offset+limit]
            
            # Formato para respuesta
            result = {
                "total": len(sorted_alerts),
                "limit": limit,
                "offset": offset,
                "alerts": paginated
            }
            
            return jsonify(result)
            
        except Exception as e:
            self.logger.error(f"Error al obtener alertas: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_alert(self, alert_id):
        """Obtener detalles de una alerta específica"""
        try:
            # Buscar alerta por ID
            for alert in self.event_history:
                if alert.get("id") == alert_id:
                    return jsonify(alert)
                    
            return jsonify({"error": "Alerta no encontrada"}), 404
            
        except Exception as e:
            self.logger.error(f"Error al obtener alerta {alert_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def acknowledge_alert(self, alert_id):
        """Marcar una alerta como atendida"""
        try:
            # Buscar alerta en activas
            for i, alert in enumerate(self.active_alerts):
                if alert.get("id") == alert_id:
                    # Marcar como atendida
                    self.active_alerts[i]["status"] = "acknowledged"
                    
                    # Actualizar también en historial
                    for event in self.event_history:
                        if event.get("id") == alert_id:
                            event["status"] = "acknowledged"
                            event["acknowledged_at"] = datetime.now().isoformat()
                    
                    return jsonify({
                        "status": "success",
                        "message": "Alerta marcada como atendida"
                    })
            
            return jsonify({"error": "Alerta no encontrada"}), 404
            
        except Exception as e:
            self.logger.error(f"Error al marcar alerta {alert_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_events(self):
        """Obtener historial de eventos"""
        try:
            # Obtener parámetros de filtrado
            event_type = request.args.get('type')
            camera_id = request.args.get('camera')
            from_date = request.args.get('from')
            to_date = request.args.get('to')
            limit = int(request.args.get('limit', 100))
            offset = int(request.args.get('offset', 0))
            
            # Lista base de eventos
            events = self.event_history.copy()
            
            # Aplicar filtros
            if event_type:
                events = [e for e in events if e.get("type") == event_type]
                
            if camera_id:
                events = [e for e in events if e.get("camera_id") == camera_id]
                
            if from_date:
                try:
                    from_dt = datetime.fromisoformat(from_date)
                    events = [e for e in events if datetime.fromisoformat(e.get("timestamp", "")) >= from_dt]
                except:
                    pass
                    
            if to_date:
                try:
                    to_dt = datetime.fromisoformat(to_date)
                    events = [e for e in events if datetime.fromisoformat(e.get("timestamp", "")) <= to_dt]
                except:
                    pass
            
            # Ordenar por timestamp (más reciente primero)
            sorted_events = sorted(
                events, 
                key=lambda e: e.get("timestamp", ""), 
                reverse=True
            )
            
            # Aplicar paginación
            paginated = sorted_events[offset:offset+limit]
            
            # Formato para respuesta
            result = {
                "total": len(sorted_events),
                "limit": limit,
                "offset": offset,
                "events": paginated
            }
            
            return jsonify(result)
            
        except Exception as e:
            self.logger.error(f"Error al obtener eventos: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_recordings(self):
        """Obtener lista de grabaciones"""
        try:
            # Obtener parámetros de filtrado
            camera_id = request.args.get('camera')
            from_date = request.args.get('from')
            to_date = request.args.get('to')
            limit = int(request.args.get('limit', 100))
            offset = int(request.args.get('offset', 0))
            
            # Consultar indexador
            recordings = self.video_indexer.get_recordings(
                camera_id=camera_id,
                from_date=from_date,
                to_date=to_date,
                limit=limit,
                offset=offset
            )
            
            return jsonify(recordings)
            
        except Exception as e:
            self.logger.error(f"Error al obtener grabaciones: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_recording(self, recording_id):
        """Obtener detalles de una grabación específica"""
        try:
            # Consultar indexador
            recording = self.video_indexer.get_recording(recording_id)
            
            if not recording:
                return jsonify({"error": "Grabación no encontrada"}), 404
                
            return jsonify(recording)
            
        except Exception as e:
            self.logger.error(f"Error al obtener grabación {recording_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def download_recording(self, recording_id):
        """Descargar archivo de grabación"""
        try:
            # Consultar indexador
            recording = self.video_indexer.get_recording(recording_id)
            
            if not recording:
                return jsonify({"error": "Grabación no encontrada"}), 404
                
            filepath = recording.get("filepath")
            
            if not filepath or not os.path.exists(filepath):
                return jsonify({"error": "Archivo no encontrado"}), 404
                
            return send_file(
                filepath,
                as_attachment=True,
                attachment_filename=os.path.basename(filepath),
                mimetype='video/mp4'
            )
            
        except Exception as e:
            self.logger.error(f"Error al descargar grabación {recording_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def delete_recording(self, recording_id):
        """Eliminar una grabación"""
        try:
            # Consultar indexador
            recording = self.video_indexer.get_recording(recording_id)
            
            if not recording:
                return jsonify({"error": "Grabación no encontrada"}), 404
                
            filepath = recording.get("filepath")
            
            # Intentar eliminar archivo
            if filepath and os.path.exists(filepath):
                os.remove(filepath)
                
            # Eliminar del indexador
            self.video_indexer.delete_recording(recording_id)
            
            return jsonify({
                "status": "success",
                "message": "Grabación eliminada correctamente"
            })
            
        except Exception as e:
            self.logger.error(f"Error al eliminar grabación {recording_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_config(self):
        """Obtener configuración completa del sistema"""
        try:
            # Excluir información sensible
            filtered_config = self.config.copy()
            
            # Filtrar URLs y credenciales de cámaras
            if "cameras" in filtered_config:
                for camera_id, camera in filtered_config["cameras"].items():
                    if "password" in camera:
                        camera["password"] = "********"
            
            # Filtrar credenciales de almacenamiento
            if "storage" in filtered_config and "s3" in filtered_config["storage"]:
                s3_config = filtered_config["storage"]["s3"]
                if "secret_key" in s3_config:
                    s3_config["secret_key"] = "********"
            
            # Filtrar credenciales de notificaciones
            if "notifications" in filtered_config:
                notif_config = filtered_config["notifications"]
                for provider in ["email", "sms", "push"]:
                    if provider in notif_config and "password" in notif_config[provider]:
                        notif_config[provider]["password"] = "********"
            
            return jsonify(filtered_config)
            
        except Exception as e:
            self.logger.error(f"Error al obtener configuración: {e}")
            return jsonify({"error": str(e)}), 500
    
    def update_config(self):
        """Actualizar configuración completa del sistema"""
        try:
            # Verificar permisos (aquí se podría implementar autenticación)
            
            # Obtener datos
            data = request.json
            if not data:
                return jsonify({"error": "Datos no válidos"}), 400
                
            # Hacer backup de configuración actual
            backup_config = self.config.copy()
            
            # Actualizar configuración
            self.config.update(data)
            
            # Guardar cambios
            if not self._save_config():
                # Restaurar backup si hay error
                self.config = backup_config
                return jsonify({"error": "Error al guardar configuración"}), 500
                
            # Reiniciar componentes afectados
            self._reinitialize_components()
            
            return jsonify({
                "status": "success",
                "message": "Configuración actualizada correctamente"
            })
            
        except Exception as e:
            self.logger.error(f"Error al actualizar configuración: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_config_section(self, section):
        """Obtener una sección específica de la configuración"""
        try:
            if section not in self.config:
                return jsonify({"error": f"Sección {section} no encontrada"}), 404
                
            # Filtrar información sensible
            filtered_section = self.config[section].copy()
            
            # Filtrar según sección
            if section == "cameras":
                for camera_id, camera in filtered_section.items():
                    if "password" in camera:
                        camera["password"] = "********"
            elif section == "storage" and "s3" in filtered_section:
                if "secret_key" in filtered_section["s3"]:
                    filtered_section["s3"]["secret_key"] = "********"
            elif section == "notifications":
                for provider in ["email", "sms", "push"]:
                    if provider in filtered_section and "password" in filtered_section[provider]:
                        filtered_section[provider]["password"] = "********"
            
            return jsonify(filtered_section)
            
        except Exception as e:
            self.logger.error(f"Error al obtener sección {section}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def update_config_section(self, section):
        """Actualizar una sección específica de la configuración"""
        try:
            if section not in self.config:
                return jsonify({"error": f"Sección {section} no encontrada"}), 404
                
            # Obtener datos
            data = request.json
            if not data:
                return jsonify({"error": "Datos no válidos"}), 400
                
            # Hacer backup de configuración actual
            backup_section = self.config[section].copy()
            
            # Actualizar sección
            self.config[section] = data
            
            # Guardar cambios
            if not self._save_config():
                # Restaurar backup si hay error
                self.config[section] = backup_section
                return jsonify({"error": "Error al guardar configuración"}), 500
                
            # Reiniciar componentes según sección
            if section == "cameras":
                self._init_cameras()
            elif section == "storage":
                self._init_components()
            elif section == "notifications":
                self.notification_manager = NotificationManager(data)
            
            return jsonify({
                "status": "success",
                "message": f"Sección {section} actualizada correctamente"
            })
            
        except Exception as e:
            self.logger.error(f"Error al actualizar sección {section}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def _save_config(self):
        """Guardar configuración a archivo"""
        try:
            # Asegurarse de que self.config_path está definido
            config_path = getattr(self, 'config_path', "configs/system.json")
            
            # Crear directorio si no existe
            config_dir = os.path.dirname(config_path)
            os.makedirs(config_dir, exist_ok=True)
            
            # Guardar configuración
            with open(config_path, 'w') as f:
                json.dump(self.config, f, indent=4)
                
            self.logger.info(f"Configuración guardada en {config_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error al guardar configuración: {e}")
            return False
    
    def _reinitialize_components(self):
        """Reinicializar componentes del sistema"""
        try:
            # Reiniciar componentes
            self._init_components()
            self.logger.info("Componentes reinicializados correctamente")
            return True
            
        except Exception as e:
            self.logger.error(f"Error al reinicializar componentes: {e}")
            return False
    
    def get_statistics(self):
        """Obtener estadísticas generales del sistema"""
        try:
            # Asegurarse de que start_time está definido
            start_time = getattr(self, 'start_time', time.time())
            
            # Recopilar estadísticas
            stats = {
                "cameras": {
                    "total": len(self.cameras),
                    "online": sum(1 for c in self.cameras.values() if c.get("status") == "online"),
                    "recording": sum(1 for c in self.cameras.values() if c.get("recording", False))
                },
                "events": {
                    "total": len(self.event_history),
                    "active_alerts": len(self.active_alerts),
                    "by_type": {},
                    "by_camera": {}
                },
                "storage": self.storage_manager.get_storage_usage(),
                "system": {
                    "uptime": time.time() - start_time,
                    "version": "1.0.0"
                }
            }
            
            # Conteo por tipo de evento
            for event in self.event_history:
                event_type = event.get("type", "unknown")
                if event_type not in stats["events"]["by_type"]:
                    stats["events"]["by_type"][event_type] = 0
                stats["events"]["by_type"][event_type] += 1
                
            # Conteo por cámara
            for event in self.event_history:
                camera_id = event.get("camera_id", "unknown")
                if camera_id not in stats["events"]["by_camera"]:
                    stats["events"]["by_camera"][camera_id] = 0
                stats["events"]["by_camera"][camera_id] += 1
            
            return jsonify(stats)
            
        except Exception as e:
            self.logger.error(f"Error al obtener estadísticas: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_specific_statistics(self, stat_type):
        """Obtener estadísticas específicas"""
        try:
            if stat_type == "detections":
                # Estadísticas de detecciones por cámara
                stats = {}
                for camera_id, analyzer in self.analyzers.items():
                    camera_name = self.cameras.get(camera_id, {}).get("name", camera_id)
                    stats[camera_id] = {
                        "name": camera_name,
                        "object_counts": {
                            "person": analyzer.get_object_count("person"),
                            "vehicle": analyzer.get_object_count(["car", "truck", "bus"]),
                            "total": analyzer.get_object_count()
                        },
                        "zone_counts": analyzer.get_zone_counts()
                    }
                    
                return jsonify(stats)
                
            elif stat_type == "alerts":
                # Estadísticas de alertas
                stats = {
                    "total": len(self.event_history),
                    "active": len(self.active_alerts),
                    "by_type": {},
                    "by_camera": {},
                    "by_hour": [0] * 24,
                    "recent_trend": []
                }
                
                # Conteo por tipo y cámara
                for event in self.event_history:
                    event_type = event.get("type", "unknown")
                    if event_type not in stats["by_type"]:
                        stats["by_type"][event_type] = 0
                    stats["by_type"][event_type] += 1
                    
                    camera_id = event.get("camera_id", "unknown")
                    if camera_id not in stats["by_camera"]:
                        stats["by_camera"][camera_id] = 0
                    stats["by_camera"][camera_id] += 1
                    
                    # Distribución por hora
                    try:
                        timestamp = datetime.fromisoformat(event.get("timestamp", ""))
                        hour = timestamp.hour
                        stats["by_hour"][hour] += 1
                    except:
                        pass
                
                # Tendencia reciente (últimos 7 días por día)
                now = datetime.now()
                for i in range(7):
                    day = (now - timedelta(days=i)).date()
                    day_count = 0
                    
                    for event in self.event_history:
                        try:
                            event_date = datetime.fromisoformat(event.get("timestamp", "")).date()
                            if event_date == day:
                                day_count += 1
                        except:
                            pass
                    
                    stats["recent_trend"].insert(0, {
                        "date": day.isoformat(),
                        "count": day_count
                    })
                
                return jsonify(stats)
                
            elif stat_type == "storage":
                # Estadísticas de almacenamiento
                return jsonify(self.storage_manager.get_detailed_storage_stats())
                
            else:
                return jsonify({"error": f"Tipo de estadística no reconocido: {stat_type}"}), 400
            
        except Exception as e:
            self.logger.error(f"Error al obtener estadísticas específicas: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_zones(self, camera_id):
        """Obtener zonas definidas para una cámara"""
        try:
            if camera_id not in self.analyzers:
                return jsonify({"error": "Cámara no encontrada"}), 404
                
            analyzer = self.analyzers[camera_id]
            zones = analyzer.config.get("zones", {})
            
            return jsonify(zones)
            
        except Exception as e:
            self.logger.error(f"Error al obtener zonas para cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def create_zone(self, camera_id):
        """Crear nueva zona para una cámara"""
        try:
            if camera_id not in self.analyzers:
                return jsonify({"error": "Cámara no encontrada"}), 404
                
            # Obtener datos
            data = request.json
            if not data or "name" not in data or "polygon" not in data:
                return jsonify({"error": "Datos incompletos"}), 400
                
            zone_name = data["name"]
            polygon = data["polygon"]
            color = data.get("color", (0, 255, 0))  # Verde por defecto
            
            # Validar polígono
            if not isinstance(polygon, list) or len(polygon) < 3:
                return jsonify({"error": "El polígono debe tener al menos 3 puntos"}), 400
                
            # Crear zona
            analyzer = self.analyzers[camera_id]
            analyzer.set_zone_definition(zone_name, polygon, color)
            
            # Guardar cambios en configuración
            if camera_id in self.config.get("cameras", {}):
                camera_config = self.config["cameras"][camera_id]
                if "analyzer" not in camera_config:
                    camera_config["analyzer"] = {}
                if "zones" not in camera_config["analyzer"]:
                    camera_config["analyzer"]["zones"] = {}
                    
                camera_config["analyzer"]["zones"][zone_name] = {
                    "polygon": polygon,
                    "color": color
                }
                
                self._save_config()
            
            return jsonify({
                "status": "success",
                "message": f"Zona '{zone_name}' creada correctamente"
            })
            
        except Exception as e:
            self.logger.error(f"Error al crear zona para cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def update_zone(self, camera_id, zone_id):
        """Actualizar zona existente"""
        try:
            if camera_id not in self.analyzers:
                return jsonify({"error": "Cámara no encontrada"}), 404
                
            analyzer = self.analyzers[camera_id]
            zones = analyzer.config.get("zones", {})
            
            if zone_id not in zones:
                return jsonify({"error": f"Zona '{zone_id}' no encontrada"}), 404
                
            # Obtener datos
            data = request.json
            if not data:
                return jsonify({"error": "Datos no válidos"}), 400
                
            # Actualizar polígono si está presente
            if "polygon" in data:
                polygon = data["polygon"]
                if not isinstance(polygon, list) or len(polygon) < 3:
                    return jsonify({"error": "El polígono debe tener al menos 3 puntos"}), 400
                    
                color = data.get("color", zones[zone_id].get("color"))
                analyzer.set_zone_definition(zone_id, polygon, color)
                
            # Actualizar configuración
            if camera_id in self.config.get("cameras", {}):
                camera_config = self.config["cameras"][camera_id]
                if "analyzer" in camera_config and "zones" in camera_config["analyzer"]:
                    if zone_id in camera_config["analyzer"]["zones"]:
                        if "polygon" in data:
                            camera_config["analyzer"]["zones"][zone_id]["polygon"] = data["polygon"]
                        if "color" in data:
                            camera_config["analyzer"]["zones"][zone_id]["color"] = data["color"]
                            
                        self._save_config()
            
            return jsonify({
                "status": "success",
                "message": f"Zona '{zone_id}' actualizada correctamente"
            })
            
        except Exception as e:
            self.logger.error(f"Error al actualizar zona {zone_id} para cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def delete_zone(self, camera_id, zone_id):
        """Eliminar zona"""
        try:
            if camera_id not in self.analyzers:
                return jsonify({"error": "Cámara no encontrada"}), 404
                
            analyzer = self.analyzers[camera_id]
            
            # Eliminar zona
            success = analyzer.delete_zone(zone_id)
            if not success:
                return jsonify({"error": f"Zona '{zone_id}' no encontrada"}), 404
                
            # Actualizar configuración
            if camera_id in self.config.get("cameras", {}):
                camera_config = self.config["cameras"][camera_id]
                if "analyzer" in camera_config and "zones" in camera_config["analyzer"]:
                    if zone_id in camera_config["analyzer"]["zones"]:
                        del camera_config["analyzer"]["zones"][zone_id]
                        self._save_config()
            
            return jsonify({
                "status": "success",
                "message": f"Zona '{zone_id}' eliminada correctamente"
            })
            
        except Exception as e:
            self.logger.error(f"Error al eliminar zona {zone_id} para cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_camera_stream(self, camera_id):
        """Obtener stream MJPEG de una cámara"""
        try:
            if camera_id not in self.cameras:
                return jsonify({"error": "Cámara no encontrada"}), 404
                
            if self.cameras[camera_id].get("status") != "online":
                return jsonify({"error": "Cámara no disponible"}), 503
                
            # Implementar streaming MJPEG
            def generate_frames():
                while True:
                    # Obtener frame
                    stream = self.camera_streams.get(camera_id)
                    if not stream:
                        break
                        
                    frame = stream.get("last_frame")
                    if frame is None:
                        time.sleep(0.1)
                        continue
                    
                    # Comprimir a JPEG
                    _, jpeg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                    
                    # Formato MJPEG
                    yield (b'--frame\r\n'
                          b'Content-Type: image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')
                    
                    # Limitar FPS del stream
                    time.sleep(0.033)  # ~30 FPS
            
            return Response(
                generate_frames(),
                mimetype='multipart/x-mixed-replace; boundary=frame'
            )
            
        except Exception as e:
            self.logger.error(f"Error al obtener stream de cámara {camera_id}: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_learning_status(self):
        """Obtener estado del sistema de aprendizaje"""
        try:
            status = {
                "client_id": self.learning_system.client_id,
                "event_count": len(self.learning_system.event_history),
                "models": {
                    model_type: {"available": True}
                    for model_type in self.learning_system.behavior_models
                },
                "thresholds": self.learning_system.detection_thresholds,
                "high_risk_zones": [
                    zone_id for zone_id, profile in self.learning_system.zone_risk_profiles.items()
                    if profile.get('risk_level', 0) > 50
                ]
            }
            
            return jsonify(status)
        except Exception as e:
            self.logger.error(f"Error al obtener estado de aprendizaje: {e}")
            return jsonify({"error": str(e)}), 500
    
    def train_models(self):
        """Iniciar entrenamiento de modelos"""
        try:
            data = request.json or {}
            specific_model = data.get('model_type')
            
            results = self.learning_system.train_models(specific_model)
            
            return jsonify({
                "status": "success",
                "results": results
            })
        except Exception as e:
            self.logger.error(f"Error al entrenar modelos: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_optimized_parameters(self):
        """Obtener parámetros optimizados"""
        try:
            camera_id = request.args.get('camera_id')
            zone_id = request.args.get('zone_id')
            event_type = request.args.get('event_type')
            
            params = self.learning_system.get_optimized_parameters(
                camera_id=camera_id,
                zone_id=zone_id,
                event_type=event_type
            )
            
            return jsonify(params)
        except Exception as e:
            self.logger.error(f"Error al obtener parámetros optimizados: {e}")
            return jsonify({"error": str(e)}), 500
    
    def run_simulation(self):
        """Ejecutar simulación para entrenamiento"""
        try:
            data = request.json
            if not data:
                return jsonify({"error": "Configuración de simulación requerida"}), 400
            
            results = self.learning_system.run_scenario_simulation(data)
            
            return jsonify(results)
        except Exception as e:
            self.logger.error(f"Error al ejecutar simulación: {e}")
            return jsonify({"error": str(e)}), 500
    
    def register_feedback(self, event_id):
        """Registrar retroalimentación para un evento"""
        try:
            data = request.json
            if not data or 'feedback' not in data:
                return jsonify({"error": "Retroalimentación requerida"}), 400
            
            feedback = data.get('feedback')
            if feedback not in ['true_positive', 'false_positive', 'not_sure']:
                return jsonify({"error": "Valor de retroalimentación inválido"}), 400
            
            # Buscar evento
            event_data = None
            for event in self.event_history:
                if event.get('id') == event_id:
                    event_data = event
                    break
                
            if not event_data:
                return jsonify({"error": "Evento no encontrado"}), 404
            
            # Registrar retroalimentación
            self.learning_system.register_event(event_data, feedback)
            
            return jsonify({
                "status": "success",
                "message": "Retroalimentación registrada correctamente"
            })
        except Exception as e:
            self.logger.error(f"Error al registrar retroalimentación: {e}")
            return jsonify({"error": str(e)}), 500
    
    def get_watchlist(self):
        """Obtener lista de personas en lista de vigilancia"""
        try:
            # Obtener todas las personas
            persons = self.face_recognition_system.get_all_persons()
            
            # Filtrar solo las que están en lista de vigilancia
            watchlist = [p for p in persons if p.get('watch_list', False)]
            
            # Excluir datos de embeddings para aligerar respuesta
            for person in watchlist:
                if 'embedding' in person:
                    del person['embedding']
                    
            return jsonify(watchlist)
        except Exception as e:
            self.logger.error(f"Error al obtener lista de vigilancia: {e}")
            return jsonify({"error": str(e)}), 500
    
    def add_to_watchlist(self, person_id):
        """Añadir persona a la lista de vigilancia"""
        try:
            # Verificar si la persona existe
            person = self.face_recognition_system.get_person(person_id)
            if not person:
                return jsonify({"error": "Persona no encontrada"}), 404
            
            # Obtener datos adicionales
            data = request.json or {}
            alert_level = data.get('alert_level', 'high')
            notes = data.get('notes', '')
            
            # Actualizar información
            updated_info = {
                'watch_list': True,
                'watch_list_date': datetime.now().isoformat(),
                'watch_list_alert_level': alert_level,
                'watch_list_notes': notes
            }
            
            result = self.face_recognition_system.update_person_info(person_id, updated_info)
            
            if not result:
                return jsonify({"error": "No se pudo añadir a la lista de vigilancia"}), 500
            
            return jsonify({
                "status": "success",
                "message": f"Persona {person_id} añadida a la lista de vigilancia"
            })
        except Exception as e:
            self.logger.error(f"Error al añadir persona {person_id} a lista de vigilancia: {e}")
            return jsonify({"error": str(e)}), 500
    
    def remove_from_watchlist(self, person_id):
        """Eliminar persona de la lista de vigilancia"""
        try:
            # Verificar si la persona existe
            person = self.face_recognition_system.get_person(person_id)
            if not person:
                return jsonify({"error": "Persona no encontrada"}), 404
            
            # Actualizar información
            updated_info = {
                'watch_list': False,
                'watch_list_removed_date': datetime.now().isoformat()
            }
            
            result = self.face_recognition_system.update_person_info(person_id, updated_info)
            
            if not result:
                return jsonify({"error": "No se pudo eliminar de la lista de vigilancia"}), 500
            
            return jsonify({
                "status": "success",
                "message": f"Persona {person_id} eliminada de la lista de vigilancia"
            })
        except Exception as e:
            self.logger.error(f"Error al eliminar persona {person_id} de lista de vigilancia: {e}")
            return jsonify({"error": str(e)}), 500
    
    def run(self, host=None, port=None, debug=None):
        """Iniciar la API REST"""
        # Guardar tiempo de inicio
        self.start_time = time.time()
        
        # Obtener configuración de API
        api_config = self.config.get("api", {})
        
        # Usar valores de parámetros o de configuración
        host = host or api_config.get("host", "0.0.0.0")
        port = port or api_config.get("port", 5000)
        debug = debug if debug is not None else api_config.get("debug", False)
        
        self.logger.info(f"Iniciando API REST en {host}:{port}")
        
        try:
            # Iniciar aplicación Flask
            self.app.run(host=host, port=port, debug=debug, threaded=True)
        except KeyboardInterrupt:
            self.logger.info("API REST detenida por el usuario")
        except Exception as e:
            self.logger.error(f"Error al iniciar API REST: {e}")
        finally:
            # Limpiar recursos
            self.running = False
            if self.bg_thread.is_alive():
                self.bg_thread.join(timeout=2.0)
                
            self.logger.info("Recursos liberados")


if __name__ == "__main__":
    # Configurar logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Cargar ruta de configuración desde argumentos o usar valor por defecto
    import argparse
    parser = argparse.ArgumentParser(description='API REST para sistema de vigilancia')
    parser.add_argument('--config', type=str, default='configs/system.json',
                        help='Ruta al archivo de configuración')
    args = parser.parse_args()
    
    # Inicializar y ejecutar API
    api = SurveillanceAPI(config_path=args.config)
    api.run() 
```

### src\api\websocket.py
```py | 9517 bytes | Modificado: 2025-03-15 09:44:51.864166
```
import json
import logging
import asyncio
from typing import Dict, Set, Any, Optional, Callable, Awaitable
from fastapi import WebSocket, WebSocketDisconnect, Depends, HTTPException
from starlette.websockets import WebSocketState

from src.events.event_bus import EventBus
from src.database.db import get_db
from src.database.models import User, Camera
# from src.api.auth import get_current_user_ws

class ConnectionManager:
    """Gestiona conexiones WebSocket para transmisión en tiempo real"""
    
    def __init__(self):
        self.active_connections: Dict[str, Set[WebSocket]] = {}
        self.user_connections: Dict[int, Set[WebSocket]] = {}
        self.logger = logging.getLogger("WebSocketManager")
        
    async def connect(self, websocket: WebSocket, channel: str, user_id: int = None):
        """Establece una conexión WebSocket"""
        await websocket.accept()
        
        # Inicializar canal si no existe
        if channel not in self.active_connections:
            self.active_connections[channel] = set()
        
        # Añadir conexión al canal
        self.active_connections[channel].add(websocket)
        
        # Registrar conexión de usuario si se proporciona ID
        if user_id:
            if user_id not in self.user_connections:
                self.user_connections[user_id] = set()
            self.user_connections[user_id].add(websocket)
            
        self.logger.info(f"Nueva conexión WebSocket: canal={channel}, usuario={user_id}")
    
    async def disconnect(self, websocket: WebSocket, channel: str = None, user_id: int = None):
        """Desconecta un WebSocket"""
        # Eliminar de todos los canales si no se especifica uno
        if channel:
            if channel in self.active_connections:
                self.active_connections[channel].discard(websocket)
                # Eliminar canal si está vacío
                if not self.active_connections[channel]:
                    del self.active_connections[channel]
        else:
            # Buscar en todos los canales
            for ch in list(self.active_connections.keys()):
                if websocket in self.active_connections[ch]:
                    self.active_connections[ch].discard(websocket)
                    # Eliminar canal si está vacío
                    if not self.active_connections[ch]:
                        del self.active_connections[ch]
        
        # Eliminar conexión de usuario
        if user_id and user_id in self.user_connections:
            self.user_connections[user_id].discard(websocket)
            if not self.user_connections[user_id]:
                del self.user_connections[user_id]
        elif not user_id:
            # Buscar en todos los usuarios
            for uid in list(self.user_connections.keys()):
                if websocket in self.user_connections[uid]:
                    self.user_connections[uid].discard(websocket)
                    if not self.user_connections[uid]:
                        del self.user_connections[uid]
        
        self.logger.info(f"Conexión WebSocket cerrada: canal={channel}, usuario={user_id}")
    
    async def send_message(self, message: Any, channel: str):
        """Envía un mensaje a todos los clientes en un canal"""
        if channel not in self.active_connections:
            return
        
        # Convertir a JSON si no es string
        if not isinstance(message, str):
            message = json.dumps(message)
        
        # Enviar a todas las conexiones en el canal
        disconnected = set()
        for connection in self.active_connections[channel]:
            try:
                if connection.client_state == WebSocketState.CONNECTED:
                    await connection.send_text(message)
            except RuntimeError:
                # Conexión cerrada o inválida
                disconnected.add(connection)
            except Exception as e:
                self.logger.error(f"Error enviando mensaje WebSocket: {e}")
                disconnected.add(connection)
        
        # Eliminar conexiones desconectadas
        for conn in disconnected:
            await self.disconnect(conn, channel)
    
    async def broadcast(self, message: Any):
        """Envía un mensaje a todos los clientes en todos los canales"""
        # Convertir a JSON si no es string
        if not isinstance(message, str):
            message = json.dumps(message)
            
        all_connections = set()
        for connections in self.active_connections.values():
            all_connections.update(connections)
        
        # Enviar a todas las conexiones únicas
        disconnected = set()
        for connection in all_connections:
            try:
                if connection.client_state == WebSocketState.CONNECTED:
                    await connection.send_text(message)
            except RuntimeError:
                # Conexión cerrada o inválida
                disconnected.add(connection)
            except Exception as e:
                self.logger.error(f"Error en broadcast WebSocket: {e}")
                disconnected.add(connection)
        
        # Eliminar conexiones desconectadas
        for conn in disconnected:
            await self.disconnect(conn)
    
    async def send_to_user(self, user_id: int, message: Any):
        """Envía un mensaje a todas las conexiones de un usuario"""
        if user_id not in self.user_connections:
            return
        
        # Convertir a JSON si no es string
        if not isinstance(message, str):
            message = json.dumps(message)
        
        # Enviar a todas las conexiones del usuario
        disconnected = set()
        for connection in self.user_connections[user_id]:
            try:
                if connection.client_state == WebSocketState.CONNECTED:
                    await connection.send_text(message)
            except RuntimeError:
                # Conexión cerrada o inválida
                disconnected.add(connection)
            except Exception as e:
                self.logger.error(f"Error enviando mensaje a usuario {user_id}: {e}")
                disconnected.add(connection)
        
        # Eliminar conexiones desconectadas
        for conn in disconnected:
            await self.disconnect(conn, user_id=user_id)

# Instancia global de ConnectionManager
manager = ConnectionManager()

# Manejador de eventos del EventBus para WebSockets
class WebSocketEventHandler:
    """Maneja eventos del sistema y los envía a los clientes WebSocket"""
    
    def __init__(self, event_bus: EventBus, connection_manager: ConnectionManager):
        self.event_bus = event_bus
        self.manager = connection_manager
        self.logger = logging.getLogger("WebSocketEventHandler")
        self.subscriptions = {}
    
    async def initialize(self):
        """Inicializa las suscripciones a eventos"""
        # Lista de canales a los que suscribirse
        channels = [
            "alert_*",  # Todos los eventos de alertas
            "camera_*",  # Todos los eventos de cámaras
            "detection_*",  # Todos los eventos de detección
            "system_*",  # Todos los eventos del sistema
            "user_*",  # Todos los eventos de usuarios
        ]
        
        # Suscribirse a cada canal
        for channel in channels:
            await self.event_bus.subscribe(channel, self.handle_event)
            self.subscriptions[channel] = True
        
        # Iniciar listener
        await self.event_bus.start_listener()
        self.logger.info("Iniciado manejador de eventos para WebSockets")
    
    async def handle_event(self, channel: str, data: Any):
        """Maneja un evento recibido y lo reenvía a los clientes WebSocket"""
        try:
            # Determinar el canal WebSocket según el canal de eventos
            ws_channel = channel.replace("_", "/")
            
            # Añadir timestamp si no existe
            if isinstance(data, dict) and "timestamp" not in data:
                data["timestamp"] = datetime.now().isoformat()
            
            # Enviar mensaje a través del connection manager
            await self.manager.send_message(data, ws_channel)
            
            # Si es una alerta, también enviar al canal general de alertas
            if channel.startswith("alert_"):
                await self.manager.send_message(data, "alerts")
            
            # Si es un evento de sistema, también enviar al canal general de sistema
            if channel.startswith("system_"):
                await self.manager.send_message(data, "system")
            
            self.logger.debug(f"Evento reenviado a WebSockets: {channel}")
            
        except Exception as e:
            self.logger.error(f"Error manejando evento para WebSockets: {e}")
    
    async def close(self):
        """Cierra el manejador de eventos"""
        # Detener listener
        await self.event_bus.stop_listener()
        
        # Cancelar suscripciones
        for channel in self.subscriptions:
            await self.event_bus.unsubscribe(channel, self.handle_event)
        
        self.subscriptions = {}
        self.logger.info("Cerrado manejador de eventos para WebSockets") 
```

### src\camera_vendors\base.py
```py | 1598 bytes | Modificado: 2025-03-15 09:13:23.157703
```
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List

class BaseCameraVendor(ABC):
    """Clase base abstracta para integración con diferentes marcas de cámaras"""
    
    def __init__(self):
        self.supported_features = []
        
    @abstractmethod
    def get_stream_url(self, camera_config: Dict[str, Any]) -> str:
        """Obtiene la URL de streaming para la cámara según su configuración"""
        pass
        
    def get_events(self, camera_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Obtiene eventos de la cámara (detección de movimiento, etc.)"""
        # Implementación opcional, no todas las cámaras soportan esto
        return []
        
    def get_device_info(self, camera_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Obtiene información básica del dispositivo"""
        # Implementación opcional
        return None
        
    def ptz_control(self, camera_config: Dict[str, Any], command: str, **kwargs) -> bool:
        """Controla funciones PTZ (Pan/Tilt/Zoom) si la cámara lo soporta"""
        # Implementación opcional
        return False
        
    def get_snapshot(self, camera_config: Dict[str, Any], output_path: Optional[str] = None):
        """Obtiene una imagen instantánea de la cámara"""
        # Implementación opcional
        return None
        
    def is_feature_supported(self, feature: str) -> bool:
        """Verifica si la funcionalidad específica está soportada"""
        return feature in self.supported_features 
```

### src\camera_vendors\dahua.py
```py | 8539 bytes | Modificado: 2025-03-13 20:26:52.192403
```
import requests
import cv2
import json
import logging
import time
import base64
from urllib.parse import quote
from src.camera_vendors.base import BaseCameraVendor

class DahuaVendor(BaseCameraVendor):
    """Integración con cámaras Dahua"""
    
    def __init__(self):
        self.supported_features = ["rtsp", "ptz", "events", "config", "recordings"]
        self.logger = logging.getLogger("DahuaVendor")
        self.sessions = {}  # Almacena sesiones activas por cámara
    
    def get_stream_url(self, camera_config):
        """Obtiene URL para stream RTSP de cámara Dahua"""
        ip = camera_config['ip']
        username = camera_config['username']
        password = camera_config['password']
        channel = camera_config.get('channel', 1)
        stream = camera_config.get('stream', 'main')  # 'main', 'sub', 'snap'
        
        # Codificar credenciales para URL
        auth = f"{quote(username)}:{quote(password)}"
        
        return f"rtsp://{auth}@{ip}:554/cam/realmonitor?channel={channel}&subtype={stream}"
    
    def connect(self, camera_config):
        """Establece conexión con la cámara y guarda la sesión"""
        ip = camera_config['ip']
        username = camera_config['username']
        password = camera_config['password']
        http_port = camera_config.get('http_port', 80)
        
        # URL base para API
        base_url = f"http://{ip}:{http_port}/cgi-bin"
        
        try:
            # Autenticar y obtener sesión
            auth_url = f"{base_url}/global.cgi?action=login&username={username}&password={password}"
            response = requests.get(auth_url, timeout=5)
            
            if response.status_code != 200 or "Error" in response.text:
                self.logger.error(f"Error de autenticación en cámara Dahua {ip}: {response.text}")
                return False
            
            # Extraer ID de sesión
            session_line = [line for line in response.text.split('\n') if 'session' in line.lower()]
            if not session_line:
                self.logger.error(f"No se encontró ID de sesión en la respuesta: {response.text}")
                return False
            
            session_id = session_line[0].split('=')[1].strip()
            
            # Guardar sesión
            self.sessions[ip] = {
                'id': session_id,
                'base_url': base_url,
                'last_used': time.time()
            }
            
            self.logger.info(f"Conexión establecida con cámara Dahua {ip}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error conectando con cámara Dahua {ip}: {e}")
            return False
    
    def get_device_info(self, camera_config):
        """Obtiene información básica del dispositivo"""
        ip = camera_config['ip']
        
        # Asegurar que hay conexión
        if ip not in self.sessions:
            if not self.connect(camera_config):
                return None
        
        session = self.sessions[ip]
        base_url = session['base_url']
        session_id = session['id']
        
        try:
            # Consultar información del dispositivo
            info_url = f"{base_url}/magicBox.cgi?action=getDeviceType&session={session_id}"
            device_response = requests.get(info_url, timeout=5)
            
            if device_response.status_code != 200:
                self.logger.error(f"Error obteniendo información de dispositivo: {device_response.text}")
                return None
            
            # Consultar información de software
            version_url = f"{base_url}/magicBox.cgi?action=getSoftwareVersion&session={session_id}"
            version_response = requests.get(version_url, timeout=5)
            
            if version_response.status_code != 200:
                self.logger.error(f"Error obteniendo versión de software: {version_response.text}")
                return None
            
            # Parsear respuestas
            device_type = device_response.text.split('=')[1].strip() if 'deviceType' in device_response.text else 'Unknown'
            software_version = version_response.text.split('=')[1].strip() if 'version' in version_response.text else 'Unknown'
            
            return {
                'device_type': device_type,
                'software_version': software_version,
                'vendor': 'Dahua',
                'ip': ip
            }
            
        except Exception as e:
            self.logger.error(f"Error consultando información de dispositivo Dahua {ip}: {e}")
            return None
    
    def ptz_control(self, camera_config, command, speed=5, stop_after=None):
        """Control PTZ básico"""
        ip = camera_config['ip']
        channel = camera_config.get('channel', 1)
        
        # Asegurar que hay conexión
        if ip not in self.sessions:
            if not self.connect(camera_config):
                return False
        
        session = self.sessions[ip]
        base_url = session['base_url']
        session_id = session['id']
        
        # Mapeo de comandos a códigos PTZ de Dahua
        ptz_commands = {
            'up': 'Up',
            'down': 'Down',
            'left': 'Left',
            'right': 'Right',
            'upleft': 'LeftUp',
            'upright': 'RightUp',
            'downleft': 'LeftDown',
            'downright': 'RightDown',
            'stop': 'Stop',
            'zoom_in': 'ZoomTele',
            'zoom_out': 'ZoomWide',
            'home': 'Home'
        }
        
        if command.lower() not in ptz_commands:
            self.logger.error(f"Comando PTZ no soportado: {command}")
            return False
        
        ptz_command = ptz_commands[command.lower()]
        
        try:
            # Enviar comando PTZ
            ptz_url = f"{base_url}/ptz.cgi?action=start&channel={channel}&code={ptz_command}&arg1=0&arg2={speed}&arg3=0&session={session_id}"
            response = requests.get(ptz_url, timeout=5)
            
            if response.status_code != 200 or "Error" in response.text:
                self.logger.error(f"Error ejecutando comando PTZ: {response.text}")
                return False
            
            # Si se especificó, detener después de un tiempo
            if stop_after and command.lower() != 'stop':
                time.sleep(stop_after)
                stop_url = f"{base_url}/ptz.cgi?action=stop&channel={channel}&code={ptz_command}&arg1=0&arg2={speed}&arg3=0&session={session_id}"
                requests.get(stop_url, timeout=5)
            
            return True
            
        except Exception as e:
            self.logger.error(f"Error controlando PTZ para cámara Dahua {ip}: {e}")
            return False
    
    def get_snapshot(self, camera_config, output_path=None):
        """Obtiene una captura instantánea de la cámara"""
        ip = camera_config['ip']
        channel = camera_config.get('channel', 1)
        
        # Construir URL para snapshot
        username = camera_config['username']
        password = camera_config['password']
        http_port = camera_config.get('http_port', 80)
        
        try:
            # URL directa para snapshot
            snapshot_url = f"http://{ip}:{http_port}/cgi-bin/snapshot.cgi?channel={channel}"
            
            # Realizar petición con autenticación
            response = requests.get(snapshot_url, auth=(username, password), timeout=5)
            
            if response.status_code != 200:
                self.logger.error(f"Error obteniendo snapshot: {response.status_code}")
                return None
            
            # Convertir respuesta a imagen
            image_array = np.frombuffer(response.content, np.uint8)
            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
            
            # Guardar si se especificó una ruta
            if output_path and image is not None:
                cv2.imwrite(output_path, image)
                self.logger.info(f"Snapshot guardado en {output_path}")
            
            return image
            
        except Exception as e:
            self.logger.error(f"Error capturando snapshot de cámara Dahua {ip}: {e}")
            return None 
```

### src\camera_vendors\hikvision.py
```py | 835 bytes | Modificado: 2025-03-13 20:25:02.535138
```
import requests
import cv2
from src.camera_vendors.base import BaseCameraVendor

class HikvisionVendor(BaseCameraVendor):
    """Integración con cámaras Hikvision"""
    
    def __init__(self):
        self.supported_features = ["rtsp", "ptz", "events", "config"]
        
    def get_stream_url(self, camera_config):
        ip = camera_config['ip']
        username = camera_config['username']
        password = camera_config['password']
        channel = camera_config.get('channel', 1)
        stream = camera_config.get('stream', 0)
        
        return f"rtsp://{username}:{password}@{ip}:554/h264/ch{channel}/{stream}"
        
    def get_events(self, camera_config):
        """Obtener eventos de la cámara (detección de movimiento, etc.)"""
        # Implementación usando ISAPI
        # ... 
```

### src\config\agent_config.py
```py | 1604 bytes | Modificado: 2025-03-05 13:53:05.578015
```
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from datetime import datetime

@dataclass
class AgentConfigBase:
    name: str
    type: str
    enabled: bool = True
    version: str = "1.0.0"
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    settings: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def validate(self) -> bool:
        """Valida la configuración básica"""
        return all([
            isinstance(self.name, str) and len(self.name) > 0,
            isinstance(self.type, str) and len(self.type) > 0,
            isinstance(self.enabled, bool),
            isinstance(self.settings, dict)
        ])
        
    def update_settings(self, new_settings: Dict[str, Any]):
        """Actualiza la configuración"""
        self.settings.update(new_settings)
        self.updated_at = datetime.now()
        
    def to_dict(self) -> Dict[str, Any]:
        """Convierte la configuración a diccionario"""
        return {
            "name": self.name,
            "type": self.type,
            "enabled": self.enabled,
            "version": self.version,
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
            "settings": self.settings,
            "dependencies": self.dependencies,
            "metadata": self.metadata
        } 
```

### src\config\base_config.py
```py | 2811 bytes | Modificado: 2025-03-05 13:51:26.330932
```
from typing import Dict, Any, Optional
import yaml
from pathlib import Path
from dataclasses import dataclass

@dataclass
class AgentConfig:
    agent_type: str
    name: str
    enabled: bool
    settings: Dict[str, Any]

class ConfigManager:
    def __init__(self, config_path: Path):
        self.config_path = config_path
        self.config_dir = config_path.parent
        self.system_config = self._load_config(config_path)
        self.agent_configs = {}
        self._load_agent_configs()
        
    def _load_config(self, path: Path) -> Dict[str, Any]:
        """Carga un archivo de configuración YAML"""
        try:
            with open(path, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            raise RuntimeError(f"Error cargando configuración {path}: {e}")
            
    def _load_agent_configs(self):
        """Carga las configuraciones de todos los agentes"""
        agent_types = ['video', 'access']
        
        for agent_type in agent_types:
            config_file = self.config_dir / f"{agent_type}_agent_config.yaml"
            if config_file.exists():
                config_data = self._load_config(config_file)
                self.agent_configs[agent_type] = config_data
                
    def get_system_config(self) -> Dict[str, Any]:
        """Retorna la configuración del sistema"""
        return self.system_config
        
    def get_agent_config(self, agent_type: str) -> AgentConfig:
        """Obtiene la configuración de un tipo de agente"""
        if agent_type not in self.agent_configs:
            raise ValueError(f"Configuración no encontrada para agente: {agent_type}")
            
        config_data = self.agent_configs[agent_type]
        return AgentConfig(
            agent_type=agent_type,
            name=config_data.get('name', f"{agent_type}_agent"),
            enabled=config_data.get('enabled', True),
            settings=config_data.get('settings', {})
        )
        
    def update_agent_config(self, agent_type: str, settings: Dict[str, Any]):
        """Actualiza la configuración de un agente"""
        if agent_type not in self.agent_configs:
            raise ValueError(f"Agente no encontrado: {agent_type}")
            
        # Actualizar configuración en memoria
        self.agent_configs[agent_type]['settings'].update(settings)
        
        # Guardar en disco
        config_file = self.config_dir / f"{agent_type}_agent_config.yaml"
        with open(config_file, 'w') as f:
            yaml.dump(self.agent_configs[agent_type], f)

    def get_ml_config(self) -> Dict[str, Any]:
        """Obtiene configuración del motor ML"""
        return self.system_config.get('ml_engine', {}) 
```

### src\config\config_loader.py
```py | 2268 bytes | Modificado: 2025-03-13 20:30:54.730329
```
import os
import yaml
import logging
from typing import Dict, Any

logger = logging.getLogger("ConfigLoader")

def load_config(config_path: str) -> Dict[str, Any]:
    """Carga la configuración desde un archivo YAML y sustituye variables de entorno"""
    if not os.path.exists(config_path):
        logger.error(f"Archivo de configuración no encontrado: {config_path}")
        raise FileNotFoundError(f"Archivo de configuración no encontrado: {config_path}")
    
    try:
        with open(config_path, 'r') as file:
            config = yaml.safe_load(file)
        
        # Procesar variables de entorno en la configuración
        config = _process_env_vars(config)
        
        return config
    except yaml.YAMLError as e:
        logger.error(f"Error al parsear el archivo YAML: {e}")
        raise
    except Exception as e:
        logger.error(f"Error al cargar la configuración: {e}")
        raise

def _process_env_vars(config: Dict[str, Any]) -> Dict[str, Any]:
    """Sustituye variables de entorno en la configuración"""
    if isinstance(config, dict):
        for key, value in config.items():
            config[key] = _process_env_vars(value)
    elif isinstance(config, list):
        for i, item in enumerate(config):
            config[i] = _process_env_vars(item)
    elif isinstance(config, str) and config.startswith("${") and config.endswith("}"):
        # Extraer nombre de la variable de entorno
        env_var = config[2:-1]
        # Obtener valor de la variable de entorno o usar string vacío si no existe
        env_value = os.environ.get(env_var, "")
        return env_value
    
    return config

def save_config(config: Dict[str, Any], config_path: str) -> bool:
    """Guarda la configuración en un archivo YAML"""
    try:
        # Crear directorio si no existe
        os.makedirs(os.path.dirname(config_path), exist_ok=True)
        
        with open(config_path, 'w') as file:
            yaml.dump(config, file, default_flow_style=False)
        
        logger.info(f"Configuración guardada en {config_path}")
        return True
    except Exception as e:
        logger.error(f"Error al guardar la configuración: {e}")
        return False 
```

### src\config\system_config.py
```py | 432 bytes | Modificado: 2025-03-05 13:19:26.410726
```
SYSTEM_CONFIG = {
    'deployment_mode': 'hybrid',  # 'cloud', 'local', 'hybrid'
    'storage': {
        'event_retention': '30d',
        'storage_type': 'selective',  # 'full', 'selective', 'minimal'
    },
    'ml_settings': {
        'update_frequency': '7d',
        'min_confidence': 0.85
    },
    'communication': {
        'primary_channel': 'whatsapp',
        'backup_channels': ['push', 'email']
    }
} 
```

### src\core\__init__.py
```py | 767 bytes | Modificado: 2025-03-06 00:16:48.341626
```
from .event_system import EventBus, Event
from .ml_engine import ObjectDetector, Detection, ObjectTracker, Track, BehaviorAnalyzer, BehaviorPattern
# Importar solo si ya se ha definido
try:
    from .master_control import SystemController
    __all__ = [
        'EventBus',
        'Event',
        'ObjectDetector',
        'Detection',
        'ObjectTracker',
        'Track',
        'BehaviorAnalyzer',
        'BehaviorPattern',
        'SystemController'
    ]
except ImportError:
    # Si SystemController aún no está definido
    __all__ = [
        'EventBus',
        'Event',
        'ObjectDetector',
        'Detection',
        'ObjectTracker',
        'Track',
        'BehaviorAnalyzer',
        'BehaviorPattern'
    ] 
```

### src\core\event_system\__init__.py
```py | 74 bytes | Modificado: 2025-03-05 20:49:47.551078
```
from .event_bus import EventBus, Event

__all__ = ['EventBus', 'Event'] 
```

### src\core\event_system\event_bus.py
```py | 3021 bytes | Modificado: 2025-03-05 21:15:06.602435
```
from typing import Dict, Any, List, Callable, Awaitable, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio
import json
from pathlib import Path

@dataclass
class Event:
    event_type: str
    data: Dict[str, Any]
    timestamp: datetime
    source: str
    priority: int = 1
    id: Optional[str] = None

class EventBus:
    def __init__(self):
        self.subscribers: Dict[str, List[Callable[[Event], Awaitable[None]]]] = {}
        self.event_history: List[Event] = []
        self.max_history = 1000
        self._lock = asyncio.Lock()
        
    async def emit(self, event: Event):
        """Emite un evento a todos los suscriptores"""
        if event.event_type in self.subscribers:
            for callback in self.subscribers[event.event_type]:
                await callback(event)
                
    def subscribe(self, event_type: str, callback: Callable[[Event], Awaitable[None]]):
        """Suscribe un callback a un tipo de evento"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        self.subscribers[event_type].append(callback)
        
    def unsubscribe(self, event_type: str, callback: Callable):
        """Desuscribe un callback de un tipo de evento"""
        if event_type in self.subscribers:
            self.subscribers[event_type].remove(callback)
            
    async def _safe_callback(self, callback: Callable, event: Event):
        """Ejecuta un callback de manera segura"""
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(event)
            else:
                callback(event)
        except Exception as e:
            print(f"Error en callback de evento {event.event_type}: {e}")
            
    def get_recent_events(self, event_type: Optional[str] = None, 
                         limit: int = 100) -> List[Event]:
        """Obtiene eventos recientes del historial"""
        if event_type:
            events = [e for e in self.event_history if e.event_type == event_type]
        else:
            events = self.event_history.copy()
            
        return sorted(events, 
                     key=lambda x: x.timestamp, 
                     reverse=True)[:limit]
                     
    async def save_events(self, path: Path):
        """Guarda eventos en disco"""
        async with self._lock:
            events_data = [
                {
                    'event_type': e.event_type,
                    'data': e.data,
                    'timestamp': e.timestamp.isoformat(),
                    'source': e.source,
                    'priority': e.priority,
                    'id': e.id
                }
                for e in self.event_history
            ]
            
            path.parent.mkdir(parents=True, exist_ok=True)
            with open(path, 'w') as f:
                json.dump(events_data, f, indent=2) 
```

### src\core\master_control\__init__.py
```py | 82 bytes | Modificado: 2025-03-06 00:16:48.341626
```
from .system_controller import SystemController

__all__ = ['SystemController'] 
```

### src\core\master_control\system_controller.py
```py | 5266 bytes | Modificado: 2025-03-05 19:42:47.189263
```
from typing import Dict, Any, List
import asyncio
from pathlib import Path
from src.config.base_config import ConfigManager
from src.utils.logging import SecurityLogger
from src.core.event_system import EventBus
from src.agent_modules.video_analytics.video_agent import VideoAgent
from src.agent_modules.access_control.access_agent import AccessControlAgent
from src.services.alert_manager import AlertManager
from src.services.visitor_management import VisitorManager
from src.services.notification.whatsapp_service import WhatsAppService
from src.agent_modules.base import BaseAgent

class SystemController:
    def __init__(self, config_path: Path):
        # Cargar configuración
        self.config_manager = ConfigManager(config_path)
        self.system_config = self.config_manager.get_system_config()
        
        # Inicializar componentes core
        self.event_bus = EventBus()
        self.logger = SecurityLogger(self.system_config['logging'])
        
        # Inicializar servicios
        self.alert_manager = AlertManager(self.system_config['alerts'])
        self.visitor_manager = VisitorManager(self.system_config['visitors'])
        
        # Inicializar agentes
        self.agents: List[BaseAgent] = []
        self._initialize_agents()
        
        # Configurar manejadores de eventos
        self._setup_event_handlers()
        
    def _initialize_agents(self):
        """Inicializa los agentes del sistema"""
        # Video Analytics
        for camera_id, camera_config in self.system_config['cameras'].items():
            agent_config = self.config_manager.get_agent_config('video')
            agent_config.update({'camera_id': camera_id, **camera_config})
            
            self.agents.append(VideoAgent(
                agent_config,
                self.event_bus,
                self.logger
            ))
            
        # Control de Acceso
        for point_id, point_config in self.system_config['access_points'].items():
            agent_config = self.config_manager.get_agent_config('access')
            agent_config.update({'point_id': point_id, **point_config})
            
            self.agents.append(AccessControlAgent(
                agent_config,
                self.event_bus,
                self.logger
            ))
            
    def _setup_event_handlers(self):
        """Configura los manejadores de eventos del sistema"""
        # Eventos de seguridad
        self.event_bus.subscribe(
            "security_alert",
            self._handle_security_alert
        )
        
        # Eventos de acceso
        self.event_bus.subscribe(
            "access_request",
            self._handle_access_request
        )
        
        # Eventos de estado de agentes
        self.event_bus.subscribe(
            "agent_status_changed",
            self._handle_agent_status
        )
        
    async def start(self):
        """Inicia el sistema"""
        try:
            self.logger.logger.info("Iniciando sistema de seguridad...")
            
            # Iniciar agentes
            agent_tasks = []
            for agent in self.agents:
                self.logger.logger.info(f"Iniciando agente: {agent.__class__.__name__}")
                agent_tasks.append(asyncio.create_task(agent.start()))
                
            # Esperar señal de terminación
            await asyncio.gather(*agent_tasks)
            
        except Exception as e:
            self.logger.logger.error(f"Error en el sistema: {str(e)}")
            await self.shutdown()
            
    async def shutdown(self):
        """Detiene el sistema de manera ordenada"""
        self.logger.logger.info("Deteniendo sistema...")
        
        # Detener agentes
        for agent in self.agents:
            try:
                await agent.stop()
                self.logger.logger.info(f"Agente detenido: {agent.__class__.__name__}")
            except Exception as e:
                self.logger.logger.error(f"Error deteniendo agente {agent.__class__.__name__}: {str(e)}")
                
    async def _handle_security_alert(self, event):
        """Maneja alertas de seguridad"""
        await self.alert_manager.process_alert(event.data)
        
    async def _handle_access_request(self, event):
        """Maneja solicitudes de acceso"""
        access_point = event.data['access_point']
        for agent in self.agents:
            if isinstance(agent, AccessControlAgent) and agent.point_id == access_point:
                await agent.process_access_request(event.data)
            
    async def _handle_agent_status(self, event):
        """Maneja cambios de estado de los agentes"""
        self.logger.logger.info(
            f"Estado de agente actualizado: {event.data['agent_id']} -> {event.data['status']}"
        )

    def register_agent(self, agent: BaseAgent):
        """Registra un nuevo agente"""
        self.agents.append(agent)

    def process_event(self, event_data):
        """Procesa eventos detectados"""
        
    def handle_alert(self, alert_type, data):
        """Gestiona las alertas del sistema""" 
```

### src\core\ml_engine\__init__.py
```py | 316 bytes | Modificado: 2025-03-05 16:57:23.715007
```
from .object_detection import ObjectDetector, Detection
from .object_tracking import ObjectTracker, Track
from .behavior_analyzer import BehaviorAnalyzer, BehaviorPattern

__all__ = [
    'ObjectDetector',
    'Detection',
    'ObjectTracker',
    'Track',
    'BehaviorAnalyzer',
    'BehaviorPattern'
] 
```

### src\core\ml_engine\behavior_analyzer.py
```py | 4016 bytes | Modificado: 2025-03-06 00:12:45.405500
```
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
import numpy as np
from .object_tracking import Track
import cv2

@dataclass
class BehaviorPattern:
    pattern_type: str
    confidence: float
    details: Dict[str, Any]
    track_ids: List[int]
    timestamp: datetime

class BehaviorAnalyzer:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.pattern_history: List[BehaviorPattern] = []
        self.track_history: Dict[int, List[Tuple[datetime, np.ndarray]]] = {}
        self.max_history = config.get('max_history_seconds', 30)
        self.loitering_area_threshold = config.get('loitering_area_threshold', 5000)
        self.group_distance_threshold = config.get('group_distance_threshold', 100)
        
    def analyze_tracks(self, tracks: List[Track], current_time: datetime) -> List[BehaviorPattern]:
        """Analiza los tracks para detectar patrones de comportamiento"""
        # Quitar el async ya que no es necesario
        if not tracks:
            return []
        
        patterns = []
        
        # Detectar patrones
        if loitering := self._detect_loitering(tracks):
            patterns.append(loitering)
        
        if grouping := self._detect_grouping(tracks):
            patterns.append(grouping)
        
        return patterns
        
    def _detect_loitering(self, tracks: List[Track]) -> Optional[BehaviorPattern]:
        """Detecta comportamiento de merodeo"""
        for track in tracks:
            # Calcular área cubierta por el track
            area = self._calculate_track_area(track)
            
            # Si el área es menor que el umbral, puede ser merodeo
            if area < self.loitering_area_threshold:
                return BehaviorPattern(
                    pattern_type="loitering",
                    confidence=0.7,
                    details={
                        "area": float(area),
                        "track_id": track.id
                    },
                    track_ids=[track.id],
                    timestamp=datetime.now()
                )
        return None
        
    def _detect_grouping(self, tracks: List[Track]) -> Optional[BehaviorPattern]:
        """Detecta formación de grupos"""
        if len(tracks) < 2:
            return None
        
        # Calcular centros de los tracks
        centers = []
        for track in tracks:
            x1, y1, x2, y2 = track.detection.bbox
            center = np.array([(x1 + x2) / 2, (y1 + y2) / 2])
            centers.append(center)
        
        # Buscar tracks cercanos
        groups = []
        for i, center1 in enumerate(centers):
            group = [i]
            for j, center2 in enumerate(centers[i+1:], i+1):
                distance = np.linalg.norm(center1 - center2)
                if distance < self.group_distance_threshold:
                    group.append(j)
            if len(group) > 1:
                groups.append(group)
        
        # Si encontramos un grupo
        if groups:
            # Usar el grupo más grande
            largest_group = max(groups, key=len)
            group_track_ids = [tracks[i].id for i in largest_group]
            
            return BehaviorPattern(
                pattern_type="group_formation",
                confidence=0.8,
                details={
                    "group_size": len(group_track_ids),
                    "distance_threshold": self.group_distance_threshold
                },
                track_ids=group_track_ids,
                timestamp=datetime.now()
            )
        
        return None
    
    def _calculate_track_area(self, track: Track) -> float:
        """
        Calcula el área cubierta por un track
        """
        x1, y1, x2, y2 = track.detection.bbox
        return (x2 - x1) * (y2 - y1)
```

### src\core\ml_engine\face_recognition.py
```py | 5364 bytes | Modificado: 2025-03-05 14:08:23.069305
```
from typing import List, Dict, Any, Optional
import numpy as np
import cv2
import torch
from pathlib import Path
import face_recognition
import asyncio
from datetime import datetime
import json

class FaceRecognizer:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.known_faces: Dict[str, np.ndarray] = {}
        self.known_names: Dict[str, str] = {}
        self._load_known_faces()
        
        self.detection_lock = asyncio.Lock()
        self.batch_size = config.get('batch_size', 4)
        self.min_face_size = config.get('min_face_size', 20)
        
    def _load_known_faces(self):
        """Carga las caras conocidas desde el directorio de entrenamiento"""
        faces_dir = Path(self.config['faces_dir'])
        if not faces_dir.exists():
            raise RuntimeError(f"Directorio de caras no encontrado: {faces_dir}")
            
        for user_dir in faces_dir.iterdir():
            if not user_dir.is_dir():
                continue
                
            user_id = user_dir.name
            encodings = []
            
            for img_path in user_dir.glob("*.jpg"):
                try:
                    image = face_recognition.load_image_file(str(img_path))
                    encoding = face_recognition.face_encodings(image)[0]
                    encodings.append(encoding)
                except Exception as e:
                    print(f"Error cargando imagen {img_path}: {e}")
                    continue
                    
            if encodings:
                self.known_faces[user_id] = np.mean(encodings, axis=0)
                
                # Cargar nombre del usuario
                meta_file = user_dir / "metadata.json"
                if meta_file.exists():
                    with open(meta_file) as f:
                        metadata = json.load(f)
                        self.known_names[user_id] = metadata.get('name', user_id)
                        
    async def identify_faces(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """Identifica rostros en un frame"""
        async with self.detection_lock:
            # Detectar rostros
            face_locations = face_recognition.face_locations(
                frame,
                model="cnn" if torch.cuda.is_available() else "hog"
            )
            
            if not face_locations:
                return []
                
            # Obtener encodings
            face_encodings = face_recognition.face_encodings(frame, face_locations)
            
            results = []
            for location, encoding in zip(face_locations, face_encodings):
                matches = face_recognition.compare_faces(
                    list(self.known_faces.values()),
                    encoding,
                    tolerance=self.config.get('similarity_threshold', 0.6)
                )
                
                if True in matches:
                    # Encontrar la mejor coincidencia
                    face_distances = face_recognition.face_distance(
                        list(self.known_faces.values()),
                        encoding
                    )
                    best_match_index = np.argmin(face_distances)
                    
                    if matches[best_match_index]:
                        user_id = list(self.known_faces.keys())[best_match_index]
                        confidence = 1 - face_distances[best_match_index]
                        
                        results.append({
                            'user_id': user_id,
                            'name': self.known_names.get(user_id, user_id),
                            'confidence': float(confidence),
                            'location': location,
                            'timestamp': datetime.now()
                        })
                        
            return results
            
    async def add_face(self, user_id: str, image: np.ndarray) -> bool:
        """Añade una nueva cara al conjunto de entrenamiento"""
        try:
            face_locations = face_recognition.face_locations(image)
            if not face_locations:
                return False
                
            encoding = face_recognition.face_encodings(image, face_locations)[0]
            
            if user_id in self.known_faces:
                # Actualizar encoding existente
                current_encoding = self.known_faces[user_id]
                self.known_faces[user_id] = np.mean(
                    [current_encoding, encoding],
                    axis=0
                )
            else:
                self.known_faces[user_id] = encoding
                
            # Guardar imagen
            faces_dir = Path(self.config['faces_dir']) / user_id
            faces_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            cv2.imwrite(
                str(faces_dir / f"{timestamp}.jpg"),
                cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            )
            
            return True
            
        except Exception as e:
            print(f"Error añadiendo cara: {e}")
            return False 
```

### src\core\ml_engine\ml_controller.py
```py | 447 bytes | Modificado: 2025-03-05 13:19:26.395724
```
class MLController:
    def __init__(self):
        self.models = {}
        self.training_data = {}
        
    def load_model(self, location_id):
        """Carga modelo específico para una ubicación"""
        
    def train_location_model(self, location_id, data):
        """Entrena modelo para ubicación específica"""
        
    def detect_patterns(self, frame, context):
        """Detecta patrones en frames de video""" 
```

### src\core\ml_engine\object_detection.py
```py | 7721 bytes | Modificado: 2025-03-06 00:37:32.360851
```
from typing import List, Dict, Any, Optional, Tuple
import torch
import numpy as np
from dataclasses import dataclass
from pathlib import Path
import cv2
import random

@dataclass
class Detection:
    """Representa una detección de objeto"""
    bbox: Tuple[int, int, int, int]  # (x1, y1, x2, y2)
    class_id: int
    class_name: str
    confidence: float
    frame_id: int

class ObjectDetector:
    def __init__(self, config: Dict[str, Any], test_mode: bool = False):
        self.config = config
        self.device = config.get('device', 'cpu')
        self.confidence_threshold = config.get('confidence_threshold', 0.5)
        self.test_mode = test_mode  # Modo de prueba para no cargar modelo real
        self.classes = self._load_classes()
        
        # Solo cargar el modelo si no estamos en modo de prueba
        if not self.test_mode:
            try:
                self.model = self._load_model()
            except Exception as e:
                # En caso de error, establecer modo de prueba
                print(f"No se pudo cargar el modelo. Usando modo de prueba: {e}")
                self.test_mode = True
        
    def _load_model(self):
        """Carga el modelo de detección"""
        model_path = Path(self.config['model_path'])
        if not model_path.exists():
            raise FileNotFoundError(f"Modelo no encontrado: {model_path}")
            
        try:
            # Intentar cargar el modelo con force_reload
            model = torch.hub.load(
                'ultralytics/yolov5',
                'custom', 
                path=model_path,
                force_reload=True,
                trust_repo=True  # Añadido para evitar advertencias de seguridad
            )
            return model.to(self.device)
        except Exception as e:
            # Si falla, intentar cargar el modelo directamente
            try:
                model = torch.load(model_path, map_location=self.device)
                if hasattr(model, 'module'):
                    model = model.module
                return model
            except Exception as load_error:
                raise RuntimeError(f"Error al cargar el modelo: {str(e)}\nError secundario: {str(load_error)}")
    
    def _load_classes(self) -> List[str]:
        """Carga las clases desde el archivo"""
        classes_path = Path(self.config.get('classes_path', 'models/coco.names'))
        
        # Clases predeterminadas en caso de que no exista el archivo
        default_classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 
            'toothbrush'
        ]
        
        if not classes_path.exists():
            return default_classes
            
        try:
            with open(classes_path, 'r') as f:
                classes = [line.strip() for line in f.readlines()]
            return classes
        except Exception:
            return default_classes
            
    async def detect(self, frame: np.ndarray, frame_id: int) -> List[Detection]:
        """Detecta objetos en un frame de video"""
        if self.test_mode:
            # En modo de prueba, generar detecciones simuladas
            return self._generate_test_detections(frame, frame_id)
            
        # Preprocesar frame
        img = self._preprocess_frame(frame)
        
        # Realizar inferencia
        with torch.no_grad():
            results = self.model(img)
            
        # Procesar resultados
        detections = []
        
        # Extraer detecciones que superen el umbral de confianza
        for *xyxy, conf, cls in results.xyxy[0]:
            if conf >= self.confidence_threshold:
                x1, y1, x2, y2 = map(int, xyxy)
                class_id = int(cls)
                class_name = self.classes[class_id] if class_id < len(self.classes) else f"class_{class_id}"
                
                detections.append(Detection(
                    bbox=(x1, y1, x2, y2),
                    class_id=class_id,
                    class_name=class_name,
                    confidence=float(conf),
                    frame_id=frame_id
                ))
                
        return detections
        
    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """Preprocesa el frame para la inferencia"""
        return frame  # YOLOv5 no requiere preprocesamiento especial
        
    def _generate_test_detections(self, frame: np.ndarray, frame_id: int) -> List[Detection]:
        """Genera detecciones simuladas para pruebas"""
        height, width = frame.shape[:2]
        detections = []
        
        # Generar 1-3 detecciones aleatorias
        num_detections = random.randint(1, 3)
        
        for _ in range(num_detections):
            # Generar bbox aleatorio
            x1 = random.randint(0, width - 100)
            y1 = random.randint(0, height - 100)
            w = random.randint(50, 200)
            h = random.randint(50, 200)
            x2 = min(x1 + w, width)
            y2 = min(y1 + h, height)
            
            # Clase aleatoria
            class_id = random.randint(0, len(self.classes) - 1)
            class_name = self.classes[class_id]
            
            # Confianza aleatoria por encima del umbral
            confidence = random.uniform(self.confidence_threshold, 1.0)
            
            detections.append(Detection(
                bbox=(x1, y1, x2, y2),
                class_id=class_id,
                class_name=class_name,
                confidence=confidence,
                frame_id=frame_id
            ))
            
        return detections
        
    def draw_detections(self, frame: np.ndarray, detections: List[Detection]) -> np.ndarray:
        """Dibuja las detecciones en el frame"""
        result = frame.copy()
        
        for det in detections:
            x1, y1, x2, y2 = det.bbox
            label = f"{det.class_name} {det.confidence:.2f}"
            
            # Color basado en clase
            color = (
                (det.class_id * 50) % 255,
                (det.class_id * 100) % 255,
                (det.class_id * 150) % 255
            )
            
            # Dibujar bbox
            cv2.rectangle(result, (x1, y1), (x2, y2), color, 2)
            
            # Dibujar etiqueta
            cv2.putText(
                result,
                label,
                (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                color,
                2
            )
            
        return result

__all__ = ['ObjectDetector', 'Detection'] 
```

### src\core\ml_engine\object_detector.py
```py | 2820 bytes | Modificado: 2025-03-05 13:37:45.421898
```
from typing import List, Dict, Any, Tuple
import torch
from pathlib import Path
import numpy as np
from ultralytics import YOLO
import cv2

class ObjectDetector:
    def __init__(self, model_path: str = "yolov8n.pt"):
        """
        Inicializa el detector de objetos
        Args:
            model_path: Ruta al modelo pre-entrenado o personalizado
        """
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = self._load_model(model_path)
        self.class_names = self.model.names
        self.confidence_threshold = 0.5
        
    def _load_model(self, model_path: str) -> YOLO:
        """Carga el modelo YOLO"""
        try:
            model = YOLO(model_path)
            model.to(self.device)
            return model
        except Exception as e:
            raise RuntimeError(f"Error cargando modelo: {str(e)}")
            
    def detect(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detecta objetos en un frame
        Args:
            frame: Imagen en formato numpy array (BGR)
        Returns:
            Lista de detecciones con formato:
            [
                {
                    'bbox': (x1, y1, x2, y2),
                    'class_id': int,
                    'class_name': str,
                    'confidence': float
                },
                ...
            ]
        """
        results = self.model(frame, conf=self.confidence_threshold)[0]
        detections = []
        
        for box in results.boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            class_id = int(box.cls)
            confidence = float(box.conf)
            
            detections.append({
                'bbox': (int(x1), int(y1), int(x2), int(y2)),
                'class_id': class_id,
                'class_name': self.class_names[class_id],
                'confidence': confidence
            })
            
        return detections
        
    def draw_detections(self, frame: np.ndarray, detections: List[Dict[str, Any]]) -> np.ndarray:
        """
        Dibuja las detecciones en el frame
        """
        frame_copy = frame.copy()
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            label = f"{det['class_name']} {det['confidence']:.2f}"
            
            # Dibujar bbox
            cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Dibujar etiqueta
            cv2.putText(
                frame_copy, 
                label, 
                (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (0, 255, 0),
                2
            )
            
        return frame_copy 
```

### src\core\ml_engine\object_tracker.py
```py | 3891 bytes | Modificado: 2025-03-05 13:37:45.423901
```
from typing import Dict, List, Optional, Tuple
import numpy as np
from dataclasses import dataclass
from datetime import datetime
import cv2

@dataclass
class TrackedObject:
    object_id: int
    class_id: int
    class_name: str
    first_seen: datetime
    last_seen: datetime
    positions: List[Tuple[int, int]]  # Centro del objeto
    confidence: float
    lost_count: int = 0

class ObjectTracker:
    def __init__(self, max_lost_frames: int = 30):
        self.tracked_objects: Dict[int, TrackedObject] = {}
        self.next_id = 0
        self.max_lost_frames = max_lost_frames
        
    def update(self, detections: List[Dict[str, Any]]) -> List[TrackedObject]:
        """
        Actualiza el estado de los objetos trackeados
        Args:
            detections: Lista de detecciones del detector
        Returns:
            Lista de objetos trackeados activos
        """
        current_time = datetime.now()
        
        # Incrementar contador de frames perdidos para todos los objetos
        for obj in self.tracked_objects.values():
            obj.lost_count += 1
            
        # Actualizar objetos existentes y crear nuevos
        matched_detections = set()
        
        for detection in detections:
            bbox = detection['bbox']
            center = self._get_bbox_center(bbox)
            
            # Buscar el objeto más cercano
            closest_obj = self._find_closest_object(center)
            
            if closest_obj is not None:
                # Actualizar objeto existente
                closest_obj.positions.append(center)
                closest_obj.last_seen = current_time
                closest_obj.confidence = detection['confidence']
                closest_obj.lost_count = 0
                matched_detections.add(id(detection))
            else:
                # Crear nuevo objeto
                new_obj = TrackedObject(
                    object_id=self.next_id,
                    class_id=detection['class_id'],
                    class_name=detection['class_name'],
                    first_seen=current_time,
                    last_seen=current_time,
                    positions=[center],
                    confidence=detection['confidence']
                )
                self.tracked_objects[self.next_id] = new_obj
                self.next_id += 1
                
        # Eliminar objetos perdidos
        self._remove_lost_objects()
        
        return list(self.tracked_objects.values())
        
    def _get_bbox_center(self, bbox: Tuple[int, int, int, int]) -> Tuple[int, int]:
        """Calcula el centro de un bbox"""
        x1, y1, x2, y2 = bbox
        return ((x1 + x2) // 2, (y1 + y2) // 2)
        
    def _find_closest_object(self, center: Tuple[int, int]) -> Optional[TrackedObject]:
        """Encuentra el objeto más cercano al centro dado"""
        min_dist = float('inf')
        closest_obj = None
        
        for obj in self.tracked_objects.values():
            if obj.lost_count > self.max_lost_frames:
                continue
                
            last_pos = obj.positions[-1]
            dist = np.sqrt((center[0] - last_pos[0])**2 + (center[1] - last_pos[1])**2)
            
            if dist < min_dist:
                min_dist = dist
                closest_obj = obj
                
        return closest_obj if min_dist < 100 else None
        
    def _remove_lost_objects(self):
        """Elimina objetos que se han perdido por mucho tiempo"""
        to_remove = []
        for obj_id, obj in self.tracked_objects.items():
            if obj.lost_count > self.max_lost_frames:
                to_remove.append(obj_id)
                
        for obj_id in to_remove:
            del self.tracked_objects[obj_id] 
```

### src\core\ml_engine\object_tracking.py
```py | 8835 bytes | Modificado: 2025-03-06 00:10:10.971133
```
from typing import List, Dict, Any, Tuple
import numpy as np
from dataclasses import dataclass
import cv2
from .object_detection import Detection

@dataclass
class Track:
    id: int
    detection: Detection
    kalman_filter: cv2.KalmanFilter
    history: List[Detection] = None
    age: int = 0
    hits: int = 0
    time_since_update: int = 0

class ObjectTracker:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.max_age = config.get('max_age', 30)
        self.min_hits = config.get('min_hits', 3)
        self.iou_threshold = config.get('iou_threshold', 0.3)
        
        # Almacena los tracks activos
        self.tracks: List[Track] = []
        self.next_id = 1
        
    def update(self, detections: List[Detection]) -> List[Track]:
        """Actualiza los tracks con nuevas detecciones"""
        # Si no hay tracks, inicializarlos
        if not self.tracks:
            return self._init_tracks(detections)
            
        # Si no hay detecciones, actualizar tracks existentes
        if not detections:
            return self._update_tracks([])
            
        # Calcular matriz de IoU
        match_matrix = self._calculate_iou_matrix(detections)
        
        # Asociar detecciones a tracks
        matches, unmatched_tracks, unmatched_detections = self._associate_detections(match_matrix)
        
        # Actualizar tracks con detecciones asignadas
        for track_idx, detection_idx in matches:
            self._update_matched_track(self.tracks[track_idx], detections[detection_idx])
            
        # Actualizar tracks sin detecciones
        for track_idx in unmatched_tracks:
            self._update_unmatched_track(self.tracks[track_idx])
            
        # Inicializar nuevos tracks para detecciones sin asignar
        for detection_idx in unmatched_detections:
            self._init_new_track(detections[detection_idx])
            
        # Eliminar tracks viejos
        self.tracks = [t for t in self.tracks if t.time_since_update <= self.max_age]
        
        # Retornar solo tracks confirmados
        return [t for t in self.tracks if t.hits >= self.min_hits]
        
    def _init_tracks(self, detections: List[Detection]) -> List[Track]:
        """Inicializa tracks para un conjunto de detecciones"""
        self.tracks = []
        
        for detection in detections:
            self._init_new_track(detection)
            
        # No retornar tracks hasta que sean confirmados
        return []
        
    def _init_new_track(self, detection: Detection):
        """Inicializa un nuevo track para una detección"""
        # Configurar Kalman filter
        kf = cv2.KalmanFilter(4, 2)
        kf.measurementMatrix = np.array([[1, 0, 0, 0],
                                       [0, 1, 0, 0]], np.float32)
        kf.transitionMatrix = np.array([[1, 0, 1, 0],
                                      [0, 1, 0, 1],
                                      [0, 0, 1, 0],
                                      [0, 0, 0, 1]], np.float32)
        
        # Posición inicial
        x1, y1, x2, y2 = detection.bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        kf.statePost = np.array([[center_x],
                             [center_y],
                             [0],  # velocidad x
                             [0]], np.float32)  # velocidad y
        
        # Crear track
        self.tracks.append(Track(
            id=self.next_id,
            detection=detection,
            kalman_filter=kf,
            history=[detection],
            hits=1
        ))
        
        # Incrementar ID
        self.next_id += 1
        
    def _calculate_iou_matrix(self, detections: List[Detection]) -> np.ndarray:
        """Calcula la matriz de IoU entre tracks y detecciones"""
        n_tracks = len(self.tracks)
        n_detections = len(detections)
        
        iou_matrix = np.zeros((n_tracks, n_detections))
        
        for i, track in enumerate(self.tracks):
            for j, detection in enumerate(detections):
                iou_matrix[i, j] = self._calculate_iou(track.detection.bbox, detection.bbox)
                
        return iou_matrix
        
    def _calculate_iou(self, bbox1: Tuple[int, int, int, int], 
                     bbox2: Tuple[int, int, int, int]) -> float:
        """Calcula IoU entre dos bounding boxes"""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # Calcular área de intersección
        xx1 = max(x1_1, x1_2)
        yy1 = max(y1_1, y1_2)
        xx2 = min(x2_1, x2_2)
        yy2 = min(y2_1, y2_2)
        
        # Intersección
        w = max(0, xx2 - xx1)
        h = max(0, yy2 - yy1)
        intersection = w * h
        
        # Unión
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        # IoU
        iou = intersection / max(union, 1e-6)
        
        return iou
        
    def _associate_detections(self, iou_matrix: np.ndarray):
        """Asocia detecciones a tracks usando IoU"""
        n_tracks, n_detections = iou_matrix.shape
        
        # Lista de pares (track_idx, detection_idx)
        matches = []
        
        # Track y detección sin emparejar
        unmatched_tracks = list(range(n_tracks))
        unmatched_detections = list(range(n_detections))
        
        # Para cada track, encontrar la mejor detección
        for t in range(n_tracks):
            if len(unmatched_detections) == 0:
                break
                
            # Obtener mejor match para este track
            best_match = -1
            best_iou = self.iou_threshold
            
            for d in unmatched_detections:
                iou = iou_matrix[t, d]
                if iou > best_iou:
                    best_iou = iou
                    best_match = d
                    
            if best_match >= 0:
                matches.append((t, best_match))
                unmatched_tracks.remove(t)
                unmatched_detections.remove(best_match)
                
        return matches, unmatched_tracks, unmatched_detections
        
    def _update_matched_track(self, track: Track, detection: Detection):
        """Actualiza un track con una detección emparejada"""
        x1, y1, x2, y2 = detection.bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        # Actualizar Kalman filter
        track.kalman_filter.correct(np.array([[center_x], [center_y]], np.float32))
        
        # Actualizar track
        track.detection = detection
        track.history.append(detection)
        track.hits += 1
        track.time_since_update = 0
        track.age += 1
        
    def _update_unmatched_track(self, track: Track):
        """Actualiza un track sin detección emparejada"""
        # Predicción de Kalman
        predicted_state = track.kalman_filter.predict()
        
        # Crear bbox actualizado basado en la predicción
        center_x = predicted_state[0, 0]
        center_y = predicted_state[1, 0]
        
        # Obtener ancho y alto del bbox actual
        x1, y1, x2, y2 = track.detection.bbox
        width = x2 - x1
        height = y2 - y1
        
        # Crear nuevo bbox centrado en la posición predicha
        new_x1 = int(center_x - width / 2)
        new_y1 = int(center_y - height / 2)
        new_x2 = int(center_x + width / 2)
        new_y2 = int(center_y + height / 2)
        
        # Actualizar detección simulada
        track.detection = Detection(
            bbox=(new_x1, new_y1, new_x2, new_y2),
            class_id=track.detection.class_id,
            class_name=track.detection.class_name,
            confidence=track.detection.confidence * 0.9,  # Disminuir confianza
            frame_id=track.detection.frame_id + 1
        )
        
        # Actualizar estado
        track.time_since_update += 1
        track.age += 1
        
    def _update_tracks(self, matched_detections: List[Detection]) -> List[Track]:
        """Actualiza todos los tracks sin nuevas detecciones"""
        for track in self.tracks:
            track.time_since_update += 1
            track.age += 1
            
        # Eliminar tracks viejos
        self.tracks = [t for t in self.tracks if t.time_since_update <= self.max_age]
        
        # Retornar solo tracks confirmados
        return [t for t in self.tracks if t.hits >= self.min_hits]

__all__ = ['Track', 'ObjectTracker'] 
```

### src\core\ml_engine\plate_recognition.py
```py | 2867 bytes | Modificado: 2025-03-05 13:47:52.225543
```
from typing import Optional, Dict, Any
import cv2
import numpy as np
import pytesseract
from dataclasses import dataclass
import torch
from ultralytics import YOLO

@dataclass
class PlateDetection:
    plate_text: str
    confidence: float
    bbox: tuple
    image: np.ndarray

class PlateRecognizer:
    def __init__(self):
        # Cargar modelo YOLO para detección de placas
        self.plate_detector = YOLO('models/plate_detector.pt')
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Configurar Tesseract
        self.tesseract_config = '--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
        
    async def detect_plate(self, image: np.ndarray) -> Optional[PlateDetection]:
        """Detecta y reconoce una placa en la imagen"""
        try:
            # Detectar región de la placa
            results = self.plate_detector(image)[0]
            if len(results.boxes) == 0:
                return None
                
            # Obtener la detección con mayor confianza
            box = results.boxes[0]
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            
            # Extraer región de la placa
            plate_region = image[y1:y2, x1:x2]
            
            # Preprocesar imagen
            processed_plate = self._preprocess_plate(plate_region)
            
            # OCR en la región de la placa
            plate_text = pytesseract.image_to_string(
                processed_plate,
                config=self.tesseract_config
            ).strip()
            
            if not plate_text:
                return None
                
            return PlateDetection(
                plate_text=plate_text,
                confidence=confidence,
                bbox=(x1, y1, x2, y2),
                image=processed_plate
            )
            
        except Exception as e:
            print(f"Error en reconocimiento de placa: {e}")
            return None
            
    def _preprocess_plate(self, plate_img: np.ndarray) -> np.ndarray:
        """Preprocesa la imagen de la placa para mejorar OCR"""
        # Convertir a escala de grises
        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        
        # Aplicar umbral adaptativo
        thresh = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 11, 2
        )
        
        # Reducir ruido
        denoised = cv2.fastNlMeansDenoising(thresh)
        
        # Dilatar para conectar componentes
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
        dilated = cv2.dilate(denoised, kernel, iterations=1)
        
        return dilated 
```

### src\database\db.py
```py | 1739 bytes | Modificado: 2025-03-13 20:28:44.240096
```
import os
import logging
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.pool import QueuePool
from contextlib import contextmanager

# Cargar configuración desde variables de entorno o valores por defecto
DATABASE_URL = os.environ.get("DATABASE_URL", "sqlite:///vigia.db")

# Configurar logger
logger = logging.getLogger("Database")

# Crear engine con pool de conexiones
engine = create_engine(
    DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    pool_recycle=3600,  # Reciclar conexiones cada hora
    pool_pre_ping=True,  # Verificar conexión antes de usar
    poolclass=QueuePool
)

# Crear fábrica de sesiones
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine
)

# Crear sesión con scope para entornos multihilo
db_session = scoped_session(SessionLocal)

@contextmanager
def get_db():
    """Proporciona una sesión de base de datos con manejo de contexto"""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Error en la transacción: {e}")
        raise
    finally:
        session.close()

def init_db():
    """Inicializa la base de datos creando todas las tablas"""
    from src.database.models import Base
    Base.metadata.create_all(bind=engine)
    logger.info("Base de datos inicializada")

def drop_db():
    """Elimina todas las tablas de la base de datos"""
    from src.database.models import Base
    Base.metadata.drop_all(bind=engine)
    logger.info("Base de datos eliminada") 
```

### src\database\models.py
```py | 10753 bytes | Modificado: 2025-03-15 10:07:40.111092
```
﻿import uuid
from datetime import datetime
from sqlalchemy import Column, Integer, String, Float, Boolean, DateTime, ForeignKey, JSON, Text, Table
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship, backref

Base = declarative_base()

# Mixin para timestamps comunes
class TimestampMixin:
    """Mixin para añadir timestamps automáticos a los modelos"""
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)

# Tabla de asociación para la relación many-to-many entre roles y permisos
role_permissions = Table(
    'role_permissions',
    Base.metadata,
    Column('role_id', Integer, ForeignKey('roles.id'), primary_key=True),
    Column('permission_id', Integer, ForeignKey('permissions.id'), primary_key=True)
)

class User(Base, TimestampMixin):
    """Modelo para usuarios del sistema"""
    __tablename__ = 'users'
    
    id = Column(Integer, primary_key=True)
    username = Column(String(50), unique=True, nullable=False)
    password_hash = Column(String(255), nullable=False)
    email = Column(String(100), unique=True, nullable=False)
    role_id = Column(Integer, ForeignKey('roles.id'), nullable=False)
    first_name = Column(String(50))
    last_name = Column(String(50))
    last_login = Column(DateTime)
    is_active = Column(Boolean, default=True, nullable=False)
    
    # Relaciones
    role = relationship("Role", back_populates="users")
    sessions = relationship("Session", back_populates="user")
    notifications = relationship("Notification", back_populates="user")
    
    def __repr__(self):
        return f"<User {self.username}>"

class Role(Base, TimestampMixin):
    """Modelo para roles de usuario"""
    __tablename__ = 'roles'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(50), unique=True, nullable=False)
    description = Column(String(255))
    
    # Relaciones
    users = relationship("User", back_populates="role")
    permissions = relationship("Permission", secondary=role_permissions, back_populates="roles")
    
    def __repr__(self):
        return f"<Role {self.name}>"

class Permission(Base, TimestampMixin):
    """Modelo para permisos"""
    __tablename__ = 'permissions'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(50), unique=True, nullable=False)
    description = Column(String(255))
    
    # Relaciones
    roles = relationship("Role", secondary=role_permissions, back_populates="permissions")
    
    def __repr__(self):
        return f"<Permission {self.name}>"

class Session(Base, TimestampMixin):
    """Modelo para sesiones de usuario"""
    __tablename__ = 'sessions'
    
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)
    token = Column(String(255), unique=True, nullable=False)
    ip_address = Column(String(45))
    user_agent = Column(Text)
    expires_at = Column(DateTime, nullable=False)
    
    # Relaciones
    user = relationship("User", back_populates="sessions")
    
    def __repr__(self):
        return f"<Session {self.id} - User {self.user_id}>"

class Camera(Base, TimestampMixin):
    """Modelo para cámaras del sistema"""
    __tablename__ = 'cameras'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(100), nullable=False)
    vendor = Column(String(50), nullable=False)
    ip = Column(String(50), nullable=False)
    username = Column(String(50))
    password = Column(String(255))
    rtsp_url = Column(String(255))
    fps = Column(Integer, default=10)
    resolution = Column(String(20))
    config = Column(JSON, default={})
    is_active = Column(Boolean, default=True, nullable=False)
    
    # Relaciones
    zones = relationship("Zone", back_populates="camera")
    recordings = relationship("Recording", back_populates="camera")
    
    def __repr__(self):
        return f"<Camera {self.name}>"

class Zone(Base, TimestampMixin):
    """Modelo para zonas de detección"""
    __tablename__ = 'zones'
    
    id = Column(Integer, primary_key=True)
    camera_id = Column(Integer, ForeignKey('cameras.id'), nullable=False)
    name = Column(String(50), nullable=False)
    type = Column(String(20), nullable=False)  # intrusion, loitering, line, etc.
    points = Column(JSON, nullable=False)  # [[x1,y1], [x2,y2], ...]
    color = Column(String(20))
    is_active = Column(Boolean, default=True)
    
    # Relaciones
    camera = relationship("Camera", back_populates="zones")
    alerts = relationship("Alert", back_populates="zone")
    
    __table_args__ = {'mysql_charset': 'utf8mb4', 'mysql_collate': 'utf8mb4_unicode_ci'}
    
    def __repr__(self):
        return f"<Zone {self.name} - Camera {self.camera_id}>"

class Recording(Base, TimestampMixin):
    """Modelo para grabaciones de video"""
    __tablename__ = 'recordings'
    
    id = Column(Integer, primary_key=True)
    camera_id = Column(Integer, ForeignKey('cameras.id'), nullable=False)
    start_time = Column(DateTime, nullable=False)
    end_time = Column(DateTime)
    duration = Column(Integer)  # en segundos
    file_path = Column(Text, nullable=False)
    file_size = Column(Integer)  # en bytes
    has_alerts = Column(Boolean, default=False, nullable=False)
    
    # Relaciones
    camera = relationship("Camera", back_populates="recordings")
    alerts = relationship("Alert", back_populates="recording")
    detected_objects = relationship("DetectedObject", back_populates="recording")
    
    def __repr__(self):
        return f"<Recording {self.id} - Camera {self.camera_id}>"

class Alert(Base, TimestampMixin):
    """Modelo para alertas"""
    __tablename__ = 'alerts'
    
    id = Column(Integer, primary_key=True)
    camera_id = Column(Integer, ForeignKey('cameras.id'), nullable=False)
    recording_id = Column(Integer, ForeignKey('recordings.id'))
    event_type = Column(String(50), nullable=False)  # intrusion, loitering, etc.
    priority = Column(String(20), nullable=False)  # high, medium, low
    timestamp = Column(DateTime, nullable=False)
    frame_number = Column(Integer)
    bbox = Column(JSON)  # [x1, y1, x2, y2]
    screenshot_path = Column(Text)
    zone_id = Column(Integer, ForeignKey('zones.id'))
    object_ids = Column(JSON)  # [id1, id2, ...]
    alert_metadata = Column(JSON)
    is_acknowledged = Column(Boolean, default=False, nullable=False)
    acknowledged_by = Column(Integer, ForeignKey('users.id'))
    acknowledged_at = Column(DateTime)
    notes = Column(Text)
    
    # Relaciones
    camera = relationship("Camera")
    recording = relationship("Recording", back_populates="alerts")
    zone = relationship("Zone", back_populates="alerts")
    acknowledger = relationship("User")
    
    def __repr__(self):
        return f"<Alert {self.id} - Type {self.event_type}>"

class DetectedObject(Base, TimestampMixin):
    """Modelo para objetos detectados"""
    __tablename__ = 'detected_objects'
    
    id = Column(Integer, primary_key=True)
    camera_id = Column(Integer, ForeignKey('cameras.id'), nullable=False)
    recording_id = Column(Integer, ForeignKey('recordings.id'))
    object_id = Column(String(50), nullable=False)
    class_id = Column(Integer, nullable=False)
    class_name = Column(String(50), nullable=False)
    first_seen = Column(DateTime, nullable=False)
    last_seen = Column(DateTime, nullable=False)
    path = Column(JSON)  # [[frame_num, x, y], ...]
    confidence = Column(Float)
    
    # Relaciones
    camera = relationship("Camera")
    recording = relationship("Recording", back_populates="detected_objects")
    
    def __repr__(self):
        return f"<DetectedObject {self.id} - Class {self.class_name}>"

class Statistic(Base, TimestampMixin):
    """Modelo para estadísticas"""
    __tablename__ = 'statistics'
    
    id = Column(Integer, primary_key=True)
    camera_id = Column(Integer, ForeignKey('cameras.id'), nullable=False)
    date = Column(DateTime, nullable=False)
    hour = Column(Integer, nullable=False)  # 0-23
    people_count = Column(Integer, default=0, nullable=False)
    vehicle_count = Column(Integer, default=0, nullable=False)
    alert_count = Column(Integer, default=0, nullable=False)
    zone_counts = Column(JSON)  # {"zone_id": {"class_id": count}}
    
    # Relaciones
    camera = relationship("Camera")
    
    def __repr__(self):
        return f"<Statistic {self.id} - Camera {self.camera_id} - Date {self.date}>"

class SystemLog(Base, TimestampMixin):
    """Modelo para logs del sistema"""
    __tablename__ = 'system_logs'
    
    id = Column(Integer, primary_key=True)
    log_level = Column(String(20), nullable=False)
    component = Column(String(50), nullable=False)
    message = Column(Text, nullable=False)
    user_id = Column(Integer, ForeignKey('users.id'))
    ip_address = Column(String(45))
    
    # Relaciones
    user = relationship("User")
    
    def __repr__(self):
        return f"<SystemLog {self.id} - Level {self.log_level}>"

class SystemConfig(Base, TimestampMixin):
    """Modelo para configuración del sistema"""
    __tablename__ = 'system_config'
    
    id = Column(Integer, primary_key=True)
    section = Column(String(50), nullable=False)
    key = Column(String(50), nullable=False)
    value = Column(JSON, nullable=False)
    description = Column(Text)
    updated_by = Column(Integer, ForeignKey('users.id'))
    
    # Relaciones
    user = relationship("User")
    
    # Restricción única para sección+clave
    __table_args__ = (
        {'mysql_charset': 'utf8mb4', 'mysql_collate': 'utf8mb4_unicode_ci'},
    )
    
    def __repr__(self):
        return f"<SystemConfig {self.section}.{self.key}>"

class Notification(Base, TimestampMixin):
    """Modelo para notificaciones de usuario"""
    __tablename__ = 'notifications'
    
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)
    type = Column(String(50), nullable=False)
    title = Column(String(100), nullable=False)
    message = Column(Text, nullable=False)
    is_read = Column(Boolean, default=False, nullable=False)
    read_at = Column(DateTime)
    
    # Relaciones
    user = relationship("User", back_populates="notifications")
    
    def __repr__(self):
        return f"<Notification {self.id} - User {self.user_id}>" 

```

### src\detection\object_detector.py
```py | 3582 bytes | Modificado: 2025-03-07 00:42:24.516925
```
import torch
import numpy as np
import cv2
from pathlib import Path

class ObjectDetector:
    def __init__(self, model_path="models/yolov5s.pt", confidence=0.5, device=None):
        self.confidence = confidence
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self._load_model(model_path)
        self.classes = self.model.names
        
    def _load_model(self, model_path):
        # Cargar modelo YOLOv5 desde PyTorch Hub o archivo local
        if Path(model_path).exists():
            model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)
        else:
            # Usar modelo preentrenado de YOLOv5
            model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
        
        model.to(self.device)
        model.conf = self.confidence  # Umbral de confianza
        return model
        
    def detect(self, frame):
        # Convertir frame a formato adecuado si es necesario
        if isinstance(frame, np.ndarray):
            # Ya es un array numpy
            pass
        elif hasattr(frame, 'numpy'):
            # Convertir a numpy si es un tensor
            frame = frame.numpy()
        
        # Realizar inferencia
        results = self.model(frame)
        
        # Procesar resultados
        detections = []
        for pred in results.xyxy[0]:  # xyxy formato es [x1, y1, x2, y2, conf, class]
            x1, y1, x2, y2, conf, cls = pred.cpu().numpy()
            if conf >= self.confidence:
                detections.append({
                    'class': self.classes[int(cls)],
                    'class_id': int(cls),
                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                    'confidence': float(conf)
                })
        
        return detections
    
    def filter_by_class(self, detections, class_names):
        """Filtra las detecciones por nombre de clase"""
        if not class_names:
            return detections
            
        return [d for d in detections if d['class'] in class_names]
    
    def draw_detections(self, frame, detections, color_map=None):
        """Dibuja los bounding boxes en el frame"""
        if color_map is None:
            color_map = {
                'person': (0, 255, 0),     # Verde para personas
                'car': (255, 0, 0),        # Azul para coches
                'truck': (255, 0, 255),    # Magenta para camiones
                'default': (0, 165, 255)   # Naranja por defecto
            }
        
        result_frame = frame.copy()
        
        for det in detections:
            bbox = det['bbox']
            cls = det['class']
            conf = det['confidence']
            
            # Obtener color para la clase o usar el default
            color = color_map.get(cls, color_map['default'])
            
            # Dibujar bounding box
            cv2.rectangle(
                result_frame, 
                (int(bbox[0]), int(bbox[1])), 
                (int(bbox[2]), int(bbox[3])), 
                color, 
                2
            )
            
            # Añadir etiqueta
            label = f"{cls} {conf:.2f}"
            cv2.putText(
                result_frame, 
                label, 
                (int(bbox[0]), int(bbox[1] - 10)), 
                cv2.FONT_HERSHEY_SIMPLEX, 
                0.5, 
                color, 
                2
            )
            
        return result_frame 
```

### src\events\event_bus.py
```py | 10496 bytes | Modificado: 2025-03-13 20:28:44.239096
```
import json
import logging
import asyncio
import redis.asyncio as redis
from typing import Dict, List, Any, Callable, Awaitable, Optional

class EventBus:
    """
    Sistema de eventos basado en Redis PubSub para vigIA
    Permite comunicación asíncrona entre componentes
    """
    
    def __init__(self, redis_host="localhost", redis_port=6379, 
                 redis_db=0, redis_password=None, retry_on_timeout=True):
        """Inicializa la conexión a Redis y configura el bus de eventos"""
        self.logger = logging.getLogger("EventBus")
        self.redis_config = {
            "host": redis_host,
            "port": redis_port,
            "db": redis_db,
            "password": redis_password,
            "retry_on_timeout": retry_on_timeout,
            "decode_responses": True  # Para recibir strings en vez de bytes
        }
        self.redis = redis.Redis(**self.redis_config)
        self.pubsub = None
        self.handlers: Dict[str, List[Callable[[str, Any], Awaitable[None]]]] = {}
        self.is_running = False
        self.listener_task = None
    
    async def connect(self) -> bool:
        """Establece conexión con Redis"""
        try:
            # Verificar conexión
            await self.redis.ping()
            self.pubsub = self.redis.pubsub()
            self.logger.info("Conexión exitosa a Redis")
            return True
        except redis.ConnectionError as e:
            self.logger.error(f"Error conectando a Redis: {e}")
            return False
        except Exception as e:
            self.logger.error(f"Error inesperado conectando a Redis: {e}")
            return False
    
    async def reconnect(self) -> bool:
        """Reconecta en caso de pérdida de conexión"""
        self.logger.info("Intentando reconexión a Redis...")
        try:
            # Cerrar conexiones existentes
            if self.pubsub:
                await self.pubsub.close()
            await self.redis.close()
            
            # Crear nuevas conexiones
            self.redis = redis.Redis(**self.redis_config)
            self.pubsub = self.redis.pubsub()
            
            # Verificar conexión
            await self.redis.ping()
            
            # Reactivar suscripciones
            if self.handlers:
                await self.pubsub.subscribe(*self.handlers.keys())
            
            self.logger.info("Reconexión exitosa a Redis")
            return True
        except Exception as e:
            self.logger.error(f"Error durante la reconexión a Redis: {e}")
            return False
    
    async def publish(self, channel: str, message: Any) -> bool:
        """Publica un mensaje en un canal específico"""
        try:
            # Convertir mensaje a JSON si no es string
            if not isinstance(message, str):
                message = json.dumps(message)
            
            # Publicar mensaje
            result = await self.redis.publish(channel, message)
            if result > 0:
                self.logger.debug(f"Mensaje publicado en {channel}, recibido por {result} suscriptores")
            return True
        except redis.ConnectionError:
            self.logger.error("Error de conexión al publicar mensaje, intentando reconectar")
            if await self.reconnect():
                # Reintentar después de reconexión
                return await self.publish(channel, message)
            return False
        except Exception as e:
            self.logger.error(f"Error publicando mensaje: {e}")
            return False
    
    async def subscribe(self, channel: str, handler: Callable[[str, Any], Awaitable[None]]) -> bool:
        """Suscribe a un canal y registra un manejador para los mensajes"""
        try:
            # Inicializar lista de handlers si no existe
            if channel not in self.handlers:
                self.handlers[channel] = []
                # Suscribir al canal en Redis
                if self.pubsub:
                    await self.pubsub.subscribe(channel)
            
            # Registrar handler
            self.handlers[channel].append(handler)
            self.logger.info(f"Suscrito al canal: {channel}")
            
            # Iniciar listener si no está corriendo
            if not self.is_running:
                await self.start_listener()
            
            return True
        except redis.ConnectionError:
            self.logger.error("Error de conexión al suscribirse, intentando reconectar")
            if await self.reconnect():
                # Reintentar después de reconexión
                return await self.subscribe(channel, handler)
            return False
        except Exception as e:
            self.logger.error(f"Error suscribiéndose al canal {channel}: {e}")
            return False
    
    async def unsubscribe(self, channel: str, handler: Optional[Callable] = None) -> bool:
        """Cancela suscripción a un canal específico"""
        try:
            if channel in self.handlers:
                if handler:
                    # Eliminar handler específico
                    self.handlers[channel] = [h for h in self.handlers[channel] if h != handler]
                    # Si no quedan handlers, cancelar suscripción al canal
                    if not self.handlers[channel]:
                        del self.handlers[channel]
                        if self.pubsub:
                            await self.pubsub.unsubscribe(channel)
                else:
                    # Eliminar todos los handlers y cancelar suscripción
                    del self.handlers[channel]
                    if self.pubsub:
                        await self.pubsub.unsubscribe(channel)
                
                self.logger.info(f"Cancelada suscripción al canal: {channel}")
                return True
            return False
        except Exception as e:
            self.logger.error(f"Error cancelando suscripción al canal {channel}: {e}")
            return False
    
    async def start_listener(self) -> None:
        """Inicia el proceso de escucha de mensajes"""
        if self.is_running:
            return
        
        if not self.pubsub:
            if not await self.connect():
                self.logger.error("No se pudo iniciar listener: conexión a Redis fallida")
                return
        
        # Suscribirse a todos los canales registrados
        if self.handlers:
            await self.pubsub.subscribe(*self.handlers.keys())
        
        self.is_running = True
        self.listener_task = asyncio.create_task(self._message_listener())
        self.logger.info("Iniciado listener de mensajes")
    
    async def stop_listener(self) -> None:
        """Detiene el proceso de escucha de mensajes"""
        self.is_running = False
        if self.listener_task:
            self.listener_task.cancel()
            try:
                await self.listener_task
            except asyncio.CancelledError:
                pass
            self.listener_task = None
        
        # Cancelar todas las suscripciones
        if self.pubsub and self.handlers:
            await self.pubsub.unsubscribe(*self.handlers.keys())
        
        self.logger.info("Detenido listener de mensajes")
    
    async def _message_listener(self) -> None:
        """Proceso para escuchar mensajes (loop interno)"""
        try:
            async for message in self.pubsub.listen():
                if not self.is_running:
                    break
                
                # Ignorar mensajes de suscripción/desuscripción
                if message["type"] not in ("message", "pmessage"):
                    continue
                
                channel = message["channel"]
                data = message["data"]
                
                # Procesar mensaje si hay handlers registrados
                if channel in self.handlers:
                    # Convertir de JSON si es posible
                    try:
                        if isinstance(data, str):
                            data = json.loads(data)
                    except json.JSONDecodeError:
                        # No es JSON, usar el mensaje tal cual
                        pass
                    
                    # Ejecutar todos los handlers registrados para este canal
                    for handler in self.handlers[channel]:
                        try:
                            await handler(channel, data)
                        except Exception as e:
                            self.logger.error(f"Error en handler para canal {channel}: {e}")
        
        except redis.ConnectionError:
            self.logger.error("Conexión perdida en el listener, intentando reconectar")
            self.is_running = False
            
            # Intentar reconectar
            if await self.reconnect():
                # Reiniciar listener si reconexión exitosa
                await self.start_listener()
            else:
                self.logger.error("No se pudo reconectar, listener detenido")
        
        except asyncio.CancelledError:
            # Cancelación normal, no es un error
            pass
        
        except Exception as e:
            self.logger.error(f"Error en listener de mensajes: {e}")
            self.is_running = False
    
    async def close(self) -> None:
        """Cierra todas las conexiones y detiene el listener"""
        await self.stop_listener()
        
        if self.pubsub:
            await self.pubsub.close()
            self.pubsub = None
        
        if self.redis:
            await self.redis.close()
        
        self.logger.info("EventBus cerrado")

class EventTypes:
    """Constantes para tipos de eventos comunes"""
    OBJECT_DETECTED = "object_detected"
    OBJECT_TRACKED = "object_tracked"
    BEHAVIOR_DETECTED = "behavior_detected"
    ALERT_GENERATED = "alert_generated"
    RECORDING_STARTED = "recording_started"
    RECORDING_STOPPED = "recording_stopped"
    SYSTEM_ERROR = "system_error"
    ACCESS_GRANTED = "access_granted"
    ACCESS_DENIED = "access_denied"
    PERIMETER_BREACH = "perimeter_breach"
    THEFT_DETECTED = "theft_detected" 
```

### src\frontend\dashboard\camera_view_panel.js
```js | 30291 bytes | Modificado: 2025-03-07 01:01:21.493624
```
/**
 * Panel de Visualización de Cámaras
 * 
 * Gestiona la visualización y control de múltiples cámaras de seguridad.
 */
class CameraViewPanel {
    /**
     * Inicializa el panel de cámaras
     * @param {string} containerId ID del contenedor HTML
     * @param {string} apiEndpoint Endpoint de la API para cámaras
     */
    constructor(containerId, apiEndpoint) {
        this.container = document.getElementById(containerId);
        if (!this.container) {
            console.error(`Container with ID ${containerId} not found`);
            return;
        }
        
        this.apiEndpoint = apiEndpoint;
        this.cameras = new Map();
        this.activeStreams = new Map();
        this.selectedCamera = null;
        this.layout = '2x2';  // Opciones: '1x1', '2x2', '3x3', 'custom'
        this.eventListeners = {
            cameraSelected: []
        };
        
        this.initialize();
    }
    
    /**
     * Inicializar componentes de la UI
     */
    initialize() {
        // Crear estructura básica si no existe
        if (!document.getElementById('camera-grid')) {
            this.container.innerHTML = `
                <div class="camera-controls d-flex justify-content-between mb-3">
                    <div class="layout-controls btn-group">
                        <button class="btn btn-outline-secondary layout-btn" data-layout="1x1">
                            <i class="fas fa-square"></i>
                        </button>
                        <button class="btn btn-outline-secondary layout-btn active" data-layout="2x2">
                            <i class="fas fa-th-large"></i>
                        </button>
                        <button class="btn btn-outline-secondary layout-btn" data-layout="3x3">
                            <i class="fas fa-th"></i>
                        </button>
                    </div>
                    <div class="camera-actions">
                        <select id="camera-selector" class="custom-select">
                            <option value="">Seleccionar cámara...</option>
                        </select>
                        <button id="refresh-cameras" class="btn btn-primary ml-2">
                            <i class="fas fa-sync-alt"></i>
                        </button>
                    </div>
                </div>
                <div id="camera-grid" class="camera-grid grid-2x2">
                    <div class="camera-placeholder text-center p-5">
                        <i class="fas fa-video fa-3x mb-3"></i>
                        <p>No hay cámaras disponibles</p>
                    </div>
                </div>
                <div id="camera-detail-panel" class="camera-detail d-none">
                    <div class="detail-header d-flex justify-content-between">
                        <h3 id="camera-detail-title">Detalles de la Cámara</h3>
                        <button id="close-camera-detail" class="btn btn-sm btn-light">
                            <i class="fas fa-times"></i>
                        </button>
                    </div>
                    <div id="camera-details-content"></div>
                </div>
            `;
            
            // Configurar event listeners
            this.setupEventListeners();
        }
        
        // Cargar cámaras iniciales
        this.loadCameras();
    }
    
    /**
     * Configurar event listeners para controles de la UI
     */
    setupEventListeners() {
        // Botones de layout
        const layoutButtons = document.querySelectorAll('.layout-btn');
        layoutButtons.forEach(button => {
            button.addEventListener('click', () => {
                // Actualizar clase activa
                layoutButtons.forEach(btn => btn.classList.remove('active'));
                button.classList.add('active');
                
                // Cambiar layout
                const layout = button.getAttribute('data-layout');
                this.changeLayout(layout);
            });
        });
        
        // Selector de cámara
        const cameraSelector = document.getElementById('camera-selector');
        if (cameraSelector) {
            cameraSelector.addEventListener('change', () => {
                const cameraId = cameraSelector.value;
                if (cameraId) {
                    this.focusCamera(cameraId);
                }
            });
        }
        
        // Botón de actualizar
        const refreshBtn = document.getElementById('refresh-cameras');
        if (refreshBtn) {
            refreshBtn.addEventListener('click', () => {
                this.loadCameras();
            });
        }
        
        // Cerrar detalles de cámara
        const closeDetailBtn = document.getElementById('close-camera-detail');
        if (closeDetailBtn) {
            closeDetailBtn.addEventListener('click', () => {
                this.hideCameraDetails();
            });
        }
    }
    
    /**
     * Cargar lista de cámaras desde la API
     */
    loadCameras() {
        const cameraGrid = document.getElementById('camera-grid');
        if (cameraGrid) {
            cameraGrid.innerHTML = `
                <div class="loading-indicator text-center p-5">
                    <div class="spinner-border text-primary" role="status">
                        <span class="sr-only">Cargando...</span>
                    </div>
                    <p class="mt-2">Cargando cámaras...</p>
                </div>
            `;
        }
        
        fetch(this.apiEndpoint)
            .then(response => response.json())
            .then(data => {
                // Almacenar cámaras
                this.cameras.clear();
                data.forEach(camera => {
                    this.cameras.set(camera.id, camera);
                });
                
                // Actualizar selector
                this.updateCameraSelector();
                
                // Renderizar grid
                this.renderCameraGrid();
            })
            .catch(error => {
                console.error('Error loading cameras:', error);
                // Mostrar mensaje de error
                const cameraGrid = document.getElementById('camera-grid');
                if (cameraGrid) {
                    cameraGrid.innerHTML = `
                        <div class="alert alert-danger m-3">
                            Error al cargar cámaras. Por favor, intente nuevamente.
                        </div>
                    `;
                }
            });
    }
    
    /**
     * Actualizar selector de cámaras
     */
    updateCameraSelector() {
        const selector = document.getElementById('camera-selector');
        if (!selector) return;
        
        // Guardar selección actual
        const currentSelection = selector.value;
        
        // Limpiar opciones existentes, manteniendo la primera
        while (selector.options.length > 1) {
            selector.remove(1);
        }
        
        // Agregar opciones de cámaras
        this.cameras.forEach(camera => {
            const option = document.createElement('option');
            option.value = camera.id;
            option.textContent = camera.name;
            selector.appendChild(option);
        });
        
        // Restaurar selección si existe
        if (currentSelection && Array.from(this.cameras.keys()).includes(currentSelection)) {
            selector.value = currentSelection;
        }
    }
    
    /**
     * Cambiar layout de la cuadrícula
     */
    changeLayout(layout) {
        this.layout = layout;
        
        const grid = document.getElementById('camera-grid');
        if (!grid) return;
        
        // Quitar clases existentes
        grid.classList.remove('grid-1x1', 'grid-2x2', 'grid-3x3', 'grid-custom');
        
        // Agregar nueva clase
        grid.classList.add(`grid-${layout}`);
        
        // Renderizar cámaras con nuevo layout
        this.renderCameraGrid();
    }
    
    /**
     * Renderizar cuadrícula de cámaras
     */
    renderCameraGrid() {
        const grid = document.getElementById('camera-grid');
        if (!grid) return;
        
        // Determinar cuántas cámaras mostrar según layout
        let camCount;
        switch (this.layout) {
            case '1x1': camCount = 1; break;
            case '2x2': camCount = 4; break;
            case '3x3': camCount = 9; break;
            case 'custom': camCount = 6; break;
            default: camCount = 4;
        }
        
        // Comprobar si hay cámaras
        if (this.cameras.size === 0) {
            grid.innerHTML = `
                <div class="camera-placeholder text-center p-5">
                    <i class="fas fa-video-slash fa-3x mb-3"></i>
                    <p>No hay cámaras disponibles</p>
                </div>
            `;
            return;
        }
        
        // Limpiar grid
        grid.innerHTML = '';
        
        // Detener streams activos
        this.stopAllStreams();
        
        // Seleccionar cámaras a mostrar
        let camerasToShow;
        if (this.selectedCamera && this.layout === '1x1') {
            // En vista de una sola cámara, mostrar la seleccionada
            camerasToShow = [this.cameras.get(this.selectedCamera)];
        } else {
            // En otros layouts, mostrar las primeras N cámaras
            camerasToShow = Array.from(this.cameras.values()).slice(0, camCount);
        }
        
        // Crear elementos para cada cámara
        camerasToShow.forEach(camera => {
            const cameraElement = document.createElement('div');
            cameraElement.className = 'camera-cell';
            cameraElement.id = `camera-cell-${camera.id}`;
            
            cameraElement.innerHTML = `
                <div class="camera-header">
                    <span class="camera-name">${camera.name}</span>
                    <span class="camera-status ${camera.status === 'online' ? 'online' : 'offline'}">
                        ${camera.status === 'online' ? 'EN LÍNEA' : 'FUERA DE LÍNEA'}
                    </span>
                </div>
                <div class="camera-stream" id="stream-${camera.id}">
                    ${camera.status === 'online' 
                        ? '<div class="loading-stream"><span class="spinner-border spinner-border-sm"></span> Cargando feed...</div>'
                        : '<div class="offline-message">Cámara desconectada</div>'
                    }
                </div>
                <div class="camera-controls">
                    <button class="btn btn-sm btn-info camera-details-btn" data-camera-id="${camera.id}">
                        <i class="fas fa-info-circle"></i>
                    </button>
                    <button class="btn btn-sm btn-primary camera-fullscreen-btn" data-camera-id="${camera.id}">
                        <i class="fas fa-expand"></i>
                    </button>
                    ${camera.ptz_capable 
                        ? `<button class="btn btn-sm btn-secondary camera-ptz-btn" data-camera-id="${camera.id}">
                            <i class="fas fa-arrows-alt"></i>
                           </button>`
                        : ''
                    }
                </div>
            `;
            
            grid.appendChild(cameraElement);
            
            // Agregar event listeners a los botones
            cameraElement.querySelector('.camera-details-btn').addEventListener('click', () => {
                this.showCameraDetails(camera.id);
            });
            
            cameraElement.querySelector('.camera-fullscreen-btn').addEventListener('click', () => {
                this.focusCamera(camera.id);
            });
            
            if (camera.ptz_capable) {
                cameraElement.querySelector('.camera-ptz-btn').addEventListener('click', () => {
                    this.openPTZControls(camera.id);
                });
            }
            
            // Iniciar streaming si la cámara está online
            if (camera.status === 'online') {
                this.startStreaming(camera.id);
            }
        });
        
        // Si está en vista '1x1' y hay una cámara seleccionada, mostrar controles adicionales
        if (this.layout === '1x1' && this.selectedCamera) {
            this.showEnhancedControls(this.selectedCamera);
        }
    }
    
    /**
     * Iniciar streaming para una cámara
     */
    startStreaming(cameraId) {
        const camera = this.cameras.get(cameraId);
        if (!camera || camera.status !== 'online') return;
        
        const streamContainer = document.getElementById(`stream-${cameraId}`);
        if (!streamContainer) return;
        
        // En un sistema real, aquí se conectaría al endpoint de streaming
        // Por ahora simularemos con un placeholder de imagen o video
        
        if (camera.stream_type === 'hls') {
            // Streaming HLS (HTTP Live Streaming)
            streamContainer.innerHTML = `
                <video id="video-${cameraId}" class="camera-video" controls autoplay muted></video>
            `;
            
            const videoElement = document.getElementById(`video-${cameraId}`);
            
            // En una implementación real, cargaríamos la librería HLS.js
            // y configuraríamos el streaming. Aquí es simulado.
            setTimeout(() => {
                videoElement.poster = camera.thumbnail_url || 'assets/camera-placeholder.jpg';
                
                // Simular carga de video
                if (camera.demo_video_url) {
                    videoElement.src = camera.demo_video_url;
                    videoElement.play().catch(e => console.log('Autoplay prevented:', e));
                }
            }, 500);
            
            // Almacenar referencia del stream activo
            this.activeStreams.set(cameraId, {
                type: 'hls',
                element: videoElement
            });
            
        } else if (camera.stream_type === 'mjpeg') {
            // Streaming MJPEG
            streamContainer.innerHTML = `
                <img id="mjpeg-${cameraId}" class="camera-feed" 
                    src="${camera.stream_url || camera.thumbnail_url || 'assets/camera-placeholder.jpg'}" 
                    alt="${camera.name}">
            `;
            
            // Almacenar referencia del stream activo
            this.activeStreams.set(cameraId, {
                type: 'mjpeg',
                element: document.getElementById(`mjpeg-${cameraId}`)
            });
            
        } else {
            // Tipo de streaming no soportado, mostrar imagen estática
            streamContainer.innerHTML = `
                <img class="camera-feed" 
                    src="${camera.thumbnail_url || 'assets/camera-placeholder.jpg'}" 
                    alt="${camera.name}">
                <div class="stream-overlay">Vista previa</div>
            `;
        }
    }
    
    /**
     * Detener streaming para una cámara
     */
    stopStreaming(cameraId) {
        if (!this.activeStreams.has(cameraId)) return;
        
        const stream = this.activeStreams.get(cameraId);
        
        if (stream.type === 'hls' && stream.element) {
            // Detener reproducción de video
            stream.element.pause();
            stream.element.src = '';
        }
        
        // Eliminar del registro de streams activos
        this.activeStreams.delete(cameraId);
    }
    
    /**
     * Detener todos los streams activos
     */
    stopAllStreams() {
        this.activeStreams.forEach((stream, cameraId) => {
            this.stopStreaming(cameraId);
        });
        
        this.activeStreams.clear();
    }
    
    /**
     * Mostrar detalles de una cámara
     */
    showCameraDetails(cameraId) {
        const camera = this.cameras.get(cameraId);
        if (!camera) return;
        
        const detailPanel = document.getElementById('camera-detail-panel');
        const detailsContent = document.getElementById('camera-details-content');
        
        if (!detailPanel || !detailsContent) return;
        
        // Actualizar título
        document.getElementById('camera-detail-title').textContent = camera.name;
        
        // Construir contenido de detalles
        detailsContent.innerHTML = `
            <div class="camera-metadata">
                <div class="row">
                    <div class="col-md-6">
                        <dl>
                            <dt>ID:</dt>
                            <dd>${camera.id}</dd>
                            
                            <dt>Ubicación:</dt>
                            <dd>${camera.location || 'No especificada'}</dd>
                            
                            <dt>Estado:</dt>
                            <dd>
                                <span class="badge badge-${camera.status === 'online' ? 'success' : 'danger'}">
                                    ${camera.status === 'online' ? 'En línea' : 'Fuera de línea'}
                                </span>
                            </dd>
                            
                            <dt>Tipo:</dt>
                            <dd>${camera.type || 'Standard'}</dd>
                        </dl>
                    </div>
                    <div class="col-md-6">
                        <dl>
                            <dt>Modelo:</dt>
                            <dd>${camera.model || 'Desconocido'}</dd>
                            
                            <dt>Resolución:</dt>
                            <dd>${camera.resolution || 'Estándar'}</dd>
                            
                            <dt>PTZ:</dt>
                            <dd>${camera.ptz_capable ? 'Sí' : 'No'}</dd>
                            
                            <dt>Última actualización:</dt>
                            <dd>${camera.last_update ? new Date(camera.last_update * 1000).toLocaleString() : 'N/A'}</dd>
                        </dl>
                    </div>
                </div>
            </div>
            
            <div class="camera-actions mt-3">
                <button class="btn btn-sm btn-primary camera-focus-btn" data-camera-id="${camera.id}">
                    <i class="fas fa-search-plus mr-1"></i> Enfocar
                </button>
                
                ${camera.ptz_capable ? `
                    <button class="btn btn-sm btn-secondary camera-ptz-panel-btn" data-camera-id="${camera.id}">
                        <i class="fas fa-arrows-alt mr-1"></i> Controles PTZ
                    </button>
                ` : ''}
                
                ${camera.recording_enabled ? `
                    <button class="btn btn-sm btn-info camera-recordings-btn" data-camera-id="${camera.id}">
                        <i class="fas fa-video mr-1"></i> Ver grabaciones
                    </button>
                ` : ''}
                
                <button class="btn btn-sm btn-warning camera-settings-btn" data-camera-id="${camera.id}">
                    <i class="fas fa-cog mr-1"></i> Configuración
                </button>
            </div>
            
            ${camera.map_location ? `
                <div class="camera-map mt-3">
                    <strong>Ubicación en mapa:</strong>
                    <div class="camera-map-container" id="camera-map-${camera.id}">
                        <!-- Aquí se cargaría un mapa en la implementación real -->
                        <div class="map-placeholder">Mapa de ubicación</div>
                    </div>
                </div>
            ` : ''}
        `;
        
        // Mostrar panel
        detailPanel.classList.remove('d-none');
        
        // Configurar event listeners para botones
        detailsContent.querySelector('.camera-focus-btn').addEventListener('click', () => {
            this.focusCamera(camera.id);
            this.hideCameraDetails();
        });
        
        if (camera.ptz_capable) {
            detailsContent.querySelector('.camera-ptz-panel-btn').addEventListener('click', () => {
                this.openPTZControls(camera.id);
            });
        }
        
        if (camera.recording_enabled) {
            detailsContent.querySelector('.camera-recordings-btn').addEventListener('click', () => {
                this.openRecordings(camera.id);
            });
        }
        
        detailsContent.querySelector('.camera-settings-btn').addEventListener('click', () => {
            this.openCameraSettings(camera.id);
        });
    }
    
    /**
     * Ocultar panel de detalles
     */
    hideCameraDetails() {
        const detailPanel = document.getElementById('camera-detail-panel');
        if (detailPanel) {
            detailPanel.classList.add('d-none');
        }
    }
    
    /**
     * Enfocar una cámara (modo 1x1)
     */
    focusCamera(cameraId) {
        this.selectedCamera = cameraId;
        this.changeLayout('1x1');
        
        // Notificar a listeners
        this.triggerCameraSelected(cameraId);
    }
    
    /**
     * Mostrar controles mejorados para una cámara en modo 1x1
     */
    showEnhancedControls(cameraId) {
        const camera = this.cameras.get(cameraId);
        if (!camera) return;
        
        const cameraCell = document.getElementById(`camera-cell-${cameraId}`);
        if (!cameraCell) return;
        
        // Añadir controles adicionales al contenedor principal
        const enhancedControls = document.createElement('div');
        enhancedControls.className = 'enhanced-controls mt-3';
        enhancedControls.innerHTML = `
            <div class="d-flex justify-content-between align-items-center">
                <div class="camera-info">
                    <h4>${camera.name}</h4>
                    <p class="text-muted">${camera.location || 'Sin ubicación'}</p>
                </div>
                <div class="d-flex">
                    <button class="btn btn-outline-secondary back-to-grid-btn mr-2">
                        <i class="fas fa-th-large mr-1"></i> Volver a cuadrícula
                    </button>
                    <button class="btn btn-outline-primary camera-snapshot-btn">
                        <i class="fas fa-camera mr-1"></i> Capturar imagen
                    </button>
                </div>
            </div>
            
            ${camera.ptz_capable ? `
                <div class="camera-ptz-controls mt-3" id="ptz-controls-${cameraId}">
                    <div class="d-flex justify-content-between">
                        <div class="direction-controls">
                            <div class="btn-group-vertical">
                                <button class="btn btn-sm btn-secondary ptz-up-btn" data-direction="up">
                                    <i class="fas fa-arrow-up"></i>
                                </button>
                                <button class="btn btn-sm btn-secondary ptz-down-btn" data-direction="down">
                                    <i class="fas fa-arrow-down"></i>
                                </button>
                            </div>
                            <div class="btn-group mt-2">
                                <button class="btn btn-sm btn-secondary ptz-left-btn" data-direction="left">
                                    <i class="fas fa-arrow-left"></i>
                                </button>
                                <button class="btn btn-sm btn-secondary ptz-home-btn" data-direction="home">
                                    <i class="fas fa-home"></i>
                                </button>
                                <button class="btn btn-sm btn-secondary ptz-right-btn" data-direction="right">
                                    <i class="fas fa-arrow-right"></i>
                                </button>
                            </div>
                        </div>
                        <div class="zoom-controls">
                            <button class="btn btn-sm btn-secondary ptz-zoom-in-btn" data-zoom="in">
                                <i class="fas fa-search-plus"></i>
                            </button>
                            <button class="btn btn-sm btn-secondary mt-2 ptz-zoom-out-btn" data-zoom="out">
                                <i class="fas fa-search-minus"></i>
                            </button>
                        </div>
                    </div>
                </div>
            ` : ''}
        `;
        
        cameraCell.appendChild(enhancedControls);
        
        // Configurar eventos para los controles
        enhancedControls.querySelector('.back-to-grid-btn').addEventListener('click', () => {
            this.selectedCamera = null;
            this.changeLayout('2x2'); // Volver a layout predeterminado
        });
        
        enhancedControls.querySelector('.camera-snapshot-btn').addEventListener('click', () => {
            this.takeSnapshot(cameraId);
        });
        
        // Configurar controles PTZ si están disponibles
        if (camera.ptz_capable) {
            const ptzControls = document.getElementById(`ptz-controls-${cameraId}`);
            
            ptzControls.querySelectorAll('.btn[data-direction]').forEach(btn => {
                btn.addEventListener('click', () => {
                    const direction = btn.getAttribute('data-direction');
                    this.sendPTZCommand(cameraId, direction);
                });
            });
            
            ptzControls.querySelectorAll('.btn[data-zoom]').forEach(btn => {
                btn.addEventListener('click', () => {
                    const zoom = btn.getAttribute('data-zoom');
                    this.sendPTZCommand(cameraId, zoom === 'in' ? 'zoom_in' : 'zoom_out');
                });
            });
        }
    }
    
    /**
     * Enviar comando PTZ a una cámara
     */
    sendPTZCommand(cameraId, command) {
        console.log(`Sending PTZ command: ${command} to camera ${cameraId}`);
        
        // En una implementación real, enviaríamos el comando a la API
        fetch(`${this.apiEndpoint}/${cameraId}/ptz`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ command })
        })
        .then(response => response.json())
        .then(data => {
            console.log('PTZ command response:', data);
        })
        .catch(error => {
            console.error('Error sending PTZ command:', error);
        });
    }
    
    /**
     * Tomar una captura de pantalla de la cámara
     */
    takeSnapshot(cameraId) {
        console.log(`Taking snapshot from camera ${cameraId}`);
        
        // En una implementación real, solicitaríamos una captura a la API
        fetch(`${this.apiEndpoint}/${cameraId}/snapshot`, {
            method: 'POST'
        })
        .then(response => response.blob())
        .then(blob => {
            // Crear URL para la imagen
            const url = URL.createObjectURL(blob);
            
            // Abrir en nueva ventana o descargar
            const a = document.createElement('a');
            a.href = url;
            a.download = `snapshot_${cameraId}_${new Date().getTime()}.jpg`;
            a.click();
            
            // Liberar URL
            URL.revokeObjectURL(url);
        })
        .catch(error => {
            console.error('Error taking snapshot:', error);
        });
    }
    
    /**
     * Abrir panel de control PTZ
     */
    openPTZControls(cameraId) {
        // Si estamos en modo 1x1, los controles ya se muestran
        if (this.layout === '1x1' && this.selectedCamera === cameraId) {
            return;
        }
        
        // Enfocar la cámara y mostrar los controles
        this.focusCamera(cameraId);
    }
    
    /**
     * Abrir panel de grabaciones
     */
    openRecordings(cameraId) {
        console.log(`Opening recordings for camera ${cameraId}`);
        
        // Aquí implementaríamos la apertura de una modal o panel con grabaciones
        // En una aplicación real, esto sería un componente mucho más complejo
    }
    
    /**
     * Abrir configuración de cámara
     */
    openCameraSettings(cameraId) {
        console.log(`Opening settings for camera ${cameraId}`);
        
        // Aquí implementaríamos la apertura de un panel de configuración
    }
    
    /**
     * Registrar un callback para el evento de selección de cámara
     */
    onCameraSelected(callback) {
        if (typeof callback === 'function') {
            this.eventListeners.cameraSelected.push(callback);
        }
    }
    
    /**
     * Notificar a los suscriptores sobre la selección de una cámara
     */
    triggerCameraSelected(cameraId) {
        this.eventListeners.cameraSelected.forEach(callback => {
            try {
                callback(cameraId, this.cameras.get(cameraId));
            } catch (error) {
                console.error('Error in camera selected callback:', error);
            }
        });
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { CameraViewPanel };
} 
```

### src\frontend\dashboard\security_alerts.js
```js | 29084 bytes | Modificado: 2025-03-07 00:58:43.237016
```
/**
 * Panel de Alertas de Seguridad para el Dashboard
 * 
 * Gestiona la visualización y manejo de alertas de seguridad en tiempo real.
 */
class SecurityAlertsDashboard {
    /**
     * Inicializa el panel de alertas
     * @param {string} containerId ID del contenedor HTML
     * @param {string} apiEndpoint Endpoint de la API para alertas
     */
    constructor(containerId, apiEndpoint) {
        this.container = document.getElementById(containerId);
        if (!this.container) {
            console.error(`Container with ID ${containerId} not found`);
            return;
        }
        
        this.apiEndpoint = apiEndpoint;
        this.alertsQueue = [];
        this.activeAlerts = new Map();
        this.acknowledgedAlerts = new Map();
        this.eventListeners = {
            alertSelected: [],
            userAction: []
        };
        
        this.initialize();
    }
    
    /**
     * Inicializar componentes de la UI
     */
    initialize() {
        // Crear estructura básica si no existe
        if (!document.getElementById('alerts-container')) {
            this.container.innerHTML = `
                <div class="alerts-controls">
                    <div class="d-flex justify-content-between mb-3">
                        <div class="filters">
                            <select id="priority-filter" class="custom-select">
                                <option value="all">Todas las prioridades</option>
                                <option value="high">Alta prioridad</option>
                                <option value="medium">Media prioridad</option>
                                <option value="low">Baja prioridad</option>
                            </select>
                            <select id="type-filter" class="custom-select ml-2">
                                <option value="all">Todos los tipos</option>
                                <option value="intrusion">Intrusión</option>
                                <option value="theft_detected">Robo</option>
                                <option value="loitering">Merodeo</option>
                                <option value="perimeter_breach">Violación de Perímetro</option>
                                <option value="tailgating">Acceso no autorizado</option>
                            </select>
                        </div>
                        <div class="view-controls">
                            <button id="view-active" class="btn btn-primary active">Activas</button>
                            <button id="view-acknowledged" class="btn btn-secondary">Reconocidas</button>
                        </div>
                    </div>
                    <div class="search-box mb-3">
                        <input type="text" id="alert-search" class="form-control" 
                            placeholder="Buscar por ID, ubicación, tipo...">
                    </div>
                </div>
                <div id="alerts-container" class="alerts-list">
                    <div class="alert-placeholder text-center p-5 text-muted">
                        <i class="fas fa-bell fa-3x mb-3"></i>
                        <p>No hay alertas para mostrar</p>
                    </div>
                </div>
                <div id="alert-detail-panel" class="alert-detail d-none">
                    <div class="detail-header d-flex justify-content-between">
                        <h3 id="detail-title">Detalles de la Alerta</h3>
                        <button id="close-detail" class="btn btn-sm btn-light">
                            <i class="fas fa-times"></i>
                        </button>
                    </div>
                    <div id="alert-details-content"></div>
                </div>
            `;
            
            // Configurar event listeners
            this.setupEventListeners();
        }
        
        // Cargar alertas iniciales
        this.loadAlerts();
    }
    
    /**
     * Configurar event listeners para controles de la UI
     */
    setupEventListeners() {
        // Filtro por prioridad
        const priorityFilter = document.getElementById('priority-filter');
        if (priorityFilter) {
            priorityFilter.addEventListener('change', () => {
                this.applyFilters();
            });
        }
        
        // Filtro por tipo
        const typeFilter = document.getElementById('type-filter');
        if (typeFilter) {
            typeFilter.addEventListener('change', () => {
                this.applyFilters();
            });
        }
        
        // Búsqueda
        const searchBox = document.getElementById('alert-search');
        if (searchBox) {
            searchBox.addEventListener('input', () => {
                this.applyFilters();
            });
        }
        
        // Vista de alertas activas
        const viewActiveBtn = document.getElementById('view-active');
        if (viewActiveBtn) {
            viewActiveBtn.addEventListener('click', () => {
                viewActiveBtn.classList.add('active');
                document.getElementById('view-acknowledged').classList.remove('active');
                this.showActiveAlerts();
            });
        }
        
        // Vista de alertas reconocidas
        const viewAckBtn = document.getElementById('view-acknowledged');
        if (viewAckBtn) {
            viewAckBtn.addEventListener('click', () => {
                viewAckBtn.classList.add('active');
                document.getElementById('view-active').classList.remove('active');
                this.showAcknowledgedAlerts();
            });
        }
        
        // Cerrar panel de detalles
        const closeDetailBtn = document.getElementById('close-detail');
        if (closeDetailBtn) {
            closeDetailBtn.addEventListener('click', () => {
                this.hideAlertDetails();
            });
        }
        
        // Conectar con WebSocket
        this.connectWebSocket();
    }
    
    /**
     * Cargar alertas desde la API
     */
    loadAlerts() {
        fetch(this.apiEndpoint)
            .then(response => response.json())
            .then(data => {
                // Limpiar colecciones
                this.activeAlerts.clear();
                this.acknowledgedAlerts.clear();
                this.alertsQueue = [];
                
                // Clasificar alertas
                data.forEach(alert => {
                    if (alert.status === 'acknowledged') {
                        this.acknowledgedAlerts.set(alert.id, alert);
                    } else {
                        this.activeAlerts.set(alert.id, alert);
                        this.alertsQueue.push(alert.id);
                    }
                });
                
                // Renderizar alertas
                this.renderAlerts();
            })
            .catch(error => {
                console.error('Error loading alerts:', error);
                // Mostrar mensaje de error
                const alertsContainer = document.getElementById('alerts-container');
                if (alertsContainer) {
                    alertsContainer.innerHTML = `
                        <div class="alert alert-danger m-3">
                            Error al cargar alertas. Por favor, intente nuevamente.
                        </div>
                    `;
                }
            });
    }
    
    /**
     * Conectar con WebSocket para alertas en tiempo real
     */
    connectWebSocket() {
        const wsUrl = this.apiEndpoint.replace(/^http/, 'ws') + '/ws';
        const socket = new WebSocket(wsUrl);
        
        socket.onmessage = (event) => {
            try {
                const data = JSON.parse(event.data);
                if (data.type === 'new_alert') {
                    this.addAlert(data.alert);
                } else if (data.type === 'update_alert') {
                    this.updateAlert(data.alert.id, data.alert);
                }
            } catch (error) {
                console.error('Error parsing WebSocket message:', error);
            }
        };
        
        socket.onclose = () => {
            // Reconectar después de un tiempo
            setTimeout(() => this.connectWebSocket(), 5000);
        };
    }
    
    /**
     * Aplicar filtros a las alertas
     */
    applyFilters() {
        const priorityFilter = document.getElementById('priority-filter').value;
        const typeFilter = document.getElementById('type-filter').value;
        const searchTerm = document.getElementById('alert-search').value.toLowerCase();
        
        // Determinar qué colección estamos mostrando
        const isShowingActive = document.getElementById('view-active').classList.contains('active');
        const alerts = isShowingActive ? this.activeAlerts : this.acknowledgedAlerts;
        
        // Filtrar alertas
        const filteredAlerts = Array.from(alerts.values()).filter(alert => {
            // Filtro de prioridad
            if (priorityFilter !== 'all' && alert.priority !== priorityFilter) {
                return false;
            }
            
            // Filtro de tipo
            if (typeFilter !== 'all' && alert.type !== typeFilter) {
                return false;
            }
            
            // Filtro de búsqueda
            if (searchTerm) {
                const searchFields = [
                    alert.id.toString(),
                    alert.type,
                    alert.location,
                    alert.message,
                    alert.camera_id
                ].join(' ').toLowerCase();
                
                return searchFields.includes(searchTerm);
            }
            
            return true;
        });
        
        // Renderizar alertas filtradas
        this.renderAlerts(filteredAlerts);
    }
    
    /**
     * Mostrar alertas activas
     */
    showActiveAlerts() {
        this.renderAlerts();
    }
    
    /**
     * Mostrar alertas reconocidas
     */
    showAcknowledgedAlerts() {
        const alertsContainer = document.getElementById('alerts-container');
        if (!alertsContainer) return;
        
        // Comprobar si hay alertas reconocidas
        if (this.acknowledgedAlerts.size === 0) {
            alertsContainer.innerHTML = `
                <div class="alert-placeholder text-center p-5 text-muted">
                    <i class="fas fa-check-circle fa-3x mb-3"></i>
                    <p>No hay alertas reconocidas</p>
                </div>
            `;
            return;
        }
        
        // Construir lista de alertas reconocidas
        alertsContainer.innerHTML = '';
        
        // Ordenar por timestamp
        const sortedAlerts = Array.from(this.acknowledgedAlerts.values())
            .sort((a, b) => b.timestamp - a.timestamp);
        
        // Renderizar cada alerta
        sortedAlerts.forEach(alert => {
            const alertElement = document.createElement('div');
            alertElement.id = `alert-${alert.id}`;
            alertElement.className = `alert-item alert-acknowledged alert-${alert.priority}`;
            this.renderAlertItem(alertElement, alert);
            alertsContainer.appendChild(alertElement);
        });
    }
    
    /**
     * Añadir nueva alerta
     */
    addAlert(alert) {
        // Comprobar si ya existe
        if (this.activeAlerts.has(alert.id)) {
            this.updateAlert(alert.id, alert);
            return;
        }
        
        // Añadir a la colección
        this.activeAlerts.set(alert.id, alert);
        
        // Añadir al principio de la cola de visualización
        this.alertsQueue.unshift(alert.id);
        
        // Renderizar alertas
        this.renderAlerts();
        
        // Destacar nueva alerta
        setTimeout(() => {
            const alertElement = document.getElementById(`alert-${alert.id}`);
            if (alertElement) {
                alertElement.classList.add('new-alert');
                
                // Quitar destaque después de un tiempo
                setTimeout(() => {
                    alertElement.classList.remove('new-alert');
                }, 5000);
            }
        }, 100);
    }
    
    /**
     * Actualizar alerta existente
     */
    updateAlert(alertId, alertData) {
        // Actualizar en la colección
        if (this.activeAlerts.has(alertId)) {
            this.activeAlerts.set(alertId, alertData);
            
            // Actualizar elemento en la UI si existe
            const alertElement = document.getElementById(`alert-${alertId}`);
            if (alertElement) {
                this.renderAlertItem(alertElement, alertData);
            }
            
            // Actualizar detalles si está seleccionada
            if (document.getElementById('alert-details-content').getAttribute('data-alert-id') === alertId) {
                this.showAlertDetails(alertId);
            }
        } else if (this.acknowledgedAlerts.has(alertId)) {
            this.acknowledgedAlerts.set(alertId, alertData);
        }
    }
    
    /**
     * Renderizar lista de alertas
     */
    renderAlerts(alertsList) {
        const alertsContainer = document.getElementById('alerts-container');
        if (!alertsContainer) return;
        
        // Si se proporciona una lista de alertas, usarla
        const alerts = alertsList || Array.from(this.activeAlerts.values());
        
        // Comprobar si hay alertas
        if (alerts.length === 0) {
            alertsContainer.innerHTML = `
                <div class="alert-placeholder text-center p-5 text-muted">
                    <i class="fas fa-bell-slash fa-3x mb-3"></i>
                    <p>No hay alertas activas</p>
                </div>
            `;
            return;
        }
        
        // Limpiar contenedor
        alertsContainer.innerHTML = '';
        
        // Renderizar cada alerta
        alerts.forEach(alert => {
            const alertElement = document.createElement('div');
            alertElement.id = `alert-${alert.id}`;
            alertElement.className = `alert-item alert-${alert.priority}`;
            alertElement.addEventListener('click', () => this.showAlertDetails(alert.id));
            
            this.renderAlertItem(alertElement, alert);
            alertsContainer.appendChild(alertElement);
        });
    }
    
    /**
     * Renderizar elemento individual de alerta
     */
    renderAlertItem(element, alert) {
        // Formatear timestamp
        const date = new Date(alert.timestamp * 1000);
        const timeStr = date.toLocaleTimeString();
        
        // Íconos según tipo de alerta
        const iconMap = {
            'intrusion': 'fa-user-secret',
            'theft_detected': 'fa-hand-rock',
            'loitering': 'fa-hourglass-half',
            'perimeter_breach': 'fa-door-open',
            'tailgating': 'fa-users',
            'default': 'fa-exclamation-triangle'
        };
        
        const icon = iconMap[alert.type] || iconMap.default;
        
        // Construir HTML
        element.innerHTML = `
            <div class="alert-header">
                <div class="alert-icon">
                    <i class="fas ${icon}"></i>
                </div>
                <div class="alert-title">
                    <h4>${this.formatAlertType(alert.type)}</h4>
                    <span class="alert-time">${timeStr}</span>
                </div>
                <div class="alert-priority">
                    <span class="badge badge-${this.getPriorityClass(alert.priority)}">
                        ${this.formatPriority(alert.priority)}
                    </span>
                </div>
            </div>
            <div class="alert-content">
                <p>${alert.message}</p>
                <div class="alert-location">
                    <i class="fas fa-map-marker-alt"></i> ${alert.location}
                </div>
            </div>
        `;
    }
    
    /**
     * Mostrar detalles de una alerta
     */
    showAlertDetails(alertId) {
        const detailPanel = document.getElementById('alert-detail-panel');
        const detailContent = document.getElementById('alert-details-content');
        
        if (!detailPanel || !detailContent) return;
        
        // Buscar alerta en colecciones
        let alert = this.activeAlerts.get(alertId);
        if (!alert) {
            alert = this.acknowledgedAlerts.get(alertId);
            if (!alert) return;
        }
        
        // Actualizar título
        document.getElementById('detail-title').textContent = 
            `Alerta: ${this.formatAlertType(alert.type)}`;
        
        // Guardar ID de alerta actual
        detailContent.setAttribute('data-alert-id', alertId);
        
        // Formatear timestamp
        const date = new Date(alert.timestamp * 1000);
        const dateTimeStr = date.toLocaleString();
        
        // Construir HTML de detalles
        detailContent.innerHTML = `
            <div class="alert-detail-header alert-${alert.priority}">
                <div class="row">
                    <div class="col-md-8">
                        <h2>${this.formatAlertType(alert.type)}</h2>
                        <p class="lead">${alert.message}</p>
                    </div>
                    <div class="col-md-4 text-right">
                        <span class="badge badge-${this.getPriorityClass(alert.priority)} badge-lg">
                            ${this.formatPriority(alert.priority)}
                        </span>
                        <div class="alert-timestamp mt-2">
                            <i class="far fa-clock"></i> ${dateTimeStr}
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="alert-detail-body mt-4">
                <div class="row">
                    <div class="col-md-6">
                        <h4>Ubicación</h4>
                        <p><i class="fas fa-map-marker-alt"></i> ${alert.location}</p>
                        ${alert.camera_id ? `<p><i class="fas fa-camera"></i> Cámara: ${alert.camera_id}</p>` : ''}
                    </div>
                    <div class="col-md-6">
                        <h4>Estado</h4>
                        <p><span class="badge badge-${this.getStatusClass(alert.status)}">
                            ${this.formatStatus(alert.status)}
                        </span></p>
                        ${alert.assigned_to ? `<p><i class="fas fa-user"></i> Asignado a: ${alert.assigned_to}</p>` : ''}
                    </div>
                </div>
                
                ${alert.image_url ? `
                <div class="alert-media mt-4">
                    <h4>Imagen</h4>
                    <img src="${alert.image_url}" class="img-fluid alert-image" alt="Imagen de alerta">
                </div>` : ''}
                
                ${alert.video_url ? `
                <div class="alert-media mt-4">
                    <h4>Video</h4>
                    <div class="video-container">
                        <video controls src="${alert.video_url}" class="alert-video"></video>
                    </div>
                </div>` : ''}
                
                <div class="alert-actions mt-4">
                    <h4>Acciones</h4>
                    <div class="btn-group" role="group">
                        <button class="btn btn-primary action-btn" data-action="acknowledge">
                            <i class="fas fa-check"></i> Reconocer
                        </button>
                        <button class="btn btn-warning action-btn" data-action="escalate">
                            <i class="fas fa-arrow-up"></i> Escalar
                        </button>
                        <button class="btn btn-danger action-btn" data-action="dispatch">
                            <i class="fas fa-running"></i> Enviar Personal
                        </button>
                    </div>
                </div>
                
                ${alert.notes ? `
                <div class="alert-notes mt-4">
                    <h4>Notas</h4>
                    <div class="alert-notes-content p-3 bg-light">
                        ${alert.notes}
                    </div>
                </div>` : ''}
            </div>
        `;
        
        // Configurar event listeners para botones de acción
        detailContent.querySelectorAll('.action-btn').forEach(button => {
            button.addEventListener('click', (e) => {
                e.stopPropagation();
                const action = button.getAttribute('data-action');
                this.executeAction(action, alertId);
            });
        });
        
        // Mostrar panel
        detailPanel.classList.remove('d-none');
        
        // Disparar evento de selección
        this.triggerAlertSelected(alertId, alert);
    }
    
    /**
     * Ocultar panel de detalles
     */
    hideAlertDetails() {
        const detailPanel = document.getElementById('alert-detail-panel');
        if (detailPanel) {
            detailPanel.classList.add('d-none');
        }
    }
    
    /**
     * Ejecutar acción en una alerta
     */
    executeAction(action, alertId) {
        // Obtener datos de la alerta
        const alert = this.activeAlerts.get(alertId);
        if (!alert) return;
        
        console.log(`Executing action ${action} on alert ${alertId}`);
        
        // Enviar solicitud a la API
        fetch(`${this.apiEndpoint}/${alertId}/actions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                action: action,
                timestamp: Math.floor(Date.now() / 1000)
            })
        })
        .then(response => response.json())
        .then(data => {
            if (data.success) {
                // Actualizar UI según acción
                if (action === 'acknowledge') {
                    // Mover alerta a reconocidas
                    this.acknowledgeAlert(alertId);
                }
                
                // Disparar evento de acción de usuario
                this.triggerUserAction(action, {
                    alertId: alertId,
                    alertData: alert,
                    result: data
                });
            } else {
                console.error('Error executing action:', data.message);
            }
        })
        .catch(error => {
            console.error('Error executing action:', error);
        });
    }
    
    /**
     * Reconocer una alerta
     */
    acknowledgeAlert(alertId) {
        // Buscar la alerta
        const alert = this.activeAlerts.get(alertId);
        if (!alert) return;
        
        // Actualizar estado
        alert.status = 'acknowledged';
        
        // Mover a alertas reconocidas
        this.acknowledgedAlerts.set(alertId, alert);
        this.activeAlerts.delete(alertId);
        
        // Quitar de la cola
        this.alertsQueue = this.alertsQueue.filter(id => id !== alertId);
        
        // Si estamos mostrando alertas activas, actualizar vista
        if (document.getElementById('view-active').classList.contains('active')) {
            this.renderAlerts();
        }
        
        // Ocultar detalles si se está mostrando la alerta reconocida
        if (document.getElementById('alert-details-content').getAttribute('data-alert-id') === alertId) {
            this.hideAlertDetails();
        }
    }
    
    /**
     * Actualizar estado de una alerta
     */
    updateAlertStatus(alertId, status) {
        // Buscar la alerta en colecciones
        let alert = this.activeAlerts.get(alertId);
        let wasActive = true;
        
        if (!alert) {
            alert = this.acknowledgedAlerts.get(alertId);
            wasActive = false;
            if (!alert) return;
        }
        
        // Actualizar estado
        alert.status = status;
        
        // Mover entre colecciones si es necesario
        if (status === 'acknowledged' && wasActive) {
            this.acknowledgedAlerts.set(alertId, alert);
            this.activeAlerts.delete(alertId);
            this.alertsQueue = this.alertsQueue.filter(id => id !== alertId);
        } else if (status !== 'acknowledged' && !wasActive) {
            this.activeAlerts.set(alertId, alert);
            this.acknowledgedAlerts.delete(alertId);
            this.alertsQueue.unshift(alertId);
        }
        
        // Actualizar UI
        if ((wasActive && document.getElementById('view-active').classList.contains('active')) ||
            (!wasActive && document.getElementById('view-acknowledged').classList.contains('active'))) {
            this.renderAlerts();
        }
    }
    
    /**
     * Filtrar alertas por cámara
     */
    filterByCamera(cameraId) {
        // Buscar alertas de esta cámara
        const filteredAlerts = Array.from(this.activeAlerts.values())
            .filter(alert => alert.camera_id === cameraId);
        
        // Aplicar filtro
        this.renderAlerts(filteredAlerts);
        
        // Actualizar filtros visuales
        document.getElementById('alert-search').value = `Cámara ${cameraId}`;
    }
    
    /**
     * Registrar listener para selección de alertas
     */
    onAlertSelected(callback) {
        if (typeof callback === 'function') {
            this.eventListeners.alertSelected.push(callback);
        }
    }
    
    /**
     * Registrar listener para acciones de usuario
     */
    onUserAction(callback) {
        if (typeof callback === 'function') {
            this.eventListeners.userAction.push(callback);
        }
    }
    
    /**
     * Disparar evento de selección de alerta
     */
    triggerAlertSelected(alertId, alertData) {
        this.eventListeners.alertSelected.forEach(callback => {
            try {
                callback(alertId, alertData);
            } catch (error) {
                console.error('Error in alert selected callback:', error);
            }
        });
    }
    
    /**
     * Disparar evento de acción de usuario
     */
    triggerUserAction(action, data) {
        this.eventListeners.userAction.forEach(callback => {
            try {
                callback(action, data);
            } catch (error) {
                console.error('Error in user action callback:', error);
            }
        });
    }
    
    // Métodos auxiliares para formateo
    
    formatAlertType(type) {
        const typeMap = {
            'intrusion': 'Intrusión',
            'theft_detected': 'Robo Detectado',
            'loitering': 'Merodeo',
            'perimeter_breach': 'Violación de Perímetro',
            'tailgating': 'Acceso No Autorizado'
        };
        
        return typeMap[type] || type.replace('_', ' ');
    }
    
    formatPriority(priority) {
        const priorityMap = {
            'high': 'Alta',
            'medium': 'Media',
            'low': 'Baja'
        };
        
        return priorityMap[priority] || priority;
    }
    
    formatStatus(status) {
        const statusMap = {
            'new': 'Nueva',
            'acknowledged': 'Reconocida',
            'in_progress': 'En Proceso',
            'resolved': 'Resuelta',
            'false_alarm': 'Falsa Alarma'
        };
        
        return statusMap[status] || status;
    }
    
    getPriorityClass(priority) {
        const classMap = {
            'high': 'danger',
            'medium': 'warning',
            'low': 'info'
        };
        
        return classMap[priority] || 'secondary';
    }
    
    getStatusClass(status) {
        const classMap = {
            'new': 'danger',
            'acknowledged': 'primary',
            'in_progress': 'warning',
            'resolved': 'success',
            'false_alarm': 'secondary'
        };
        
        return classMap[status] || 'secondary';
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { SecurityAlertsDashboard };
} 
```

### src\frontend\dashboard\statistics_panel.js
```js | 24116 bytes | Modificado: 2025-03-07 01:03:31.395065
```
/**
 * Panel de Estadísticas del Sistema
 * 
 * Muestra gráficos y métricas sobre el rendimiento y uso del sistema de vigilancia.
 */
class StatisticsPanel {
    /**
     * Inicializa el panel de estadísticas
     * @param {string} containerId ID del contenedor HTML
     * @param {string} apiEndpoint Endpoint de la API para estadísticas
     */
    constructor(containerId, apiEndpoint) {
        this.container = document.getElementById(containerId);
        if (!this.container) {
            console.error(`Container with ID ${containerId} not found`);
            return;
        }
        
        this.apiEndpoint = apiEndpoint;
        this.charts = {};
        this.updateInterval = null;
        this.timeRange = 'day'; // 'day', 'week', 'month'
        
        this.initialize();
    }
    
    /**
     * Inicializar componentes de la UI
     */
    initialize() {
        // Crear estructura básica si no existe
        if (!document.getElementById('statistics-container')) {
            this.container.innerHTML = `
                <div class="stats-controls d-flex justify-content-between mb-3">
                    <div class="time-range-controls btn-group">
                        <button class="btn btn-outline-secondary time-range-btn active" data-range="day">Día</button>
                        <button class="btn btn-outline-secondary time-range-btn" data-range="week">Semana</button>
                        <button class="btn btn-outline-secondary time-range-btn" data-range="month">Mes</button>
                    </div>
                    <div class="update-controls">
                        <button id="refresh-stats" class="btn btn-primary">
                            <i class="fas fa-sync-alt"></i> Actualizar
                        </button>
                    </div>
                </div>
                
                <div id="statistics-container">
                    <div class="row">
                        <div class="col-md-6">
                            <div class="card mb-4">
                                <div class="card-header">
                                    <h5 class="card-title">Alertas por Tipo</h5>
                                </div>
                                <div class="card-body">
                                    <canvas id="alerts-by-type-chart"></canvas>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-6">
                            <div class="card mb-4">
                                <div class="card-header">
                                    <h5 class="card-title">Alertas por Hora del Día</h5>
                                </div>
                                <div class="card-body">
                                    <canvas id="alerts-by-hour-chart"></canvas>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="row">
                        <div class="col-md-6">
                            <div class="card mb-4">
                                <div class="card-header">
                                    <h5 class="card-title">Rendimiento del Sistema</h5>
                                </div>
                                <div class="card-body">
                                    <canvas id="system-performance-chart"></canvas>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-6">
                            <div class="card mb-4">
                                <div class="card-header">
                                    <h5 class="card-title">Uso de Almacenamiento</h5>
                                </div>
                                <div class="card-body">
                                    <canvas id="storage-usage-chart"></canvas>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="row">
                        <div class="col-md-12">
                            <div class="card mb-4">
                                <div class="card-header">
                                    <h5 class="card-title">Resumen de Eventos</h5>
                                </div>
                                <div class="card-body">
                                    <div class="table-responsive">
                                        <table class="table table-striped" id="events-summary-table">
                                            <thead>
                                                <tr>
                                                    <th>Tipo de Evento</th>
                                                    <th>Hoy</th>
                                                    <th>Esta Semana</th>
                                                    <th>Este Mes</th>
                                                    <th>Total</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <td colspan="5" class="text-center">
                                                        <div class="spinner-border spinner-border-sm" role="status">
                                                            <span class="sr-only">Cargando...</span>
                                                        </div>
                                                        Cargando datos...
                                                    </td>
                                                </tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            `;
            
            // Configurar event listeners
            this.setupEventListeners();
        }
        
        // Cargar datos iniciales
        this.loadStatistics();
        
        // Iniciar actualización automática
        this.startAutoUpdate();
    }
    
    /**
     * Configurar event listeners para controles de la UI
     */
    setupEventListeners() {
        // Botones de rango de tiempo
        const timeRangeButtons = document.querySelectorAll('.time-range-btn');
        timeRangeButtons.forEach(button => {
            button.addEventListener('click', () => {
                // Actualizar clase activa
                timeRangeButtons.forEach(btn => btn.classList.remove('active'));
                button.classList.add('active');
                
                // Cambiar rango de tiempo
                const range = button.getAttribute('data-range');
                this.changeTimeRange(range);
            });
        });
        
        // Botón de actualizar
        const refreshButton = document.getElementById('refresh-stats');
        if (refreshButton) {
            refreshButton.addEventListener('click', () => {
                this.loadStatistics();
            });
        }
    }
    
    /**
     * Cargar estadísticas desde la API
     */
    loadStatistics() {
        // Mostrar indicadores de carga en gráficos
        document.querySelectorAll('canvas').forEach(canvas => {
            canvas.style.opacity = '0.5';
        });
        
        // Mostrar indicador de carga en la tabla
        const tableBody = document.querySelector('#events-summary-table tbody');
        if (tableBody) {
            tableBody.innerHTML = `
                <tr>
                    <td colspan="5" class="text-center">
                        <div class="spinner-border spinner-border-sm" role="status">
                            <span class="sr-only">Cargando...</span>
                        </div>
                        Cargando datos...
                    </td>
                </tr>
            `;
        }
        
        // Cargar datos desde la API
        fetch(`${this.apiEndpoint}?timeRange=${this.timeRange}`)
            .then(response => response.json())
            .then(data => {
                // Actualizar gráficos con los datos
                this.updateCharts(data);
                
                // Actualizar tabla de resumen
                this.updateEventsSummary(data.eventsSummary);
                
                // Restaurar opacidad de los gráficos
                document.querySelectorAll('canvas').forEach(canvas => {
                    canvas.style.opacity = '1';
                });
            })
            .catch(error => {
                console.error('Error loading statistics:', error);
                
                // Mostrar mensaje de error en la tabla
                if (tableBody) {
                    tableBody.innerHTML = `
                        <tr>
                            <td colspan="5" class="text-center text-danger">
                                <i class="fas fa-exclamation-triangle"></i>
                                Error al cargar estadísticas. Por favor, intente nuevamente.
                            </td>
                        </tr>
                    `;
                }
                
                // Restaurar opacidad de los gráficos
                document.querySelectorAll('canvas').forEach(canvas => {
                    canvas.style.opacity = '1';
                });
            });
    }
    
    /**
     * Cambiar rango de tiempo para las estadísticas
     */
    changeTimeRange(range) {
        if (this.timeRange === range) return;
        
        this.timeRange = range;
        this.loadStatistics();
    }
    
    /**
     * Iniciar actualización automática
     */
    startAutoUpdate() {
        // Detener actualización existente si hay alguna
        this.stopAutoUpdate();
        
        // Actualizar cada 5 minutos
        this.updateInterval = setInterval(() => {
            this.loadStatistics();
        }, 5 * 60 * 1000);
    }
    
    /**
     * Detener actualización automática
     */
    stopAutoUpdate() {
        if (this.updateInterval) {
            clearInterval(this.updateInterval);
            this.updateInterval = null;
        }
    }
    
    /**
     * Actualizar gráficos con nuevos datos
     */
    updateCharts(data) {
        // Actualizar o crear gráfico de alertas por tipo
        this.updateAlertsByTypeChart(data.alertsByType);
        
        // Actualizar o crear gráfico de alertas por hora
        this.updateAlertsByHourChart(data.alertsByHour);
        
        // Actualizar o crear gráfico de rendimiento del sistema
        this.updateSystemPerformanceChart(data.systemPerformance);
        
        // Actualizar o crear gráfico de uso de almacenamiento
        this.updateStorageUsageChart(data.storageUsage);
    }
    
    /**
     * Actualizar gráfico de alertas por tipo
     */
    updateAlertsByTypeChart(data) {
        const ctx = document.getElementById('alerts-by-type-chart');
        if (!ctx) return;
        
        // Traducir tipos de alerta
        const typeLabels = {
            'intrusion': 'Intrusión',
            'theft_detected': 'Robo',
            'loitering': 'Merodeo',
            'perimeter_breach': 'Violación de Perímetro',
            'tailgating': 'Acceso No Autorizado'
        };
        
        const labels = data.map(item => typeLabels[item.type] || item.type);
        const values = data.map(item => item.count);
        
        if (this.charts.alertsByType) {
            // Actualizar gráfico existente
            this.charts.alertsByType.data.labels = labels;
            this.charts.alertsByType.data.datasets[0].data = values;
            this.charts.alertsByType.update();
        } else {
            // Crear nuevo gráfico
            this.charts.alertsByType = new Chart(ctx, {
                type: 'pie',
                data: {
                    labels: labels,
                    datasets: [{
                        data: values,
                        backgroundColor: [
                            '#FF6384',
                            '#36A2EB',
                            '#FFCE56',
                            '#4BC0C0',
                            '#9966FF',
                            '#FF9F40'
                        ]
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    legend: {
                        position: 'right'
                    },
                    title: {
                        display: false
                    }
                }
            });
        }
    }
    
    /**
     * Actualizar gráfico de alertas por hora
     */
    updateAlertsByHourChart(data) {
        const ctx = document.getElementById('alerts-by-hour-chart');
        if (!ctx) return;
        
        // Preparar datos para el gráfico
        const hours = Array.from({ length: 24 }, (_, i) => i);
        const labels = hours.map(hour => `${hour}:00`);
        
        // Convertir datos a formato para el gráfico
        const datasets = [];
        Object.entries(data).forEach(([type, hourlyData]) => {
            // Traducir tipos de alerta
            const typeLabels = {
                'intrusion': 'Intrusión',
                'theft_detected': 'Robo',
                'loitering': 'Merodeo',
                'perimeter_breach': 'Violación de Perímetro',
                'tailgating': 'Acceso No Autorizado'
            };
            
            const typeName = typeLabels[type] || type;
            
            // Crear array de datos por hora
            const hourValues = hours.map(hour => {
                const hourStr = hour.toString();
                return hourlyData[hourStr] || 0;
            });
            
            datasets.push({
                label: typeName,
                data: hourValues,
                borderColor: this.getColorForType(type),
                backgroundColor: this.getColorForType(type, 0.2),
                borderWidth: 2,
                fill: true
            });
        });
        
        if (this.charts.alertsByHour) {
            // Actualizar gráfico existente
            this.charts.alertsByHour.data.labels = labels;
            this.charts.alertsByHour.data.datasets = datasets;
            this.charts.alertsByHour.update();
        } else {
            // Crear nuevo gráfico
            this.charts.alertsByHour = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: labels,
                    datasets: datasets
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        x: {
                            title: {
                                display: true,
                                text: 'Hora del día'
                            }
                        },
                        y: {
                            beginAtZero: true,
                            title: {
                                display: true,
                                text: 'Número de alertas'
                            }
                        }
                    }
                }
            });
        }
    }
    
    /**
     * Actualizar gráfico de rendimiento del sistema
     */
    updateSystemPerformanceChart(data) {
        const ctx = document.getElementById('system-performance-chart');
        if (!ctx) return;
        
        const labels = data.timestamps.map(ts => new Date(ts * 1000).toLocaleTimeString());
        
        const datasets = [
            {
                label: 'CPU (%)',
                data: data.cpu,
                borderColor: '#FF6384',
                backgroundColor: 'rgba(255, 99, 132, 0.2)',
                borderWidth: 2,
                fill: true
            },
            {
                label: 'Memoria (%)',
                data: data.memory,
                borderColor: '#36A2EB',
                backgroundColor: 'rgba(54, 162, 235, 0.2)',
                borderWidth: 2,
                fill: true
            }
        ];
        
        if (this.charts.systemPerformance) {
            // Actualizar gráfico existente
            this.charts.systemPerformance.data.labels = labels;
            this.charts.systemPerformance.data.datasets = datasets;
            this.charts.systemPerformance.update();
        } else {
            // Crear nuevo gráfico
            this.charts.systemPerformance = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: labels,
                    datasets: datasets
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 100,
                            title: {
                                display: true,
                                text: 'Utilización (%)'
                            }
                        }
                    }
                }
            });
        }
    }
    
    /**
     * Actualizar gráfico de uso de almacenamiento
     */
    updateStorageUsageChart(data) {
        const ctx = document.getElementById('storage-usage-chart');
        if (!ctx) return;
        
        if (this.charts.storageUsage) {
            // Actualizar gráfico existente
            this.charts.storageUsage.data.datasets[0].data = [
                data.used,
                data.total - data.used
            ];
            this.charts.storageUsage.update();
        } else {
            // Crear nuevo gráfico
            this.charts.storageUsage = new Chart(ctx, {
                type: 'doughnut',
                data: {
                    labels: ['Utilizado', 'Disponible'],
                    datasets: [{
                        data: [data.used, data.total - data.used],
                        backgroundColor: [
                            '#FF6384',
                            '#36A2EB'
                        ]
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    cutoutPercentage: 70,
                    legend: {
                        position: 'bottom'
                    },
                    title: {
                        display: false
                    },
                    plugins: {
                        doughnutlabel: {
                            labels: [
                                {
                                    text: `${this.formatStorageSize(data.used)} / ${this.formatStorageSize(data.total)}`,
                                    font: {
                                        size: '16'
                                    }
                                },
                                {
                                    text: `${Math.round(data.used / data.total * 100)}%`,
                                    font: {
                                        size: '24'
                                    }
                                }
                            ]
                        }
                    }
                }
            });
        }
    }
    
    /**
     * Actualizar tabla de resumen de eventos
     */
    updateEventsSummary(data) {
        const tableBody = document.querySelector('#events-summary-table tbody');
        if (!tableBody) return;
        
        // Traducir tipos de evento
        const typeLabels = {
            'intrusion': 'Intrusión',
            'theft_detected': 'Robo',
            'loitering': 'Merodeo',
            'perimeter_breach': 'Violación de Perímetro',
            'tailgating': 'Acceso No Autorizado',
            'suspicious_behavior': 'Comportamiento Sospechoso',
            'object_left': 'Objeto Abandonado',
            'crowd_forming': 'Formación de Multitud'
        };
        
        // Construir filas de la tabla
        let tableHtml = '';
        
        Object.entries(data).forEach(([type, counts]) => {
            const eventType = typeLabels[type] || type;
            
            tableHtml += `
                <tr>
                    <td>${eventType}</td>
                    <td>${counts.today}</td>
                    <td>${counts.week}</td>
                    <td>${counts.month}</td>
                    <td>${counts.total}</td>
                </tr>
            `;
        });
        
        // Agregar fila de totales
        const totals = Object.values(data).reduce((acc, counts) => {
            return {
                today: acc.today + counts.today,
                week: acc.week + counts.week,
                month: acc.month + counts.month,
                total: acc.total + counts.total
            };
        }, { today: 0, week: 0, month: 0, total: 0 });
        
        tableHtml += `
            <tr class="table-active font-weight-bold">
                <td>TOTAL</td>
                <td>${totals.today}</td>
                <td>${totals.week}</td>
                <td>${totals.month}</td>
                <td>${totals.total}</td>
            </tr>
        `;
        
        // Actualizar tabla
        tableBody.innerHTML = tableHtml;
    }
    
    /**
     * Obtener color para un tipo de alerta
     */
    getColorForType(type, alpha = 1) {
        const colors = {
            'intrusion': `rgba(255, 99, 132, ${alpha})`,
            'theft_detected': `rgba(54, 162, 235, ${alpha})`,
            'loitering': `rgba(255, 206, 86, ${alpha})`,
            'perimeter_breach': `rgba(75, 192, 192, ${alpha})`,
            'tailgating': `rgba(153, 102, 255, ${alpha})`,
            'suspicious_behavior': `rgba(255, 159, 64, ${alpha})`,
            'default': `rgba(201, 203, 207, ${alpha})`
        };
        
        return colors[type] || colors.default;
    }
    
    /**
     * Formatear tamaño de almacenamiento
     */
    formatStorageSize(bytes) {
        const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
        if (bytes === 0) return '0 B';
        const i = parseInt(Math.floor(Math.log(bytes) / Math.log(1024)));
        return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
    }
    
    /**
     * Limpiar recursos al destruir el componente
     */
    destroy() {
        // Detener actualización automática
        this.stopAutoUpdate();
        
        // Destruir gráficos
        Object.values(this.charts).forEach(chart => {
            if (chart && typeof chart.destroy === 'function') {
                chart.destroy();
            }
        });
        
        this.charts = {};
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { StatisticsPanel };
} 
```

### src\frontend\dashboard\unified_control.js
```js | 28791 bytes | Modificado: 2025-03-07 02:25:56.027363
```
/**
 * vigIA - Sistema de Vigilancia Inteligente con IA
 * Versión PMV (Proyecto MOTION_DETECTOR)
 *
 * © 2025 Gustavo Mayorga. Todos los derechos reservados.
 *
 * Este código es propiedad exclusiva de Gustavo Mayorga y está protegido por leyes de 
 * propiedad intelectual. Ninguna parte de este software puede ser reproducida, distribuida, 
 * o utilizada para crear trabajos derivados sin autorización explícita por escrito.
 *
 * Contacto legal: gustavo.mayorga.gm@gmail.com
 *
 * AVISO: El uso no autorizado de este código o sus conceptos está estrictamente prohibido
 * y será perseguido en la máxima medida permitida por la ley.
 */

/**
 * Panel de Control Unificado para el Sistema de Vigilancia con IA
 * 
 * Este componente integra las vistas de alertas, cámaras y estadísticas
 * en una interfaz cohesiva y reactiva para los operadores.
 */
class UnifiedControlPanel {
    /**
     * Inicializa el panel de control unificado
     * @param {Object} config Configuración del panel
     */
    constructor(config) {
        this.config = config;
        this.apiBaseUrl = config.apiBaseUrl || '/api';
        this.wsBaseUrl = config.wsBaseUrl || (window.location.protocol === 'https:' ? 
            'wss://' + window.location.host : 'ws://' + window.location.host);
            
        // Inicializar componentes
        this.alertsPanel = new SecurityAlertsDashboard(config.alertsContainerId, 
            `${this.apiBaseUrl}/alerts`);
        this.cameraPanel = new CameraViewPanel(config.cameraContainerId, 
            `${this.apiBaseUrl}/cameras`);
        this.statsPanel = new StatisticsPanel(config.statsContainerId, 
            `${this.apiBaseUrl}/stats`);
            
        // Estado de la aplicación
        this.state = {
            user: null,
            selectedAlert: null,
            activeTab: 'live',  // 'live', 'alerts', 'recordings'
            systemStatus: {
                cameras: { total: 0, online: 0, offline: 0 },
                alerts: { high: 0, medium: 0, low: 0, total: 0 },
                system: { cpu: 0, memory: 0, storage: 0 }
            }
        };
        
        // Websocket para actualizaciones en tiempo real
        this.socket = null;
        
        // Inicializar UI
        this.initialize();
    }
    
    /**
     * Inicializar interfaz de usuario y conexiones
     */
    initialize() {
        // Conectar eventos entre paneles
        this.connectPanelEvents();
        
        // Configurar navegación
        this.setupNavigation();
        
        // Iniciar conexión WebSocket
        this.connectWebSocket();
        
        // Cargar datos iniciales
        this.loadInitialData();
        
        // Configurar temporizadores de actualización
        this.setupTimers();
        
        // Escuchar eventos de teclado para atajos
        document.addEventListener('keydown', this.handleKeyboardShortcuts.bind(this));
    }
    
    /**
     * Conectar eventos entre paneles
     */
    connectPanelEvents() {
        // Cuando se selecciona una alerta, mostrar cámaras relevantes
        this.alertsPanel.onAlertSelected((alertId, alertData) => {
            this.state.selectedAlert = alertData;
            this.handleAlertSelected(alertId, alertData);
        });
        
        // Cuando se selecciona una cámara, mostrar alertas relevantes
        this.cameraPanel.onCameraSelected((cameraId) => {
            this.alertsPanel.filterByCamera(cameraId);
        });
        
        // Propagar eventos de usuario entre componentes
        this.alertsPanel.onUserAction((action, data) => {
            // Ejemplo: cuando un usuario reconoce una alerta
            if (action === 'acknowledge') {
                // Actualizar contador de alertas
                this.updateAlertCounter();
            }
        });
    }
    
    /**
     * Configurar navegación entre pestañas
     */
    setupNavigation() {
        const tabLinks = document.querySelectorAll('.tab-link');
        const tabContents = document.querySelectorAll('.tab-content');
        
        tabLinks.forEach(link => {
            link.addEventListener('click', (e) => {
                e.preventDefault();
                
                // Obtener el target del enlace
                const tabId = link.getAttribute('data-tab');
                
                // Actualizar estado
                this.state.activeTab = tabId;
                
                // Actualizar clases activas
                tabLinks.forEach(l => l.classList.remove('active'));
                link.classList.add('active');
                
                // Mostrar contenido correspondiente
                tabContents.forEach(content => {
                    if (content.getAttribute('id') === tabId + '-tab') {
                        content.classList.add('active');
                    } else {
                        content.classList.remove('active');
                    }
                });
                
                // Eventos específicos según la pestaña
                if (tabId === 'live') {
                    this.cameraPanel.resumeStreams();
                } else {
                    this.cameraPanel.pauseStreams();
                }
            });
        });
    }
    
    /**
     * Establecer conexión WebSocket para actualizaciones en tiempo real
     */
    connectWebSocket() {
        try {
            this.socket = new WebSocket(`${this.wsBaseUrl}/ws/dashboard`);
            
            this.socket.onopen = () => {
                console.log('WebSocket connected');
                this.showNotification('Conexión en tiempo real establecida', 'success');
            };
            
            this.socket.onmessage = (event) => {
                const data = JSON.parse(event.data);
                this.handleWebSocketMessage(data);
            };
            
            this.socket.onerror = (error) => {
                console.error('WebSocket error:', error);
                this.showNotification('Error en la conexión en tiempo real', 'error');
            };
            
            this.socket.onclose = () => {
                console.log('WebSocket disconnected');
                
                // Intentar reconectar después de un tiempo
                setTimeout(() => {
                    if (this.socket?.readyState === WebSocket.CLOSED) {
                        this.connectWebSocket();
                    }
                }, 5000);
            };
        } catch (error) {
            console.error('Error creating WebSocket:', error);
        }
    }
    
    /**
     * Manejar mensaje recibido por WebSocket
     */
    handleWebSocketMessage(data) {
        const { type, payload } = data;
        
        switch (type) {
            case 'new_alert':
                // Nueva alerta recibida
                this.alertsPanel.addAlert(payload);
                this.updateAlertCounter();
                this.playAlertSound(payload.priority);
                break;
                
            case 'camera_status':
                // Actualización de estado de cámara
                this.cameraPanel.updateCameraStatus(payload.camera_id, payload.status);
                this.updateCameraCounter();
                break;
                
            case 'system_stats':
                // Actualización de estadísticas del sistema
                this.statsPanel.updateStats(payload);
                this.updateSystemStatus(payload);
                break;
                
            case 'alert_update':
                // Actualización de una alerta existente
                this.alertsPanel.updateAlert(payload.id, payload);
                break;
                
            default:
                console.log('Unknown message type:', type, payload);
        }
    }
    
    /**
     * Cargar datos iniciales al abrir el dashboard
     */
    loadInitialData() {
        // Cargar alertas activas
        fetch(`${this.apiBaseUrl}/alerts/active`)
            .then(response => response.json())
            .then(data => {
                this.alertsPanel.setAlerts(data);
                this.updateAlertCounter();
            })
            .catch(error => {
                console.error('Error loading alerts:', error);
                this.showNotification('Error al cargar alertas', 'error');
            });
            
        // Cargar estado de cámaras
        fetch(`${this.apiBaseUrl}/cameras/status`)
            .then(response => response.json())
            .then(data => {
                this.cameraPanel.setCameras(data);
                this.updateCameraCounter();
            })
            .catch(error => {
                console.error('Error loading camera status:', error);
                this.showNotification('Error al cargar estado de cámaras', 'error');
            });
            
        // Cargar estadísticas del sistema
        fetch(`${this.apiBaseUrl}/stats/current`)
            .then(response => response.json())
            .then(data => {
                this.statsPanel.setStats(data);
                this.updateSystemStatus(data);
            })
            .catch(error => {
                console.error('Error loading system stats:', error);
            });
            
        // Cargar perfil de usuario
        if (this.config.userProfileUrl) {
            fetch(this.config.userProfileUrl)
                .then(response => response.json())
                .then(data => {
                    this.state.user = data;
                    this.updateUserProfile(data);
                })
                .catch(error => {
                    console.error('Error loading user profile:', error);
                });
        }
    }
    
    /**
     * Configurar temporizadores para actualización periódica
     */
    setupTimers() {
        // Actualizar estado de sistema cada minuto
        setInterval(() => {
            fetch(`${this.apiBaseUrl}/stats/current`)
                .then(response => response.json())
                .then(data => {
                    this.statsPanel.updateStats(data);
                    this.updateSystemStatus(data);
                })
                .catch(error => {
                    console.error('Error updating system stats:', error);
                });
        }, 60000);
        
        // Verificar estado de conexión cada 30 segundos
        setInterval(() => {
            if (this.socket && this.socket.readyState !== WebSocket.OPEN) {
                this.connectWebSocket();
            }
        }, 30000);
    }
    
    /**
     * Manejar selección de alerta
     */
    handleAlertSelected(alertId, alertData) {
        // Mostrar cámaras relacionadas con la alerta
        if (alertData.camera_id) {
            this.cameraPanel.focusCamera(alertData.camera_id);
        }
        
        // Mostrar acciones contextuales para esta alerta
        this.displayContextualActions(alertData);
        
        // Si hay grabación, mostrar opción de reproducción
        if (alertData.video_url) {
            const videoPlayerContainer = document.getElementById('video-player-container');
            if (videoPlayerContainer) {
                videoPlayerContainer.classList.remove('hidden');
                this.loadVideoPlayer(alertData.video_url, alertData.type);
            }
        }
        
        // Actualizar mapa si la alerta tiene ubicación
        if (alertData.location && this.mapPanel) {
            this.mapPanel.centerOnLocation(alertData.location);
            this.mapPanel.addMarker(alertData.location, alertData.type);
        }
    }
    
    /**
     * Mostrar acciones contextuales para un tipo de alerta
     */
    displayContextualActions(alertData) {
        const actionsContainer = document.getElementById('contextual-actions');
        if (!actionsContainer) return;
        
        // Limpiar acciones anteriores
        actionsContainer.innerHTML = '';
        
        // Botones específicos según tipo de alerta
        let specificButtons = '';
        
        // Acciones específicas según el tipo de alerta
        switch (alertData.type) {
            case 'intrusion':
            case 'perimeter_breach':
                specificButtons += `
                    <button class="action-btn btn-danger" data-action="lockdown">
                        <i class="fas fa-lock"></i> Bloqueo
                    </button>
                    <button class="action-btn btn-warning" data-action="dispatch_security">
                        <i class="fas fa-running"></i> Enviar Seguridad
                    </button>
                `;
                break;
                
            case 'theft_detected':
                specificButtons += `
                    <button class="action-btn btn-warning" data-action="track_subject">
                        <i class="fas fa-crosshairs"></i> Seguir Sujeto
                    </button>
                    <button class="action-btn btn-info" data-action="save_evidence">
                        <i class="fas fa-save"></i> Guardar Evidencia
                    </button>
                `;
                break;
                
            case 'loitering':
                specificButtons += `
                    <button class="action-btn btn-info" data-action="make_announcement">
                        <i class="fas fa-bullhorn"></i> Anuncio
                    </button>
                `;
                break;
                
            case 'tailgating':
                specificButtons += `
                    <button class="action-btn btn-warning" data-action="verify_ids">
                        <i class="fas fa-id-card"></i> Verificar IDs
                    </button>
                `;
                break;
        }
        
        // Botones comunes para todas las alertas
        const commonButtons = `
            <button class="action-btn btn-primary" data-action="acknowledge">
                <i class="fas fa-check"></i> Reconocer
            </button>
            <button class="action-btn btn-danger" data-action="escalate">
                <i class="fas fa-exclamation-triangle"></i> Escalar
            </button>
            <button class="action-btn btn-secondary" data-action="review_video">
                <i class="fas fa-play-circle"></i> Ver Video
            </button>
        `;
        
        // Combinar botones
        actionsContainer.innerHTML = `
            <div class="d-flex justify-content-around flex-wrap">
                ${specificButtons}
                ${commonButtons}
            </div>
        `;
        
        // Agregar event listeners a los botones
        actionsContainer.querySelectorAll('.action-btn').forEach(button => {
            button.addEventListener('click', () => {
                const action = button.getAttribute('data-action');
                this.executeAction(action, alertData);
            });
        });
    }
    
    /**
     * Ejecutar acción seleccionada
     */
    executeAction(action, alertData) {
        console.log(`Executing action: ${action}`, alertData);
        
        // Enviar acción al servidor
        fetch(`${this.apiBaseUrl}/alerts/${alertData.id}/actions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                action: action,
                user: this.state.user ? this.state.user.id : null,
                timestamp: Date.now() / 1000
            })
        })
        .then(response => response.json())
        .then(data => {
            console.log('Action response:', data);
            
            // Actualizar UI según la respuesta
            if (data.success) {
                // Mostrar notificación de éxito
                this.showNotification(`Acción "${action}" ejecutada correctamente`, 'success');
                
                // Acciones específicas según el tipo
                switch (action) {
                    case 'acknowledge':
                        this.alertsPanel.updateAlertStatus(alertData.id, 'acknowledged');
                        break;
                        
                    case 'escalate':
                        this.alertsPanel.updateAlertStatus(alertData.id, 'escalated');
                        break;
                        
                    case 'review_video':
                        if (alertData.video_url) {
                            this.openVideoModal(alertData.video_url, alertData.type);
                        }
                        break;
                }
            } else {
                // Mostrar error
                this.showNotification(`Error al ejecutar acción: ${data.message}`, 'error');
            }
        })
        .catch(error => {
            console.error('Error executing action:', error);
            this.showNotification('Error de conexión al ejecutar la acción', 'error');
        });
    }
    
    /**
     * Mostrar notificación en la UI
     */
    showNotification(message, type = 'info') {
        const notificationArea = document.getElementById('notification-area');
        if (!notificationArea) return;
        
        const notificationId = 'notification-' + Date.now();
        const notificationHtml = `
            <div id="${notificationId}" class="notification notification-${type}">
                <span class="notification-message">${message}</span>
                <button class="notification-close">&times;</button>
            </div>
        `;
        
        notificationArea.insertAdjacentHTML('beforeend', notificationHtml);
        
        // Agregar event listener para cerrar la notificación
        document.getElementById(notificationId).querySelector('.notification-close')
            .addEventListener('click', () => {
                const notification = document.getElementById(notificationId);
                notification.classList.add('notification-hiding');
                setTimeout(() => {
                    notification.remove();
                }, 300);
            });
            
        // Auto-ocultar después de un tiempo
        setTimeout(() => {
            const notification = document.getElementById(notificationId);
            if (notification) {
                notification.classList.add('notification-hiding');
                setTimeout(() => {
                    if (notification.parentNode) {
                        notification.remove();
                    }
                }, 300);
            }
        }, 5000);
    }
    
    /**
     * Reproducir sonido de alerta según prioridad
     */
    playAlertSound(priority) {
        // Verificar si hay soporte de audio
        if (!window.Audio) return;
        
        let soundFile;
        switch (priority) {
            case 'high':
                soundFile = this.config.sounds?.highPriority || 'assets/sounds/high_priority.mp3';
                break;
            case 'medium':
                soundFile = this.config.sounds?.mediumPriority || 'assets/sounds/medium_priority.mp3';
                break;
            default:
                soundFile = this.config.sounds?.lowPriority || 'assets/sounds/notification.mp3';
        }
        
        try {
            const audio = new Audio(soundFile);
            audio.play();
        } catch (e) {
            console.error('Error playing sound:', e);
        }
    }
    
    /**
     * Actualizar contador de alertas
     */
    updateAlertCounter() {
        fetch(`${this.apiBaseUrl}/alerts/count`)
            .then(response => response.json())
            .then(data => {
                this.state.systemStatus.alerts = data;
                
                // Actualizar badge de alertas
                const alertBadge = document.getElementById('alert-badge');
                if (alertBadge) {
                    alertBadge.textContent = data.total;
                    alertBadge.classList.toggle('hidden', data.total === 0);
                }
                
                // Actualizar contadores específicos
                const highPriorityCounter = document.getElementById('high-priority-counter');
                if (highPriorityCounter) {
                    highPriorityCounter.textContent = data.high;
                }
                
                const mediumPriorityCounter = document.getElementById('medium-priority-counter');
                if (mediumPriorityCounter) {
                    mediumPriorityCounter.textContent = data.medium;
                }
                
                const lowPriorityCounter = document.getElementById('low-priority-counter');
                if (lowPriorityCounter) {
                    lowPriorityCounter.textContent = data.low;
                }
            })
            .catch(error => {
                console.error('Error updating alert counter:', error);
            });
    }
    
    /**
     * Actualizar contador de cámaras
     */
    updateCameraCounter() {
        fetch(`${this.apiBaseUrl}/cameras/count`)
            .then(response => response.json())
            .then(data => {
                this.state.systemStatus.cameras = data;
                
                // Actualizar contadores
                const totalCamerasCounter = document.getElementById('total-cameras-counter');
                if (totalCamerasCounter) {
                    totalCamerasCounter.textContent = data.total;
                }
                
                const onlineCamerasCounter = document.getElementById('online-cameras-counter');
                if (onlineCamerasCounter) {
                    onlineCamerasCounter.textContent = data.online;
                }
                
                const offlineCamerasCounter = document.getElementById('offline-cameras-counter');
                if (offlineCamerasCounter) {
                    offlineCamerasCounter.textContent = data.offline;
                }
            })
            .catch(error => {
                console.error('Error updating camera counter:', error);
            });
    }
    
    /**
     * Actualizar estado del sistema
     */
    updateSystemStatus(data) {
        this.state.systemStatus.system = data;
        
        // Actualizar indicadores en la UI
        const cpuUsage = document.getElementById('cpu-usage');
        if (cpuUsage) {
            cpuUsage.textContent = `${data.cpu}%`;
            cpuUsage.style.width = `${data.cpu}%`;
            
            // Cambiar color según nivel
            if (data.cpu > 90) {
                cpuUsage.className = 'progress-bar bg-danger';
            } else if (data.cpu > 70) {
                cpuUsage.className = 'progress-bar bg-warning';
            } else {
                cpuUsage.className = 'progress-bar bg-success';
            }
        }
        
        const memoryUsage = document.getElementById('memory-usage');
        if (memoryUsage) {
            memoryUsage.textContent = `${data.memory}%`;
            memoryUsage.style.width = `${data.memory}%`;
            
            // Cambiar color según nivel
            if (data.memory > 90) {
                memoryUsage.className = 'progress-bar bg-danger';
            } else if (data.memory > 70) {
                memoryUsage.className = 'progress-bar bg-warning';
            } else {
                memoryUsage.className = 'progress-bar bg-success';
            }
        }
        
        const storageUsage = document.getElementById('storage-usage');
        if (storageUsage) {
            storageUsage.textContent = `${data.storage}%`;
            storageUsage.style.width = `${data.storage}%`;
            
            // Cambiar color según nivel
            if (data.storage > 90) {
                storageUsage.className = 'progress-bar bg-danger';
            } else if (data.storage > 70) {
                storageUsage.className = 'progress-bar bg-warning';
            } else {
                storageUsage.className = 'progress-bar bg-success';
            }
        }
    }
    
    /**
     * Actualizar perfil de usuario
     */
    updateUserProfile(userData) {
        const userNameElement = document.getElementById('user-name');
        if (userNameElement) {
            userNameElement.textContent = userData.name;
        }
        
        const userRoleElement = document.getElementById('user-role');
        if (userRoleElement) {
            userRoleElement.textContent = userData.role;
        }
        
        const userAvatarElement = document.getElementById('user-avatar');
        if (userAvatarElement && userData.avatar) {
            userAvatarElement.src = userData.avatar;
        }
    }
    
    /**
     * Abrir modal de video
     */
    openVideoModal(videoUrl, title) {
        const modalContainer = document.getElementById('video-modal-container');
        if (!modalContainer) return;
        
        // Crear modal si no existe
        if (!document.getElementById('video-modal')) {
            modalContainer.innerHTML = `
                <div id="video-modal" class="modal">
                    <div class="modal-dialog">
                        <div class="modal-content">
                            <div class="modal-header">
                                <h5 class="modal-title"></h5>
                                <button type="button" class="close" data-dismiss="modal">&times;</button>
                            </div>
                            <div class="modal-body">
                                <video id="modal-video-player" controls class="w-100"></video>
                            </div>
                        </div>
                    </div>
                </div>
            `;
            
            // Event listener para cerrar
            document.querySelector('#video-modal .close').addEventListener('click', () => {
                this.closeVideoModal();
            });
        }
        
        // Actualizar título y fuente de video
        document.querySelector('#video-modal .modal-title').textContent = 
            title ? `Video: ${title}` : 'Reproducción de video';
            
        const videoPlayer = document.getElementById('modal-video-player');
        videoPlayer.src = videoUrl;
        
        // Mostrar modal
        document.getElementById('video-modal').style.display = 'block';
        videoPlayer.play();
    }
    
    /**
     * Cerrar modal de video
     */
    closeVideoModal() {
        const modal = document.getElementById('video-modal');
        if (modal) {
            modal.style.display = 'none';
            
            // Detener reproducción
            const videoPlayer = document.getElementById('modal-video-player');
            if (videoPlayer) {
                videoPlayer.pause();
                videoPlayer.src = '';
            }
        }
    }
    
    /**
     * Manejar atajos de teclado
     */
    handleKeyboardShortcuts(event) {
        // ESC para cerrar modales
        if (event.key === 'Escape') {
            this.closeVideoModal();
        }
        
        // Ctrl+A para ir a panel de alertas
        if (event.ctrlKey && event.key === 'a') {
            event.preventDefault();
            document.querySelector('.tab-link[data-tab="alerts"]').click();
        }
        
        // Ctrl+C para ir a panel de cámaras
        if (event.ctrlKey && event.key === 'c') {
            event.preventDefault();
            document.querySelector('.tab-link[data-tab="live"]').click();
        }
        
        // Ctrl+S para ir a panel de estadísticas
        if (event.ctrlKey && event.key === 's') {
            event.preventDefault();
            document.querySelector('.tab-link[data-tab="stats"]').click();
        }
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { UnifiedControlPanel };
} 
```

### src\frontend\labeling\labeling_tool.js
```js | 686 bytes | Modificado: 2025-03-07 00:39:22.023242
```
class LabelingTool {
    constructor(containerId, datasetApi) {
        this.container = document.getElementById(containerId);
        this.api = datasetApi;
        this.currentImage = null;
        this.annotations = [];
        this.initialize();
    }
    
    initialize() {
        // Configurar interfaz de etiquetado
        // ...
    }
    
    loadImage(imageId) {
        // Cargar imagen para etiquetado
        // ...
    }
    
    createAnnotation(type, coords) {
        // Crear nueva anotación (bbox, polígono, etc)
        // ...
    }
    
    saveAnnotations() {
        // Guardar anotaciones actuales via API
        // ...
    }
} 
```

### src\frontend\services\alert_service.js
```js | 13934 bytes | Modificado: 2025-03-07 01:06:02.301777
```
/**
 * Servicio de Alertas y Notificaciones
 * 
 * Gestiona la recepción y emisión de alertas del sistema de seguridad.
 */
class AlertService {
    /**
     * Inicializa el servicio de alertas
     * @param {string} apiEndpoint Endpoint base de la API
     * @param {string} wsEndpoint Endpoint para WebSocket
     */
    constructor(apiEndpoint = '/api', wsEndpoint) {
        this.apiEndpoint = apiEndpoint;
        this.wsEndpoint = wsEndpoint || (window.location.protocol === 'https:' ? 
            `wss://${window.location.host}/ws/alerts` : 
            `ws://${window.location.host}/ws/alerts`);
            
        this.socket = null;
        this.reconnectTimer = null;
        this.reconnectAttempts = 0;
        this.maxReconnectAttempts = 10;
        this.reconnectDelay = 1000; // ms, aumentará con backoff
        
        this.alertListeners = new Map();
        this.alertCache = {
            active: new Map(),
            acknowledged: new Map(),
            all: []
        };
        
        // Conectar WebSocket
        this.connect();
    }
    
    /**
     * Conectar al WebSocket
     */
    connect() {
        try {
            // Limpiar temporizador existente
            if (this.reconnectTimer) {
                clearTimeout(this.reconnectTimer);
                this.reconnectTimer = null;
            }
            
            // Crear socket
            this.socket = new WebSocket(this.wsEndpoint);
            
            // Configurar manejo de eventos
            this.socket.onopen = this.handleSocketOpen.bind(this);
            this.socket.onmessage = this.handleSocketMessage.bind(this);
            this.socket.onclose = this.handleSocketClose.bind(this);
            this.socket.onerror = this.handleSocketError.bind(this);
        } catch (error) {
            console.error('Error connecting to WebSocket:', error);
            this.scheduleReconnect();
        }
    }
    
    /**
     * Manejar apertura de conexión
     */
    handleSocketOpen() {
        console.log('WebSocket connected');
        this.reconnectAttempts = 0;
        this.reconnectDelay = 1000;
        
        // Solicitar alertas activas al conectar
        this.requestActiveAlerts();
    }
    
    /**
     * Manejar recepción de mensaje
     */
    handleSocketMessage(event) {
        try {
            const data = JSON.parse(event.data);
            
            // Procesar según tipo de mensaje
            switch (data.type) {
                case 'new_alert':
                    this.processNewAlert(data.alert);
                    break;
                    
                case 'update_alert':
                    this.processAlertUpdate(data.alert);
                    break;
                    
                case 'active_alerts':
                    this.processActiveAlerts(data.alerts);
                    break;
                    
                default:
                    console.warn('Unknown message type:', data.type);
            }
        } catch (error) {
            console.error('Error processing WebSocket message:', error);
        }
    }
    
    /**
     * Manejar cierre de conexión
     */
    handleSocketClose(event) {
        if (event.wasClean) {
            console.log(`WebSocket closed cleanly, code=${event.code}, reason=${event.reason}`);
        } else {
            console.warn('WebSocket connection abruptly closed');
        }
        
        this.scheduleReconnect();
    }
    
    /**
     * Manejar error de conexión
     */
    handleSocketError(error) {
        console.error('WebSocket error:', error);
    }
    
    /**
     * Programar reconexión con backoff exponencial
     */
    scheduleReconnect() {
        if (this.reconnectAttempts >= this.maxReconnectAttempts) {
            console.error('Max reconnection attempts reached, giving up');
            return;
        }
        
        // Calcular delay con backoff exponencial
        const delay = Math.min(30000, this.reconnectDelay * Math.pow(1.5, this.reconnectAttempts));
        
        console.log(`Scheduling reconnect in ${delay}ms (attempt ${this.reconnectAttempts + 1})`);
        
        this.reconnectTimer = setTimeout(() => {
            this.reconnectAttempts++;
            this.connect();
        }, delay);
    }
    
    /**
     * Procesar nueva alerta
     */
    processNewAlert(alert) {
        // Guardar en caché
        this.alertCache.active.set(alert.id, alert);
        
        // Agregar al inicio del array de todas las alertas
        this.alertCache.all.unshift(alert);
        
        // Notificar a los suscriptores
        this.notifyAlertListeners('new', alert);
    }
    
    /**
     * Procesar actualización de alerta
     */
    processAlertUpdate(alert) {
        // Actualizar en caché según estado
        if (alert.status === 'acknowledged' || alert.status === 'resolved') {
            // Mover de activas a reconocidas
            this.alertCache.active.delete(alert.id);
            this.alertCache.acknowledged.set(alert.id, alert);
        } else {
            // Actualizar en la misma colección
            if (this.alertCache.active.has(alert.id)) {
                this.alertCache.active.set(alert.id, alert);
            } else if (this.alertCache.acknowledged.has(alert.id)) {
                this.alertCache.acknowledged.set(alert.id, alert);
            }
        }
        
        // Actualizar en array de todas
        const index = this.alertCache.all.findIndex(a => a.id === alert.id);
        if (index !== -1) {
            this.alertCache.all[index] = alert;
        }
        
        // Notificar a los suscriptores
        this.notifyAlertListeners('update', alert);
    }
    
    /**
     * Procesar lista de alertas activas
     */
    processActiveAlerts(alerts) {
        // Limpiar caché actual
        this.alertCache.active.clear();
        
        // Agregar alertas a la caché
        alerts.forEach(alert => {
            this.alertCache.active.set(alert.id, alert);
        });
        
        // Actualizar array completo
        this.loadAllAlerts();
        
        // Notificar a los suscriptores
        this.notifyAlertListeners('load', Array.from(this.alertCache.active.values()));
    }
    
    /**
     * Solicitar alertas activas al servidor
     */
    requestActiveAlerts() {
        // Si el socket está abierto, enviar solicitud
        if (this.socket && this.socket.readyState === WebSocket.OPEN) {
            this.socket.send(JSON.stringify({
                type: 'get_active_alerts'
            }));
        } else {
            // Intentar con HTTP
            this.loadActiveAlerts();
        }
    }
    
    /**
     * Cargar alertas activas mediante HTTP
     */
    async loadActiveAlerts() {
        try {
            const response = await fetch(`${this.apiEndpoint}/alerts/active`);
            if (!response.ok) {
                throw new Error(`HTTP error: ${response.status}`);
            }
            
            const alerts = await response.json();
            this.processActiveAlerts(alerts);
            
            return alerts;
        } catch (error) {
            console.error('Error loading active alerts:', error);
            return [];
        }
    }
    
    /**
     * Cargar todas las alertas (historial)
     */
    async loadAllAlerts(page = 1, limit = 100) {
        try {
            const response = await fetch(`${this.apiEndpoint}/alerts?page=${page}&limit=${limit}`);
            if (!response.ok) {
                throw new Error(`HTTP error: ${response.status}`);
            }
            
            const data = await response.json();
            
            // Actualizar caché
            this.alertCache.all = data.alerts;
            
            // Notificar a los suscriptores
            this.notifyAlertListeners('history', data.alerts);
            
            return data;
        } catch (error) {
            console.error('Error loading alert history:', error);
            return { alerts: [], total: 0 };
        }
    }
    
    /**
     * Obtener una alerta por ID
     */
    async getAlert(alertId) {
        // Buscar en caché primero
        if (this.alertCache.active.has(alertId)) {
            return this.alertCache.active.get(alertId);
        }
        
        if (this.alertCache.acknowledged.has(alertId)) {
            return this.alertCache.acknowledged.get(alertId);
        }
        
        // Si no está en caché, cargar desde API
        try {
            const response = await fetch(`${this.apiEndpoint}/alerts/${alertId}`);
            if (!response.ok) {
                throw new Error(`HTTP error: ${response.status}`);
            }
            
            const alert = await response.json();
            
            // Actualizar caché
            if (alert.status === 'new' || alert.status === 'in_progress') {
                this.alertCache.active.set(alertId, alert);
            } else {
                this.alertCache.acknowledged.set(alertId, alert);
            }
            
            return alert;
        } catch (error) {
            console.error(`Error loading alert ${alertId}:`, error);
            throw error;
        }
    }
    
    /**
     * Realizar acción sobre una alerta
     */
    async takeAction(alertId, action, data = {}) {
        try {
            const response = await fetch(`${this.apiEndpoint}/alerts/${alertId}/actions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    action,
                    ...data
                })
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.message || `Error al ejecutar acción ${action}`);
            }
            
            // Actualizar caché si la respuesta incluye la alerta actualizada
            const result = await response.json();
            
            if (result.alert) {
                this.processAlertUpdate(result.alert);
            }
            
            return result;
        } catch (error) {
            console.error(`Error executing action ${action} on alert ${alertId}:`, error);
            throw error;
        }
    }
    
    /**
     * Reconocer una alerta
     */
    acknowledgeAlert(alertId, notes = '') {
        return this.takeAction(alertId, 'acknowledge', { notes });
    }
    
    /**
     * Marcar alerta como resuelta
     */
    resolveAlert(alertId, resolution = '', notes = '') {
        return this.takeAction(alertId, 'resolve', { resolution, notes });
    }
    
    /**
     * Marcar alerta como falsa alarma
     */
    markAsFalseAlarm(alertId, reason = '') {
        return this.takeAction(alertId, 'false_alarm', { reason });
    }
    
    /**
     * Escalar alerta a superior o autoridades
     */
    escalateAlert(alertId, recipient = '', notes = '') {
        return this.takeAction(alertId, 'escalate', { recipient, notes });
    }
    
    /**
     * Suscribirse a eventos de alertas
     * @param {string} event Tipo de evento ('new', 'update', 'load', 'history', '*')
     * @param {Function} callback Función a llamar cuando ocurra el evento
     * @returns {Function} Función para cancelar la suscripción
     */
    subscribe(event, callback) {
        if (!this.alertListeners.has(event)) {
            this.alertListeners.set(event, new Set());
        }
        
        const listeners = this.alertListeners.get(event);
        listeners.add(callback);
        
        // Retornar función para cancelar suscripción
        return () => {
            const listeners = this.alertListeners.get(event);
            if (listeners) {
                listeners.delete(callback);
            }
        };
    }
    
    /**
     * Notificar a los suscriptores sobre eventos de alertas
     * @param {string} event Tipo de evento
     * @param {Object|Array} data Datos del evento
     */
    notifyAlertListeners(event, data) {
        // Notificar a suscriptores del evento específico
        const specificListeners = this.alertListeners.get(event);
        if (specificListeners) {
            specificListeners.forEach(callback => {
                try {
                    callback(data);
                } catch (error) {
                    console.error(`Error in ${event} alert listener:`, error);
                }
            });
        }
        
        // Notificar a suscriptores de todos los eventos
        const allListeners = this.alertListeners.get('*');
        if (allListeners) {
            allListeners.forEach(callback => {
                try {
                    callback(event, data);
                } catch (error) {
                    console.error(`Error in global alert listener:`, error);
                }
            });
        }
    }
    
    /**
     * Cerrar conexión al destruir el servicio
     */
    destroy() {
        if (this.socket) {
            this.socket.close();
            this.socket = null;
        }
        
        if (this.reconnectTimer) {
            clearTimeout(this.reconnectTimer);
            this.reconnectTimer = null;
        }
        
        this.alertListeners.clear();
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { AlertService };
} 
```

### src\frontend\services\auth_service.js
```js | 11650 bytes | Modificado: 2025-03-07 01:06:04.364022
```
/**
 * Servicio de Autenticación
 * 
 * Gestiona la autenticación, autorización y permisos de usuarios.
 */
class AuthService {
    /**
     * Inicializa el servicio de autenticación
     * @param {string} apiEndpoint Endpoint base de la API
     */
    constructor(apiEndpoint = '/api') {
        this.apiEndpoint = apiEndpoint;
        this.user = null;
        this.token = localStorage.getItem('auth_token');
        this.authListeners = [];
        this.refreshTimer = null;
        
        // Verificar si hay un token almacenado y validarlo
        if (this.token) {
            this.validateToken();
        }
    }
    
    /**
     * Iniciar sesión con credenciales
     * @param {string} username Nombre de usuario
     * @param {string} password Contraseña
     * @returns {Promise<Object>} Información del usuario autenticado
     */
    async login(username, password) {
        try {
            const response = await fetch(`${this.apiEndpoint}/auth/login`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ username, password })
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.message || 'Error de autenticación');
            }
            
            const data = await response.json();
            
            // Guardar token y datos del usuario
            this.token = data.token;
            this.user = data.user;
            
            // Guardar en localStorage
            localStorage.setItem('auth_token', this.token);
            
            // Configurar temporizador para refrescar token
            this.setupTokenRefresh(data.expiresIn || 3600);
            
            // Notificar a los suscriptores
            this.notifyAuthChange(true);
            
            return this.user;
        } catch (error) {
            console.error('Error de inicio de sesión:', error);
            throw error;
        }
    }
    
    /**
     * Cerrar sesión del usuario actual
     * @returns {Promise<boolean>} Resultado de la operación
     */
    async logout() {
        try {
            // Intentar cerrar sesión en el servidor
            if (this.token) {
                await fetch(`${this.apiEndpoint}/auth/logout`, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${this.token}`
                    }
                }).catch(err => console.warn('Error en logout:', err));
            }
            
            // Limpiar datos almacenados independientemente de la respuesta
            this.token = null;
            this.user = null;
            localStorage.removeItem('auth_token');
            
            // Detener temporizador de refresco
            if (this.refreshTimer) {
                clearTimeout(this.refreshTimer);
                this.refreshTimer = null;
            }
            
            // Notificar a los suscriptores
            this.notifyAuthChange(false);
            
            return true;
        } catch (error) {
            console.error('Error al cerrar sesión:', error);
            return false;
        }
    }
    
    /**
     * Verificar si el usuario está autenticado
     * @returns {boolean} Estado de autenticación
     */
    isAuthenticated() {
        return !!this.token && !!this.user;
    }
    
    /**
     * Obtener usuario actual
     * @returns {Object|null} Datos del usuario autenticado
     */
    getCurrentUser() {
        return this.user;
    }
    
    /**
     * Verificar si el usuario tiene un permiso específico
     * @param {string} permission Permiso a verificar
     * @returns {boolean} Si el usuario tiene el permiso
     */
    hasPermission(permission) {
        if (!this.user || !this.user.permissions) {
            return false;
        }
        
        return this.user.permissions.includes(permission);
    }
    
    /**
     * Verificar si el usuario pertenece a un rol
     * @param {string} role Rol a verificar
     * @returns {boolean} Si el usuario tiene el rol
     */
    hasRole(role) {
        if (!this.user || !this.user.roles) {
            return false;
        }
        
        return this.user.roles.includes(role);
    }
    
    /**
     * Validar token actual con el servidor
     * @returns {Promise<boolean>} Si el token es válido
     */
    async validateToken() {
        if (!this.token) {
            return false;
        }
        
        try {
            const response = await fetch(`${this.apiEndpoint}/auth/validate`, {
                method: 'GET',
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });
            
            if (!response.ok) {
                // Token inválido, limpiar datos
                this.token = null;
                this.user = null;
                localStorage.removeItem('auth_token');
                this.notifyAuthChange(false);
                return false;
            }
            
            // Token válido, obtener datos del usuario
            const data = await response.json();
            this.user = data.user;
            
            // Actualizar token si se proporciona uno nuevo
            if (data.token) {
                this.token = data.token;
                localStorage.setItem('auth_token', this.token);
                this.setupTokenRefresh(data.expiresIn || 3600);
            }
            
            this.notifyAuthChange(true);
            return true;
        } catch (error) {
            console.error('Error validando token:', error);
            return false;
        }
    }
    
    /**
     * Refrescar token antes de que expire
     * @returns {Promise<boolean>} Si el refresco fue exitoso
     */
    async refreshToken() {
        if (!this.token) {
            return false;
        }
        
        try {
            const response = await fetch(`${this.apiEndpoint}/auth/refresh`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });
            
            if (!response.ok) {
                // No se pudo refrescar el token
                return false;
            }
            
            const data = await response.json();
            
            // Actualizar token
            this.token = data.token;
            localStorage.setItem('auth_token', this.token);
            
            // Configurar próximo refresco
            this.setupTokenRefresh(data.expiresIn || 3600);
            
            return true;
        } catch (error) {
            console.error('Error refrescando token:', error);
            return false;
        }
    }
    
    /**
     * Configurar temporizador para refrescar token
     * @param {number} expiresIn Tiempo en segundos hasta expiración
     */
    setupTokenRefresh(expiresIn) {
        // Limpiar temporizador anterior si existe
        if (this.refreshTimer) {
            clearTimeout(this.refreshTimer);
        }
        
        // Configurar refresco para 5 minutos antes de expirar
        const refreshTime = Math.max((expiresIn - 300) * 1000, 0);
        
        this.refreshTimer = setTimeout(() => {
            this.refreshToken();
        }, refreshTime);
    }
    
    /**
     * Suscribirse a cambios en el estado de autenticación
     * @param {Function} callback Función a llamar cuando cambie el estado
     * @returns {Function} Función para cancelar la suscripción
     */
    onAuthChange(callback) {
        if (typeof callback === 'function') {
            this.authListeners.push(callback);
            
            // Notificar estado actual inmediatamente
            setTimeout(() => {
                callback(this.isAuthenticated(), this.user);
            }, 0);
            
            // Retornar función para cancelar suscripción
            return () => {
                const index = this.authListeners.indexOf(callback);
                if (index !== -1) {
                    this.authListeners.splice(index, 1);
                }
            };
        }
    }
    
    /**
     * Notificar a los suscriptores sobre cambios en la autenticación
     * @param {boolean} isAuthenticated Estado de autenticación
     */
    notifyAuthChange(isAuthenticated) {
        this.authListeners.forEach(callback => {
            try {
                callback(isAuthenticated, this.user);
            } catch (error) {
                console.error('Error en callback de autenticación:', error);
            }
        });
    }
    
    /**
     * Recuperar contraseña
     * @param {string} email Correo electrónico del usuario
     * @returns {Promise<boolean>} Resultado de la operación
     */
    async requestPasswordReset(email) {
        try {
            const response = await fetch(`${this.apiEndpoint}/auth/reset-password`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ email })
            });
            
            return response.ok;
        } catch (error) {
            console.error('Error al solicitar recuperación de contraseña:', error);
            return false;
        }
    }
    
    /**
     * Cambiar contraseña con token de recuperación
     * @param {string} token Token de recuperación
     * @param {string} newPassword Nueva contraseña
     * @returns {Promise<boolean>} Resultado de la operación
     */
    async resetPassword(token, newPassword) {
        try {
            const response = await fetch(`${this.apiEndpoint}/auth/reset-password/confirm`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ token, newPassword })
            });
            
            return response.ok;
        } catch (error) {
            console.error('Error al cambiar contraseña:', error);
            return false;
        }
    }
    
    /**
     * Crear una nueva cuenta de usuario
     * @param {Object} userData Datos del nuevo usuario
     * @returns {Promise<Object>} Información del usuario creado
     */
    async register(userData) {
        try {
            const response = await fetch(`${this.apiEndpoint}/auth/register`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(userData)
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.message || 'Error al registrar usuario');
            }
            
            return await response.json();
        } catch (error) {
            console.error('Error al registrar usuario:', error);
            throw error;
        }
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { AuthService };
} 
```

### src\frontend\services\config_service.js
```js | 7865 bytes | Modificado: 2025-03-07 01:03:31.395065
```
/**
 * Servicio de Configuración
 * 
 * Gestiona la carga, validación y actualización de configuraciones del sistema.
 */
class ConfigService {
    /**
     * Inicializa el servicio de configuración
     * @param {string} apiEndpoint Endpoint base de la API
     */
    constructor(apiEndpoint = '/api') {
        this.apiEndpoint = apiEndpoint;
        this.configCache = new Map();
        this.configListeners = new Map();
    }
    
    /**
     * Obtener configuración por nombre
     * @param {string} configName Nombre de la configuración
     * @param {boolean} forceRefresh Forzar recarga desde el servidor
     * @returns {Promise<Object>} Configuración solicitada
     */
    async getConfig(configName, forceRefresh = false) {
        // Si ya tenemos la configuración en caché y no se fuerza recarga
        if (!forceRefresh && this.configCache.has(configName)) {
            return this.configCache.get(configName);
        }
        
        // Cargar desde la API
        try {
            const response = await fetch(`${this.apiEndpoint}/config/${configName}`);
            
            if (!response.ok) {
                throw new Error(`Error loading config ${configName}: ${response.statusText}`);
            }
            
            const config = await response.json();
            
            // Guardar en caché
            this.configCache.set(configName, config);
            
            // Notificar a los suscriptores
            this.notifyConfigChange(configName, config);
            
            return config;
        } catch (error) {
            console.error('Config service error:', error);
            throw error;
        }
    }
    
    /**
     * Actualizar configuración
     * @param {string} configName Nombre de la configuración
     * @param {Object} configData Nuevos datos de configuración
     * @returns {Promise<Object>} Configuración actualizada
     */
    async updateConfig(configName, configData) {
        try {
            const response = await fetch(`${this.apiEndpoint}/config/${configName}`, {
                method: 'PUT',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(configData)
            });
            
            if (!response.ok) {
                throw new Error(`Error updating config ${configName}: ${response.statusText}`);
            }
            
            const updatedConfig = await response.json();
            
            // Actualizar caché
            this.configCache.set(configName, updatedConfig);
            
            // Notificar a los suscriptores
            this.notifyConfigChange(configName, updatedConfig);
            
            return updatedConfig;
        } catch (error) {
            console.error('Config update error:', error);
            throw error;
        }
    }
    
    /**
     * Suscribirse a cambios en una configuración
     * @param {string} configName Nombre de la configuración
     * @param {Function} callback Función a llamar cuando la configuración cambie
     * @returns {Function} Función para cancelar la suscripción
     */
    subscribeToConfig(configName, callback) {
        if (!this.configListeners.has(configName)) {
            this.configListeners.set(configName, new Set());
        }
        
        const listeners = this.configListeners.get(configName);
        listeners.add(callback);
        
        // Si ya tenemos la configuración en caché, notificar inmediatamente
        if (this.configCache.has(configName)) {
            try {
                callback(this.configCache.get(configName));
            } catch (error) {
                console.error('Error in config subscriber callback:', error);
            }
        }
        
        // Retornar función para cancelar suscripción
        return () => {
            const listeners = this.configListeners.get(configName);
            if (listeners) {
                listeners.delete(callback);
            }
        };
    }
    
    /**
     * Notificar a los suscriptores sobre un cambio en la configuración
     * @param {string} configName Nombre de la configuración
     * @param {Object} configData Datos de configuración actualizados
     */
    notifyConfigChange(configName, configData) {
        const listeners = this.configListeners.get(configName);
        if (!listeners) return;
        
        listeners.forEach(callback => {
            try {
                callback(configData);
            } catch (error) {
                console.error('Error in config change callback:', error);
            }
        });
    }
    
    /**
     * Obtener información sobre todas las configuraciones disponibles
     * @returns {Promise<Array>} Lista de configuraciones disponibles
     */
    async listAvailableConfigs() {
        try {
            const response = await fetch(`${this.apiEndpoint}/config`);
            
            if (!response.ok) {
                throw new Error(`Error listing configs: ${response.statusText}`);
            }
            
            return await response.json();
        } catch (error) {
            console.error('Error listing configs:', error);
            throw error;
        }
    }
    
    /**
     * Validar configuración
     * @param {string} configName Nombre de la configuración
     * @param {Object} configData Datos de configuración a validar
     * @returns {Promise<Object>} Resultado de la validación
     */
    async validateConfig(configName, configData) {
        try {
            const response = await fetch(`${this.apiEndpoint}/config/${configName}/validate`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(configData)
            });
            
            const result = await response.json();
            
            return {
                valid: response.ok,
                errors: result.errors || [],
                warnings: result.warnings || []
            };
        } catch (error) {
            console.error('Config validation error:', error);
            return {
                valid: false,
                errors: [error.message],
                warnings: []
            };
        }
    }
    
    /**
     * Restablecer configuración a valores predeterminados
     * @param {string} configName Nombre de la configuración
     * @returns {Promise<Object>} Configuración restablecida
     */
    async resetConfig(configName) {
        try {
            const response = await fetch(`${this.apiEndpoint}/config/${configName}/reset`, {
                method: 'POST'
            });
            
            if (!response.ok) {
                throw new Error(`Error resetting config ${configName}: ${response.statusText}`);
            }
            
            const resetConfig = await response.json();
            
            // Actualizar caché
            this.configCache.set(configName, resetConfig);
            
            // Notificar a los suscriptores
            this.notifyConfigChange(configName, resetConfig);
            
            return resetConfig;
        } catch (error) {
            console.error('Config reset error:', error);
            throw error;
        }
    }
    
    /**
     * Limpiar caché de configuraciones
     */
    clearCache() {
        this.configCache.clear();
    }
}

// Exportar para uso en módulos
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { ConfigService };
} 
```

### src\frontend\src\components\ConfigEditor.vue
```vue | 15650 bytes | Modificado: 2025-03-13 20:38:21.692854
```
<template>
  <div class="config-editor">
    <h1>Configuración del Sistema</h1>
    
    <div v-if="loading" class="loading-spinner">
      <div class="spinner"></div>
      <p>Cargando configuración...</p>
    </div>
    
    <div v-else-if="error" class="error-message">
      <i class="fas fa-exclamation-triangle"></i>
      <p>{{ error }}</p>
      <button @click="loadConfig" class="btn btn-primary">Reintentar</button>
    </div>
    
    <div v-else class="config-container">
      <!-- Pestañas de configuración -->
      <ul class="nav nav-tabs" role="tablist">
        <li class="nav-item" v-for="(section, index) in configSections" :key="index">
          <a class="nav-link" :class="{ active: activeSection === section.key }" 
             @click="activeSection = section.key" href="#" role="tab">
            {{ section.label }}
          </a>
        </li>
      </ul>
      
      <!-- Contenido de configuración por sección -->
      <div class="tab-content p-3 border border-top-0 rounded-bottom">
        <!-- Sección del sistema -->
        <div class="tab-pane fade" :class="{ 'show active': activeSection === 'system' }">
          <h3>Configuración General</h3>
          <form>
            <div class="form-group row">
              <label class="col-sm-3 col-form-label">Nombre del Sistema</label>
              <div class="col-sm-9">
                <input type="text" class="form-control" v-model="config.system.name">
              </div>
            </div>
            
            <div class="form-group row">
              <label class="col-sm-3 col-form-label">Versión</label>
              <div class="col-sm-9">
                <input type="text" class="form-control" v-model="config.system.version" readonly>
              </div>
            </div>
            
            <div class="form-group row">
              <label class="col-sm-3 col-form-label">Nivel de Log</label>
              <div class="col-sm-9">
                <select class="form-control" v-model="config.system.log_level">
                  <option value="DEBUG">DEBUG</option>
                  <option value="INFO">INFO</option>
                  <option value="WARNING">WARNING</option>
                  <option value="ERROR">ERROR</option>
                  <option value="CRITICAL">CRITICAL</option>
                </select>
              </div>
            </div>
            
            <div class="form-group row">
              <label class="col-sm-3 col-form-label">Zona Horaria</label>
              <div class="col-sm-9">
                <input type="text" class="form-control" v-model="config.system.timezone">
              </div>
            </div>
            
            <div class="form-group row">
              <div class="col-sm-3">Modo Debug</div>
              <div class="col-sm-9">
                <div class="form-check">
                  <input class="form-check-input" type="checkbox" v-model="config.system.enable_debug">
                </div>
              </div>
            </div>
          </form>
        </div>
        
        <!-- Sección de cámaras -->
        <div class="tab-pane fade" :class="{ 'show active': activeSection === 'cameras' }">
          <div class="d-flex justify-content-between align-items-center mb-3">
            <h3>Cámaras</h3>
            <button class="btn btn-primary" @click="addCamera">
              <i class="fas fa-plus"></i> Añadir Cámara
            </button>
          </div>
          
          <div v-if="config.cameras.length === 0" class="alert alert-info">
            No hay cámaras configuradas. Añade una nueva cámara haciendo clic en el botón "Añadir Cámara".
          </div>
          
          <div v-else class="camera-list">
            <div v-for="(camera, index) in config.cameras" :key="camera.id" class="card mb-3">
              <div class="card-header d-flex justify-content-between align-items-center">
                <h5 class="mb-0">
                  <i class="fas fa-video"></i> {{ camera.name }}
                  <span v-if="!camera.enabled" class="badge badge-secondary ml-2">Desactivada</span>
                </h5>
                <div>
                  <button class="btn btn-sm btn-outline-primary mr-2" @click="editCamera(index)">
                    <i class="fas fa-edit"></i> Editar
                  </button>
                  <button class="btn btn-sm btn-outline-danger" @click="removeCamera(index)">
                    <i class="fas fa-trash"></i> Eliminar
                  </button>
                </div>
              </div>
              <div class="card-body">
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">URL</label>
                  <div class="col-sm-9">
                    <input type="text" class="form-control" v-model="camera.url">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Usuario</label>
                  <div class="col-sm-9">
                    <input type="text" class="form-control" v-model="camera.username">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Contraseña</label>
                  <div class="col-sm-9">
                    <input type="password" class="form-control" v-model="camera.password">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Resolución</label>
                  <div class="col-sm-9">
                    <input type="text" class="form-control" v-model="camera.resolution">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">FPS</label>
                  <div class="col-sm-9">
                    <input type="number" class="form-control" v-model.number="camera.fps" min="1" max="60" step="1">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Modo de Grabación</label>
                  <div class="col-sm-9">
                    <select class="form-control" v-model="camera.recording.mode">
                      <option value="motion">Movimiento</option>
                      <option value="all">Toda la Cámara</option>
                    </select>
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Pre-Grabación</label>
                  <div class="col-sm-9">
                    <input type="number" class="form-control" v-model.number="camera.recording.pre_record" min="0" max="10" step="1">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Post-Grabación</label>
                  <div class="col-sm-9">
                    <input type="number" class="form-control" v-model.number="camera.recording.post_record" min="0" max="10" step="1">
                  </div>
                </div>
                <div class="form-group row">
                  <label class="col-sm-3 col-form-label">Peso del módulo</label>
                  <div class="col-sm-9">
                    <input type="number" class="form-control" v-model.number="camera.weight" min="0.1" max="1.0" step="0.1">
                    <small class="form-text text-muted">Entre 0.1 y 1.0, donde 1.0 es el peso máximo</small>
                  </div>
                </div>
              </div>
              <div class="modal-footer">
                <button type="button" class="btn btn-secondary" @click="closeCameraModal">Cancelar</button>
                <button type="button" class="btn btn-primary" @click="saveCamera">Guardar</button>
              </div>
            </div>
          </div>
        </div>
      </div>
      
      <div class="mt-4 d-flex justify-content-end">
        <button class="btn btn-secondary mr-2" @click="resetConfig">
          <i class="fas fa-undo"></i> Restablecer
        </button>
        <button class="btn btn-primary" @click="saveConfig" :disabled="saving">
          <i class="fas fa-save"></i> {{ saving ? 'Guardando...' : 'Guardar Configuración' }}
        </button>
      </div>
    </div>
  </div>
</template>

<script>
import axios from 'axios';

export default {
  name: 'ConfigEditor',
  data() {
    return {
      config: null,
      originalConfig: null,
      loading: true,
      saving: false,
      error: null,
      activeSection: 'system',
      configSections: [
        { key: 'system', label: 'Sistema' },
        { key: 'cameras', label: 'Cámaras' },
        { key: 'detection', label: 'Detección' },
        { key: 'storage', label: 'Almacenamiento' },
        { key: 'notifications', label: 'Notificaciones' },
        { key: 'agents', label: 'Agentes' }
      ],
      showCameraModal: false,
      showZoneModal: false,
      showAgentModal: false,
      editing: null,
      editingIndex: -1,
      editingParentIndex: -1,
      cameraVendors: [
        { value: 'hikvision', label: 'Hikvision' },
        { value: 'dahua', label: 'Dahua' },
        { value: 'axis', label: 'Axis' },
        { value: 'generic', label: 'RTSP Genérico' }
      ]
    };
  },
  created() {
    this.loadConfig();
  },
  methods: {
    async loadConfig() {
      this.loading = true;
      this.error = null;
      
      try {
        const response = await axios.get('/api/config');
        this.config = response.data;
        this.originalConfig = JSON.parse(JSON.stringify(response.data)); // Copia profunda
        this.loading = false;
      } catch (err) {
        this.loading = false;
        this.error = `Error cargando la configuración: ${err.message}`;
        console.error('Error cargando configuración:', err);
      }
    },
    
    async saveConfig() {
      this.saving = true;
      
      try {
        await axios.post('/api/config', this.config);
        this.originalConfig = JSON.parse(JSON.stringify(this.config)); // Actualizar original
        this.$toasted.success('Configuración guardada correctamente');
        this.saving = false;
      } catch (err) {
        this.saving = false;
        this.$toasted.error(`Error guardando la configuración: ${err.message}`);
        console.error('Error guardando configuración:', err);
      }
    },
    
    resetConfig() {
      if (confirm('¿Estás seguro de restablecer todos los cambios?')) {
        this.config = JSON.parse(JSON.stringify(this.originalConfig)); // Copia profunda
      }
    },
    
    addCamera() {
      this.editing = {
        id: `cam_${Date.now()}`,
        name: 'Nueva Cámara',
        enabled: true,
        vendor: 'generic',
        url: '',
        username: '',
        password: '',
        fps: 15,
        resolution: '1280x720',
        recording: {
          enabled: true,
          mode: 'motion',
          pre_record: 5,
          post_record: 10
        },
        zones: []
      };
      this.editingIndex = -1;
      this.showCameraModal = true;
    },
    
    editCamera(index) {
      this.editing = JSON.parse(JSON.stringify(this.config.cameras[index])); // Copia profunda
      this.editingIndex = index;
      this.showCameraModal = true;
    },
    
    saveCamera() {
      if (this.editingIndex === -1) {
        // Nueva cámara
        this.config.cameras.push(this.editing);
      } else {
        // Actualizar cámara existente
        this.config.cameras[this.editingIndex] = this.editing;
      }
      
      this.closeCameraModal();
    },
    
    removeCamera(index) {
      if (confirm(`¿Estás seguro de eliminar la cámara "${this.config.cameras[index].name}"?`)) {
        this.config.cameras.splice(index, 1);
      }
    },
    
    closeCameraModal() {
      this.showCameraModal = false;
      this.editing = null;
      this.editingIndex = -1;
    },
    
    addZone(cameraIndex) {
      this.editing = {
        name: 'Nueva Zona',
        type: 'intrusion',
        points: [[100, 100], [300, 100], [300, 300], [100, 300]],
        color: 'red',
        enabled: true
      };
      this.editingIndex = -1;
      this.editingParentIndex = cameraIndex;
      this.showZoneModal = true;
    },
    
    editZone(cameraIndex, zoneIndex) {
      this.editing = JSON.parse(JSON.stringify(this.config.cameras[cameraIndex].zones[zoneIndex]));
      this.editingIndex = zoneIndex;
      this.editingParentIndex = cameraIndex;
      this.showZoneModal = true;
    },
    
    saveZone() {
      if (this.editingIndex === -1) {
        // Nueva zona
        this.config.cameras[this.editingParentIndex].zones.push(this.editing);
      } else {
        // Actualizar zona existente
        this.config.cameras[this.editingParentIndex].zones[this.editingIndex] = this.editing;
      }
      
      this.closeZoneModal();
    },
    
    removeZone(cameraIndex, zoneIndex) {
      if (confirm(`¿Estás seguro de eliminar la zona "${this.config.cameras[cameraIndex].zones[zoneIndex].name}"?`)) {
        this.config.cameras[cameraIndex].zones.splice(zoneIndex, 1);
      }
    },
    
    closeZoneModal() {
      this.showZoneModal = false;
      this.editing = null;
      this.editingIndex = -1;
      this.editingParentIndex = -1;
    },
    
    addAgent() {
      this.editing = {
        type: 'custom',
        name: 'Nuevo Agente',
        enabled: true,
        model: '',
        confidence_threshold: 0.5,
        schedule: {
          enabled: false,
          time_ranges: []
        },
        params: {}
      };
      this.editingIndex = -1;
      this.showAgentModal = true;
    },
    
    editAgent(type, key) {
      this.editing = JSON.parse(JSON.stringify(this.config.agents[type]));
      this.editing.type = type;
      this.editing.key = key;
      this.editingIndex = type;
      this.showAgentModal = true;
    },
    
    saveAgent() {
      const { type, ...agentConfig } = this.editing;
      this.config.agents[type] = agentConfig;
      this.closeAgentModal();
    },
    
    closeAgentModal() {
      this.showAgentModal = false;
      this.editing = null;
      this.editingIndex = -1;
    }
  }
};
</script>

<style scoped>
.config-editor {
  padding: 1rem;
}

.loading-spinner {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  height: 300px;
}

.spinner {
  border: 5px solid #f3f3f3;
  border-top: 5px solid #3498db;
  border-radius: 50%;
  width: 50px;
  height: 50px;
  animation: spin 1s linear infinite;
  margin-bottom: 1rem;
}

@keyframes spin {
  0% { transform: rotate(0deg); }
  100% { transform: rotate(360deg); }
}

.error-message {
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 2rem;
  color: #721c24;
  background-color: #f8d7da;
  border: 1px solid #f5c6cb;
  border-radius: 0.25rem;
}

.error-message i {
  font-size: 2rem;
  margin-bottom: 1rem;
}

.tab-content {
  background-color: white;
}
</style> 
```

### src\frontend\static\css\styles.css
```css | 663 bytes | Modificado: 2025-03-07 02:25:56.030361
```
/*
vigIA - Sistema de Vigilancia Inteligente con IA
Versión PMV (Proyecto MOTION_DETECTOR)

© 2025 Gustavo Mayorga. Todos los derechos reservados.

Este código es propiedad exclusiva de Gustavo Mayorga y está protegido por leyes de 
propiedad intelectual. Ninguna parte de este software puede ser reproducida, distribuida, 
o utilizada para crear trabajos derivados sin autorización explícita por escrito.

Contacto legal: gustavo.mayorga.gm@gmail.com

AVISO: El uso no autorizado de este código o sus conceptos está estrictamente prohibido
y será perseguido en la máxima medida permitida por la ley.
*/

/* Estilos CSS existentes... */ 
```

### src\frontend\templates\index.html
```html | 14414 bytes | Modificado: 2025-03-07 02:41:45.240911
```
<!--
vigIA - Sistema de Vigilancia Inteligente con IA
Versión PMV (Proyecto MOTION_DETECTOR)

© 2025 Gustavo Mayorga. Todos los derechos reservados.

Este código es propiedad exclusiva de Gustavo Mayorga y está protegido por leyes de 
propiedad intelectual. Ninguna parte de este software puede ser reproducida, distribuida, 
o utilizada para crear trabajos derivados sin autorización explícita por escrito.

Contacto legal: gustavo.mayorga.gm@gmail.com

AVISO: El uso no autorizado de este código o sus conceptos está estrictamente prohibido
y será perseguido en la máxima medida permitida por la ley.
-->

<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>vigIA - Panel de Control</title>
    <link rel="stylesheet" href="/static/css/styles.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css">
    <link rel="shortcut icon" href="/static/img/logo-vigia.png" type="image/png">
</head>
<body class="bg-light">
    <header class="header-main bg-dark text-white">
        <nav class="navbar navbar-expand-lg navbar-dark">
            <div class="container-fluid">
                <a class="navbar-brand" href="#">
                    <img src="/static/img/logo-vigia.png" alt="vigIA Logo" height="40" class="me-2">
                    <span class="brand-text">vig<span class="brand-highlight">IA</span></span>
                </a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarMain">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarMain">
                    <ul class="navbar-nav me-auto mb-2 mb-lg-0">
                        <li class="nav-item">
                            <a class="nav-link tab-link active" data-tab="live" href="#">
                                <i class="fas fa-video me-1"></i> Cámaras en Vivo
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link tab-link" data-tab="alerts" href="#">
                                <i class="fas fa-exclamation-triangle me-1"></i> Alertas
                                <span class="badge bg-danger alert-counter">0</span>
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link tab-link" data-tab="recordings" href="#">
                                <i class="fas fa-film me-1"></i> Grabaciones
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link tab-link" data-tab="analytics" href="#">
                                <i class="fas fa-chart-line me-1"></i> Analítica
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link tab-link" data-tab="faces" href="#">
                                <i class="fas fa-user-circle me-1"></i> Reconocimiento Facial
                            </a>
                        </li>
                    </ul>
                    <div class="d-flex">
                        <div class="dropdown">
                            <a class="btn btn-outline-light dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown">
                                <i class="fas fa-user-circle me-1"></i>
                                <span id="user-name">Operador</span>
                            </a>
                            <ul class="dropdown-menu dropdown-menu-end">
                                <li><a class="dropdown-item" href="#"><i class="fas fa-cog me-2"></i>Configuración</a></li>
                                <li><a class="dropdown-item" href="#"><i class="fas fa-bell me-2"></i>Notificaciones</a></li>
                                <li><hr class="dropdown-divider"></li>
                                <li><a class="dropdown-item" href="#"><i class="fas fa-sign-out-alt me-2"></i>Cerrar Sesión</a></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </nav>
    </header>

    <main class="container-fluid py-4">
        <!-- Panel de Cámaras en Vivo -->
        <div id="tab-live" class="tab-content active">
            <div class="row">
                <div class="col-md-9">
                    <div class="card mb-4">
                        <div class="card-header d-flex justify-content-between align-items-center">
                            <h5 class="mb-0">Cámaras en Vivo</h5>
                            <div class="btn-group">
                                <button class="btn btn-sm btn-outline-secondary" id="view-grid">
                                    <i class="fas fa-th-large"></i>
                                </button>
                                <button class="btn btn-sm btn-outline-secondary" id="view-single">
                                    <i class="fas fa-square"></i>
                                </button>
                            </div>
                        </div>
                        <div class="card-body p-0">
                            <div id="camera-container" class="camera-grid">
                                <!-- Las cámaras se cargarán dinámicamente aquí -->
                                <div class="camera-loading text-center p-5">
                                    <div class="spinner-border text-primary" role="status"></div>
                                    <p class="mt-2">Cargando cámaras...</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="card mb-4">
                        <div class="card-header">
                            <h5 class="mb-0">Alertas Recientes</h5>
                        </div>
                        <div class="card-body p-0">
                            <ul class="list-group list-group-flush" id="recent-alerts">
                                <!-- Las alertas se cargarán dinámicamente aquí -->
                                <li class="list-group-item text-center text-muted">
                                    No hay alertas recientes
                                </li>
                            </ul>
                        </div>
                    </div>
                    <div class="card">
                        <div class="card-header">
                            <h5 class="mb-0">Estado del Sistema</h5>
                        </div>
                        <div class="card-body">
                            <div class="mb-3">
                                <div class="d-flex justify-content-between mb-1">
                                    <span>CPU</span>
                                    <span id="cpu-usage">0%</span>
                                </div>
                                <div class="progress">
                                    <div id="cpu-bar" class="progress-bar" role="progressbar" style="width: 0%"></div>
                                </div>
                            </div>
                            <div class="mb-3">
                                <div class="d-flex justify-content-between mb-1">
                                    <span>Memoria</span>
                                    <span id="memory-usage">0%</span>
                                </div>
                                <div class="progress">
                                    <div id="memory-bar" class="progress-bar" role="progressbar" style="width: 0%"></div>
                                </div>
                            </div>
                            <div>
                                <div class="d-flex justify-content-between mb-1">
                                    <span>Almacenamiento</span>
                                    <span id="storage-usage">0%</span>
                                </div>
                                <div class="progress">
                                    <div id="storage-bar" class="progress-bar" role="progressbar" style="width: 0%"></div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Panel de Alertas -->
        <div id="tab-alerts" class="tab-content">
            <div class="card">
                <div class="card-header">
                    <div class="row align-items-center">
                        <div class="col">
                            <h5 class="mb-0">Gestión de Alertas</h5>
                        </div>
                        <div class="col-auto">
                            <div class="btn-group">
                                <button class="btn btn-outline-secondary active" data-filter="all">Todas</button>
                                <button class="btn btn-outline-danger" data-filter="high">Alta Prioridad</button>
                                <button class="btn btn-outline-warning" data-filter="medium">Media</button>
                                <button class="btn btn-outline-info" data-filter="low">Baja</button>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card-body p-0">
                    <div class="table-responsive">
                        <table class="table table-hover" id="alerts-table">
                            <thead class="table-light">
                                <tr>
                                    <th>ID</th>
                                    <th>Tipo</th>
                                    <th>Cámara</th>
                                    <th>Timestamp</th>
                                    <th>Prioridad</th>
                                    <th>Estado</th>
                                    <th>Acciones</th>
                                </tr>
                            </thead>
                            <tbody>
                                <!-- Las alertas se cargarán dinámicamente aquí -->
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- Contenido para otras pestañas se añadirá según sea necesario -->
    </main>

    <!-- Modal para mostrar detalles de alertas -->
    <div class="modal fade" id="alert-detail-modal" tabindex="-1" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Detalles de Alerta</h5>
                    <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <div class="row">
                        <div class="col-md-6">
                            <div class="alert-image mb-3">
                                <img src="" alt="Imagen de alerta" class="img-fluid rounded" id="alert-image">
                            </div>
                        </div>
                        <div class="col-md-6">
                            <h5 id="alert-title">Título de la alerta</h5>
                            <p id="alert-description" class="text-muted"></p>
                            <div class="alert-meta">
                                <p><strong>ID:</strong> <span id="alert-id"></span></p>
                                <p><strong>Cámara:</strong> <span id="alert-camera"></span></p>
                                <p><strong>Fecha y hora:</strong> <span id="alert-time"></span></p>
                                <p><strong>Tipo:</strong> <span id="alert-type"></span></p>
                                <p><strong>Estado:</strong> <span id="alert-status" class="badge"></span></p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cerrar</button>
                    <button type="button" class="btn btn-success" id="btn-acknowledge">Reconocer Alerta</button>
                    <button type="button" class="btn btn-primary" id="btn-view-recording">Ver Grabación</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Contenedor para modales de videos -->
    <div id="video-modal-container"></div>

    <!-- Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="/static/js/api-client.js"></script>
    <script src="/static/js/camera-panel.js"></script>
    <script src="/static/js/alerts-dashboard.js"></script>
    <script src="/static/js/stats-panel.js"></script>
    <script src="/static/dashboard/unified_control.js"></script>
    <script>
        // Inicializar el panel de control cuando el documento esté listo
        document.addEventListener('DOMContentLoaded', function() {
            const config = {
                apiBaseUrl: '/api',
                alertsContainerId: 'recent-alerts',
                cameraContainerId: 'camera-container',
                statsContainerId: 'stats-container',
            };
            
            const controlPanel = new UnifiedControlPanel(config);
        });
    </script>
</body>
</html> 
```

### src\ml\model_evaluation.py
```py | 1003 bytes | Modificado: 2025-02-16 12:55:03.860233
```
﻿    # src/ml/model_evaluation.py
    from ultralytics import YOLO
    import numpy as np
    import matplotlib.pyplot as plt
    
    class ModelEvaluator:
        def __init__(self, model_path):
            self.model = YOLO(model_path)
        
        def evaluate_precision_recall(self, test_data):
            # Realizar evaluaciÃ³n de precisiÃ³n y recall
            metrics = self.model.val(data=test_data)
            
            # Graficar curva P-R
            precision = metrics.results_dict['metrics/precision(B)']
            recall = metrics.results_dict['metrics/recall(B)']
            
            plt.figure(figsize=(10, 6))
            plt.plot(recall, precision, 'b', label='Precision-Recall curve')
            plt.title('Precision-Recall Curve')
            plt.xlabel('Recall')
            plt.ylabel('Precision')
            plt.legend()
            plt.savefig('data/output/precision_recall_curve.png')
            
            return metrics

```

### src\ml\model_trainer.py
```py | 3 bytes | Modificado: 2025-02-16 12:55:03.859233
```
﻿
```

### src\notifications\email_notifier.py
```py | 3470 bytes | Modificado: 2025-03-07 00:44:44.203896
```
import smtplib
import logging
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime

class EmailNotifier:
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger('EmailNotifier')
        
    def send(self, alert_data, recipients):
        """Envía una notificación por correo electrónico"""
        if not recipients:
            self.logger.warning("No recipients specified for email notification")
            return False
            
        try:
            # Crear mensaje
            msg = MIMEMultipart()
            msg['From'] = self.config['from_addr']
            msg['To'] = ', '.join(recipients)
            
            # Definir asunto según tipo de alerta
            alert_type = alert_data.get('type', 'general')
            priority = alert_data.get('priority', 'medium')
            
            # Prefijo según prioridad
            prefix = {
                'high': '[URGENTE] ',
                'medium': '[ALERTA] ',
                'low': '[INFO] '
            }.get(priority, '')
            
            msg['Subject'] = f"{prefix}Alerta de seguridad: {alert_type.capitalize()}"
            
            # Crear cuerpo del mensaje
            body = f"""
            <html>
            <head>
                <style>
                    body {{ font-family: Arial, sans-serif; }}
                    .alert {{ padding: 10px; border-radius: 5px; margin-bottom: 10px; }}
                    .high {{ background-color: #ffdddd; color: #990000; }}
                    .medium {{ background-color: #ffffcc; color: #996600; }}
                    .low {{ background-color: #e6f3ff; color: #004d99; }}
                    .timestamp {{ font-size: 0.8em; color: #666; }}
                    .location {{ font-weight: bold; }}
                </style>
            </head>
            <body>
                <div class="alert {priority}">
                    <h2>{alert_type.capitalize()}</h2>
                    <p>{alert_data.get('message', 'Sin detalles')}</p>
                    <p class="location">Ubicación: {alert_data.get('location', 'Desconocida')}</p>
                    <p class="timestamp">Fecha y hora: {datetime.fromtimestamp(alert_data.get('timestamp', datetime.now().timestamp())).strftime('%d/%m/%Y %H:%M:%S')}</p>
                    
                    {f'<p><a href="{alert_data.get("video_url")}">Ver video</a></p>' if 'video_url' in alert_data else ''}
                    {f'<p><a href="{alert_data.get("image_url")}">Ver imagen</a></p>' if 'image_url' in alert_data else ''}
                </div>
            </body>
            </html>
            """
            
            msg.attach(MIMEText(body, 'html'))
            
            # Conectar al servidor SMTP
            server = smtplib.SMTP(self.config['smtp_server'], self.config['smtp_port'])
            server.starttls()
            server.login(self.config['username'], self.config['password'])
            
            # Enviar correo
            server.send_message(msg)
            server.quit()
            
            self.logger.info(f"Email notification sent to {len(recipients)} recipients")
            return True
            
        except Exception as e:
            self.logger.error(f"Error sending email notification: {e}")
            return False 
```

### src\notifications\notification_manager.py
```py | 8911 bytes | Modificado: 2025-03-07 00:44:44.203896
```
import json
import logging
import smtplib
import requests
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
import time
from threading import Thread, Lock
from queue import Queue, PriorityQueue

class NotificationManager:
    def __init__(self, config_path="configs/notifications.json"):
        self.config = self._load_config(config_path)
        self.channels = self._init_channels()
        self.logger = logging.getLogger('NotificationManager')
        self.notification_queue = PriorityQueue()
        self.queue_lock = Lock()
        self.processing_thread = Thread(target=self._process_notification_queue, daemon=True)
        self.processing_thread.start()
        self.rate_limiters = {}  # Para limitar frecuencia de notificaciones
        
    def _load_config(self, config_path):
        """Cargar configuración de notificaciones desde archivo JSON"""
        if not os.path.exists(config_path):
            self.logger.warning(f"Config file {config_path} not found, using defaults")
            return {
                "email": {
                    "enabled": False,
                    "smtp_server": "smtp.gmail.com",
                    "smtp_port": 587,
                    "username": "",
                    "password": "",
                    "from_addr": ""
                },
                "sms": {
                    "enabled": False,
                    "provider": "twilio",
                    "account_sid": "",
                    "auth_token": "",
                    "from_number": ""
                },
                "push": {
                    "enabled": False,
                    "provider": "firebase",
                    "api_key": ""
                },
                "webhook": {
                    "enabled": True,
                    "url": "http://localhost:8000/api/notifications",
                    "method": "POST",
                    "headers": {"Content-Type": "application/json"}
                },
                "recipients": {
                    "high_priority": {
                        "email": ["security@example.com"],
                        "sms": ["+1234567890"],
                        "push": ["device_token_1"]
                    },
                    "medium_priority": {
                        "email": ["manager@example.com"],
                        "push": ["device_token_2"]
                    },
                    "low_priority": {
                        "email": ["logs@example.com"]
                    }
                },
                "priority_channels": {
                    "high": ["sms", "push", "webhook", "email"],
                    "medium": ["push", "webhook", "email"],
                    "low": ["webhook", "email"]
                },
                "rate_limits": {
                    "high": 60,    # Segundos entre notificaciones
                    "medium": 300,
                    "low": 1800
                }
            }
            
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"Error loading notification config: {e}")
            return {}
            
    def _init_channels(self):
        """Inicializar canales de notificación configurados"""
        channels = {}
        
        if self.config.get('email', {}).get('enabled', False):
            channels['email'] = EmailNotifier(self.config['email'])
            
        if self.config.get('sms', {}).get('enabled', False):
            channels['sms'] = SMSNotifier(self.config['sms'])
            
        if self.config.get('push', {}).get('enabled', False):
            channels['push'] = PushNotifier(self.config['push'])
            
        if self.config.get('webhook', {}).get('enabled', False):
            channels['webhook'] = WebhookNotifier(self.config['webhook'])
            
        return channels
        
    def _get_recipients_for_priority(self, priority):
        """Obtener destinatarios según prioridad"""
        priority_map = {
            "high": "high_priority",
            "medium": "medium_priority",
            "low": "low_priority"
        }
        
        priority_key = priority_map.get(priority, "low_priority")
        return self.config.get("recipients", {}).get(priority_key, {})
        
    def _get_channels_for_priority(self, priority):
        """Obtener canales de notificación según prioridad"""
        return self.config.get("priority_channels", {}).get(priority, ["email"])
        
    def _can_send_notification(self, alert_key, priority):
        """Verificar si podemos enviar una notificación según límites de frecuencia"""
        if alert_key not in self.rate_limiters:
            self.rate_limiters[alert_key] = 0
            return True
            
        last_sent = self.rate_limiters[alert_key]
        rate_limit = self.config.get("rate_limits", {}).get(priority, 300)  # Default 5 minutos
        
        current_time = time.time()
        if current_time - last_sent >= rate_limit:
            return True
            
        return False
        
    def send_alert(self, alert_data, channel_types=None, priority="medium"):
        """Enviar alerta por los canales especificados según prioridad"""
        # Verificar datos mínimos
        if not isinstance(alert_data, dict) or 'message' not in alert_data:
            self.logger.error("Invalid alert data format")
            return False
            
        # Obtener canales basados en prioridad si no se especifican
        if channel_types is None:
            channel_types = self._get_channels_for_priority(priority)
            
        # Obtener destinatarios para esta prioridad
        recipients = self._get_recipients_for_priority(priority)
        
        # Agregar información de prioridad y timestamp
        if 'timestamp' not in alert_data:
            alert_data['timestamp'] = time.time()
        alert_data['priority'] = priority
        
        # Generar clave única para control de frecuencia
        alert_key = f"{alert_data.get('type', 'generic')}_{alert_data.get('location', 'unknown')}"
        
        # Verificar límites de frecuencia
        if not self._can_send_notification(alert_key, priority):
            self.logger.info(f"Rate limited notification: {alert_key}")
            return False
            
        # Actualizar timestamp de última notificación
        self.rate_limiters[alert_key] = time.time()
        
        # Agregar a la cola de notificaciones con prioridad
        priority_value = {"high": 0, "medium": 1, "low": 2}.get(priority, 1)
        
        with self.queue_lock:
            self.notification_queue.put((
                priority_value, 
                {
                    "data": alert_data,
                    "channels": channel_types,
                    "recipients": recipients
                }
            ))
            
        return True
        
    def _process_notification_queue(self):
        """Procesar cola de notificaciones en segundo plano"""
        while True:
            try:
                # Obtener notificación de mayor prioridad
                priority, notification = self.notification_queue.get()
                
                alert_data = notification["data"]
                channels = notification["channels"]
                recipients = notification["recipients"]
                
                # Procesar cada canal configurado
                for channel_type in channels:
                    if channel_type not in self.channels:
                        self.logger.warning(f"Channel {channel_type} not available")
                        continue
                        
                    channel = self.channels[channel_type]
                    channel_recipients = recipients.get(channel_type, [])
                    
                    if not channel_recipients and channel_type != 'webhook':
                        self.logger.warning(f"No recipients configured for {channel_type}")
                        continue
                        
                    try:
                        # Enviar notificación
                        channel.send(alert_data, channel_recipients)
                    except Exception as e:
                        self.logger.error(f"Error sending {channel_type} notification: {e}")
                        
                self.notification_queue.task_done()
                
            except Exception as e:
                self.logger.error(f"Error in notification queue processing: {e}")
                time.sleep(1)  # Evitar bucle 
```

### src\notifications\push_notifier.py
```py | 4001 bytes | Modificado: 2025-03-07 00:44:44.203896
```
import logging
import requests
import json

class PushNotifier:
    def __init__(self, config):
        self.config = config
        self.provider = config.get('provider', 'firebase')
        self.logger = logging.getLogger('PushNotifier')
        
    def send(self, alert_data, recipients):
        """Envía una notificación push"""
        if not recipients:
            self.logger.warning("No recipients specified for push notification")
            return False
            
        if self.provider == 'firebase':
            return self._send_firebase(alert_data, recipients)
        else:
            self.logger.error(f"Unsupported push provider: {self.provider}")
            return False
            
    def _send_firebase(self, alert_data, recipients):
        """Envía notificación push usando Firebase Cloud Messaging"""
        try:
            api_key = self.config.get('api_key')
            
            if not api_key:
                self.logger.error("Missing Firebase API key")
                return False
                
            # Formatear mensaje
            alert_type = alert_data.get('type', 'general')
            priority = alert_data.get('priority', 'medium')
            
            # Título según prioridad
            prefix = {
                'high': '🚨 URGENTE: ',
                'medium': '⚠️ ALERTA: ',
                'low': 'INFO: '
            }.get(priority, '')
            
            notification = {
                'title': f"{prefix}{alert_type.capitalize()}",
                'body': alert_data.get('message', 'Sin detalles'),
                'icon': 'notification_icon',
                'sound': 'default',
                'click_action': 'OPEN_ALERT_ACTIVITY'
            }
            
            # Datos adicionales para la app
            data = {
                'type': alert_type,
                'priority': priority,
                'location': alert_data.get('location', 'unknown'),
                'timestamp': str(alert_data.get('timestamp', 0)),
            }
            
            # Agregar URLs si existen
            if 'image_url' in alert_data:
                data['image_url'] = alert_data['image_url']
            if 'video_url' in alert_data:
                data['video_url'] = alert_data['video_url']
                
            # URL de Firebase
            url = 'https://fcm.googleapis.com/fcm/send'
            
            headers = {
                'Authorization': f'key={api_key}',
                'Content-Type': 'application/json'
            }
            
            # Enviar a cada token de dispositivo
            success_count = 0
            for token in recipients:
                payload = {
                    'notification': notification,
                    'data': data,
                    'to': token
                }
                
                try:
                    response = requests.post(url, headers=headers, data=json.dumps(payload))
                    
                    if response.status_code == 200:
                        result = response.json()
                        if result.get('success') == 1:
                            success_count += 1
                        else:
                            self.logger.warning(f"Firebase error for token {token}: {result}")
                    else:
                        self.logger.error(f"Firebase API error: {response.status_code} - {response.text}")
                        
                except Exception as e:
                    self.logger.error(f"Error sending push to {token}: {e}")
            
            self.logger.info(f"Push notification sent to {success_count}/{len(recipients)} devices")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"Error in Firebase push notification: {e}")
            return False 
```

### src\notifications\sms_notifier.py
```py | 3152 bytes | Modificado: 2025-03-07 00:44:44.203896
```
import logging
import requests
from datetime import datetime

class SMSNotifier:
    def __init__(self, config):
        self.config = config
        self.provider = config.get('provider', 'twilio')
        self.logger = logging.getLogger('SMSNotifier')
        
    def send(self, alert_data, recipients):
        """Envía una notificación por SMS"""
        if not recipients:
            self.logger.warning("No recipients specified for SMS notification")
            return False
            
        if self.provider == 'twilio':
            return self._send_twilio(alert_data, recipients)
        else:
            self.logger.error(f"Unsupported SMS provider: {self.provider}")
            return False
            
    def _send_twilio(self, alert_data, recipients):
        """Envía SMS usando Twilio API"""
        try:
            from twilio.rest import Client
            
            account_sid = self.config.get('account_sid')
            auth_token = self.config.get('auth_token')
            from_number = self.config.get('from_number')
            
            if not all([account_sid, auth_token, from_number]):
                self.logger.error("Missing Twilio configuration")
                return False
                
            client = Client(account_sid, auth_token)
            
            # Formatear mensaje
            alert_type = alert_data.get('type', 'general')
            priority = alert_data.get('priority', 'medium')
            location = alert_data.get('location', 'Desconocida')
            
            # Prefijo según prioridad
            prefix = {
                'high': '🚨 URGENTE: ',
                'medium': '⚠️ ALERTA: ',
                'low': 'INFO: '
            }.get(priority, '')
            
            message_body = f"{prefix}{alert_type.upper()}\n{alert_data.get('message', 'Sin detalles')}\nUbicación: {location}"
            
            # Agregar timestamp
            timestamp = datetime.fromtimestamp(alert_data.get('timestamp', datetime.now().timestamp()))
            message_body += f"\nFecha/Hora: {timestamp.strftime('%d/%m/%Y %H:%M')}"
            
            # Enviar a cada destinatario
            success_count = 0
            for recipient in recipients:
                try:
                    message = client.messages.create(
                        body=message_body,
                        from_=from_number,
                        to=recipient
                    )
                    success_count += 1
                except Exception as e:
                    self.logger.error(f"Error sending SMS to {recipient}: {e}")
            
            self.logger.info(f"SMS notification sent to {success_count}/{len(recipients)} recipients")
            return success_count > 0
            
        except ImportError:
            self.logger.error("Twilio package not installed. Install with: pip install twilio")
            return False
        except Exception as e:
            self.logger.error(f"Error in Twilio SMS notification: {e}")
            return False 
```

### src\notifications\webhook_notifier.py
```py | 1746 bytes | Modificado: 2025-03-07 00:44:44.205127
```
import logging
import requests
import json

class WebhookNotifier:
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger('WebhookNotifier')
        
    def send(self, alert_data, recipients=None):
        """Envía una notificación a través de webhook"""
        try:
            url = self.config.get('url')
            method = self.config.get('method', 'POST').upper()
            headers = self.config.get('headers', {"Content-Type": "application/json"})
            
            if not url:
                self.logger.error("Missing webhook URL")
                return False
                
            # Preparar datos a enviar (incluir toda la información de la alerta)
            payload = alert_data.copy()
            
            # Realizar la solicitud HTTP
            if method == 'POST':
                response = requests.post(url, json=payload, headers=headers)
            elif method == 'PUT':
                response = requests.put(url, json=payload, headers=headers)
            else:
                self.logger.error(f"Unsupported webhook method: {method}")
                return False
                
            # Verificar respuesta
            if response.status_code >= 200 and response.status_code < 300:
                self.logger.info(f"Webhook notification sent successfully: {response.status_code}")
                return True
            else:
                self.logger.error(f"Webhook error: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            self.logger.error(f"Error in webhook notification: {e}")
            return False 
```

### src\processing\video_processor.py
```py | 13686 bytes | Modificado: 2025-03-14 17:27:25.324051
```
import os
import cv2
import time
import asyncio
import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Callable
from datetime import datetime
from pathlib import Path

from ultralytics import YOLO
from ultralytics.utils.ops import non_max_suppression
# from bytetrack.byte_tracker import BYTETracker
import torch

from src.events.event_bus import EventBus, EventTypes
from src.database.models import Camera, Zone, Alert, DetectedObject
from src.database.db import get_db
from src.config.config_loader import load_config

class VideoProcessor:
    """
    Procesador de video para detección, tracking y análisis de comportamiento
    Integra la detección de objetos (YOLO), tracking (ByteTrack) y análisis de zonas
    """
    
    def __init__(self, camera_id: int, config_path: str = "configs/config.yaml", event_bus: Optional[EventBus] = None):
        """Inicializa el procesador para una cámara específica"""
        self.camera_id = camera_id
        self.logger = logging.getLogger(f"VideoProcessor-Cam{camera_id}")
        
        # Cargar configuración
        self.config = load_config(config_path)
        
        # Estado de procesamiento
        self.is_running = False
        self.current_frame = None
        self.frame_count = 0
        self.fps = 0
        self.start_time = 0
        self.detection_objects = []
        self.tracked_objects = {}  # ID: {track_info}
        self.zones = []
        self.zone_counts = {}
        
        # Bus de eventos
        self.event_bus = event_bus
        
        # Detector, Tracker y otros componentes se inicializarán bajo demanda
        self.detector = None
        self.tracker = None
        self.capture = None
        self.camera_info = None
        self.recording = None
        
    async def initialize(self):
        """Inicializa los componentes necesarios para el procesamiento"""
        try:
            # Cargar información de la cámara desde la base de datos
            with get_db() as db:
                self.camera_info = db.query(Camera).filter(Camera.id == self.camera_id).first()
                if not self.camera_info:
                    self.logger.error(f"No se encontró la cámara con ID {self.camera_id}")
                    return False
                
                # Cargar zonas asociadas a la cámara
                self.zones = db.query(Zone).filter(Zone.camera_id == self.camera_id, Zone.is_active == True).all()
                self.logger.info(f"Cargadas {len(self.zones)} zonas para la cámara {self.camera_id}")
            
            # Inicializar detector
            det_config = self.config["detection"]
            model_path = os.path.join(self.config["storage"]["models_dir"], det_config["default_model"])
            
            # Verificar si existe un modelo específico para esta cámara
            cam_model = self.camera_info.config.get("model")
            if cam_model and os.path.exists(os.path.join(self.config["storage"]["models_dir"], cam_model)):
                model_path = os.path.join(self.config["storage"]["models_dir"], cam_model)
            
            # Cargar modelo
            self.logger.info(f"Cargando modelo de detección: {model_path}")
            self.detector = YOLO(model_path)
            
            # Configurar tracker
            # self.tracker = BYTETracker(
            #     track_thresh=det_config["confidence_threshold"],
            #     match_thresh=track_config["iou_threshold"],
            #     track_buffer=track_config["max_age"],
            #     frame_rate=self.camera_info.fps or 15
            # )
            
            # Inicializar evento de detección de movimiento
            self.motion_detector = None
            if self.config["agents"]["motion_detection"]["enabled"]:
                self.motion_detector = cv2.createBackgroundSubtractorMOG2(
                    history=self.config["agents"]["motion_detection"]["history"],
                    varThreshold=100 * self.config["agents"]["motion_detection"]["sensitivity"]
                )
            
            # Conexión al evento bus si no está ya conectado
            if self.event_bus is None:
                self.event_bus = EventBus(
                    redis_host=self.config["redis"]["host"],
                    redis_port=self.config["redis"]["port"],
                    redis_db=self.config["redis"]["db"],
                    redis_password=self.config["redis"]["password"],
                )
                await self.event_bus.connect()
            
            # Inicializar conteo por zonas
            for zone in self.zones:
                self.zone_counts[zone.id] = {}
            
            self.logger.info(f"Procesador de video inicializado para cámara {self.camera_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error inicializando el procesador de video: {e}")
            return False
    
    async def start(self):
        """Inicia el procesamiento de video"""
        if self.is_running:
            self.logger.warning("El procesador ya está en ejecución")
            return False
        
        if not self.detector or not self.camera_info:
            if not await self.initialize():
                self.logger.error("No se pudo inicializar el procesador")
                return False
        
        try:
            # Abrir captura de video
            self.capture = cv2.VideoCapture(self.camera_info.url)
            if not self.capture.isOpened():
                self.logger.error(f"No se pudo abrir la cámara: {self.camera_info.url}")
                return False
            
            # Iniciar procesamiento
            self.is_running = True
            self.frame_count = 0
            self.start_time = time.time()
            
            # Publicar evento de inicio
            await self.event_bus.publish(f"camera_{self.camera_id}_processing_started", {
                "camera_id": self.camera_id,
                "timestamp": datetime.now().isoformat(),
                "message": f"Iniciado procesamiento para cámara {self.camera_info.name}"
            })
            
            self.logger.info(f"Iniciado procesamiento para cámara {self.camera_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error iniciando el procesamiento: {e}")
            self.is_running = False
            return False
    
    async def _process_frame(self):
        """Procesa un solo frame del video"""
        try:
            ret, frame = self.capture.read()
            if not ret:
                self.logger.error("No se pudo leer el frame")
                return
            
            self.current_frame = frame
            self.frame_count += 1
            
            # Procesar detección
            results = self.detector.predict(frame, conf=self.config["detection"]["confidence_threshold"])
            self.detection_objects = results[0].boxes.xyxy.tolist()
            
            # Procesar tracking
            # tracked_objects = self.tracker.update(self.detection_objects)
            # self.tracked_objects = {track_id: track_info for track_id, track_info in tracked_objects}
            
            # Procesar análisis de zonas
            zone_events = await self._analyze_zones()
            
            # Procesar comportamiento
            loitering_events = await self._process_loitering()
            
            # Actualizar conteo por zonas
            for zone in self.zones:
                self.zone_counts[zone.id] = {}
            
            self.logger.debug(f"Terminado análisis de zonas para frame {self.frame_count}")
            return zone_events, loitering_events
        except Exception as e:
            self.logger.error(f"Error procesando frame: {e}")
            return [], []
    
    async def _analyze_zones(self):
        """Analiza comportamiento de objetos en zonas"""
        try:
            zone_events = []
            for zone in self.zones:
                zone_events.append({
                    "zone_id": zone.id,
                    "zone_name": zone.name,
                    "timestamp": datetime.now().isoformat()
                })
            
            self.logger.debug(f"Terminado análisis de zonas para frame {self.frame_count}")
            return zone_events
        except Exception as e:
            self.logger.error(f"Error analizando zonas: {e}")
            return []
    
    async def _process_loitering(self, timeout: int = None):
        """Analiza comportamiento de merodeo (objetos que permanecen demasiado tiempo)"""
        if not timeout:
            timeout = self.config["behavior"]["loitering_time_threshold"]
        
        loitering_events = []
        current_time = time.time()
        
        for track_id, track_info in self.tracked_objects.items():
            # Solo analizar personas
            if track_info["class_name"] != "person":
                continue
            
            # Verificar tiempo de permanencia
            if "first_seen" in track_info and (current_time - track_info["first_seen"]) > timeout:
                # Verificar si ya se generó alerta de merodeo para este objeto
                if not track_info.get("loitering_alert_sent", False):
                    loitering_event = {
                        "track_id": track_id,
                        "class_id": track_info["class_id"],
                        "class_name": track_info["class_name"],
                        "position": track_info["position"],
                        "duration": current_time - track_info["first_seen"],
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    # Marcar como alerta enviada
                    self.tracked_objects[track_id]["loitering_alert_sent"] = True
                    
                    loitering_events.append(loitering_event)
                    
                    self.logger.info(f"Detectado merodeo: ID {track_id}, duración {current_time - track_info['first_seen']:.1f}s")
        
        return loitering_events
    
    def draw_results(self, frame=None):
        """Dibuja resultados de detección, tracking y zonas en el frame"""
        if frame is None:
            frame = self.current_frame.copy()
        if frame is None:
            return None
        
        # Dibujar objetos detectados y trayectorias
        for track_id, track_info in self.tracked_objects.items():
            # Dibujar bounding box
            x1, y1, x2, y2 = track_info["bbox"]
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), track_info["color"], 2)
            
            # Dibujar etiqueta
            label = f"{track_info['class_name']} {track_info['confidence']:.2f}"
            cv2.putText(frame, label, (int(x1), int(y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, track_info["color"], 2)
            
            # Dibujar ID
            cv2.putText(frame, str(track_id), (int(x1), int(y1-25)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Dibujar trayectoria
            if "trajectory" in track_info and len(track_info["trajectory"]) > 1:
                for i in range(1, len(track_info["trajectory"])):
                    pt1 = track_info["trajectory"][i-1]
                    pt2 = track_info["trajectory"][i]
                    cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), track_info["color"], 2)
        
        # Dibujar zonas
        for zone in self.zones:
            points = zone.points
            if not points or len(points) < 3:
                continue
            
            # Convertir puntos a formato numpy para dibujo
            pts = np.array(points, np.int32)
            pts = pts.reshape((-1, 1, 2))
            
            # Determinar color según el tipo de zona
            color = (0, 0, 255)  # Rojo por defecto
            if zone.color:
                # Convertir el color de string a tupla BGR
                if zone.color == "red":
                    color = (0, 0, 255)
                elif zone.color == "green":
                    color = (0, 255, 0)
                elif zone.color == "blue":
                    color = (255, 0, 0)
                elif zone.color == "yellow":
                    color = (0, 255, 255)
            
            # Dibujar polígono
            cv2.polylines(frame, [pts], True, color, 2)
            
            # Dibujar nombre de la zona
            if len(points) > 0:
                cv2.putText(frame, zone.name, (points[0][0], points[0][1]-10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # Dibujar conteo si existe
            if zone.id in self.zone_counts and self.zone_counts[zone.id]:
                count_text = " ".join([f"{k}:{v}" for k, v in self.zone_counts[zone.id].items()])
                if len(points) > 1:
                    cv2.putText(frame, count_text, (points[1][0], points[1][1]-10), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Mostrar FPS
        cv2.putText(frame, f"FPS: {self.fps:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        return frame 
```

### src\response\active_response.py
```py | 6327 bytes | Modificado: 2025-03-07 01:46:39.246508
```
import os
import logging
import subprocess
import threading
import queue
from gtts import gTTS
from playsound import playsound

class ActiveResponseManager:
    """Gestiona respuestas activas a eventos detectados"""
    
    def __init__(self, config=None):
        """
        Inicializa el gestor de respuestas activas
        
        Args:
            config: Configuración para respuestas automáticas
        """
        self.logger = logging.getLogger('ActiveResponseManager')
        self.config = config or {}
        self.message_queue = queue.Queue()
        self.enabled = self.config.get('enabled', True)
        self.response_thread = None
        self.running = False
        
        # Audio cacheado para mensajes comunes
        self.audio_cache = {}
        
        # Iniciar procesamiento en segundo plano
        self.start()
        
    def start(self):
        """Iniciar procesamiento en segundo plano"""
        if not self.running:
            self.running = True
            self.response_thread = threading.Thread(target=self._process_responses)
            self.response_thread.daemon = True
            self.response_thread.start()
            self.logger.info("Gestor de respuestas activas iniciado")
            
    def stop(self):
        """Detener procesamiento"""
        self.running = False
        if self.response_thread:
            self.response_thread.join(timeout=2.0)
            self.response_thread = None
        self.logger.info("Gestor de respuestas activas detenido")
        
    def _process_responses(self):
        """Procesar respuestas en segundo plano"""
        while self.running:
            try:
                # Obtener siguiente mensaje de la cola
                response_data = self.message_queue.get(timeout=1.0)
                
                # Procesar según tipo
                response_type = response_data.get('type')
                if response_type == 'audio':
                    self._process_audio_message(response_data)
                elif response_type == 'light':
                    self._process_light_signal(response_data)
                elif response_type == 'command':
                    self._process_external_command(response_data)
                
                self.message_queue.task_done()
                
            except queue.Empty:
                pass
            except Exception as e:
                self.logger.error(f"Error al procesar respuesta: {e}")
                
    def _process_audio_message(self, data):
        """Reproducir mensaje de audio"""
        message = data.get('message', '')
        language = data.get('language', 'es')
        device = data.get('device', 'default')
        
        try:
            # Verificar si está en caché
            cache_key = f"{message}-{language}"
            audio_file = self.audio_cache.get(cache_key)
            
            if not audio_file or not os.path.exists(audio_file):
                # Crear archivo de audio
                tts = gTTS(text=message, lang=language, slow=False)
                
                # Guardar en directorio temporal
                os.makedirs('temp/audio', exist_ok=True)
                audio_file = f"temp/audio/message_{hash(cache_key)}.mp3"
                tts.save(audio_file)
                
                # Guardar en caché
                self.audio_cache[cache_key] = audio_file
                
            # Reproducir audio
            if device == 'default':
                playsound(audio_file)
            else:
                # Usar dispositivo específico (implementación depende del sistema)
                self._play_on_device(audio_file, device)
                
            self.logger.info(f"Mensaje de audio reproducido: '{message}'")
            
        except Exception as e:
            self.logger.error(f"Error al reproducir mensaje de audio: {e}")
            
    def _play_on_device(self, audio_file, device):
        """Reproducir en dispositivo específico"""
        # Implementación depende del sistema operativo y hardware
        pass
            
    def _process_light_signal(self, data):
        """Activar señal luminosa"""
        # Implementación depende del hardware disponible
        pass
        
    def _process_external_command(self, data):
        """Ejecutar comando externo"""
        command = data.get('command', '')
        
        try:
            if command:
                subprocess.run(command, shell=True, check=True)
                self.logger.info(f"Comando ejecutado: '{command}'")
        except Exception as e:
            self.logger.error(f"Error al ejecutar comando: {e}")
            
    def queue_audio_warning(self, message, event_data=None, language='es', device='default'):
        """
        Encolar advertencia de audio
        
        Args:
            message: Mensaje a reproducir
            event_data: Datos del evento que activó la advertencia
            language: Código de idioma
            device: Dispositivo de salida
        """
        if not self.enabled:
            return False
            
        # Personalizar mensaje según evento
        if event_data and not message:
            event_type = event_data.get('type')
            if event_type == 'intrusion':
                zone = event_data.get('zone', 'esta área')
                message = f"Atención. Ha sido detectado en {zone}. Esta es una zona restringida."
            elif event_type == 'loitering':
                message = "Atención. Su comportamiento está siendo monitoreado. Por favor, continúe su camino."
            elif event_type == 'tailgating':
                message = "Atención. Acceso no autorizado detectado. El personal de seguridad ha sido alertado."
            else:
                message = "Atención. Su actividad está siendo monitoreada por el sistema de seguridad."
        
        # Encolar mensaje
        self.message_queue.put({
            'type': 'audio',
            'message': message,
            'language': language,
            'device': device,
            'event': event_data
        })
        
        return True 
```

### src\services\__init__.py
```py | 143 bytes | Modificado: 2025-03-05 19:19:16.241251
```
from .notification import NotificationService
from .video_recorder import VideoRecorder

__all__ = ['NotificationService', 'VideoRecorder'] 
```

### src\services\alert_manager.py
```py | 2460 bytes | Modificado: 2025-03-05 13:40:01.616566
```
from typing import Dict, List, Any
import asyncio
from datetime import datetime
import json
from pathlib import Path
import aiohttp

class AlertManager:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.alert_history = []
        self.notification_channels = {
            'whatsapp': self._send_whatsapp_alert,
            'email': self._send_email_alert,
            'push': self._send_push_notification,
            'monitoring': self._notify_monitoring_station
        }
        
    async def process_alert(self, alert_data: Dict[str, Any]):
        """Procesa y distribuye una alerta"""
        alert_id = self._generate_alert_id()
        alert = {
            'alert_id': alert_id,
            'timestamp': datetime.now().isoformat(),
            'data': alert_data,
            'status': 'new'
        }
        
        # Guardar alerta
        self.alert_history.append(alert)
        self._save_alert_to_disk(alert)
        
        # Determinar canales de notificación basado en severidad
        channels = self._determine_notification_channels(alert_data['severity'])
        
        # Enviar notificaciones
        notification_tasks = [
            self.notification_channels[channel](alert)
            for channel in channels
        ]
        
        await asyncio.gather(*notification_tasks)
        
    async def _send_whatsapp_alert(self, alert: Dict[str, Any]):
        """Envía alerta por WhatsApp"""
        try:
            message = self._format_whatsapp_message(alert)
            # Implementar lógica de envío de WhatsApp
            pass
        except Exception as e:
            print(f"Error enviando WhatsApp: {e}")
            
    def _determine_notification_channels(self, severity: int) -> List[str]:
        """Determina qué canales usar basado en la severidad"""
        if severity >= 4:
            return ['whatsapp', 'push', 'monitoring']
        elif severity >= 3:
            return ['whatsapp', 'push']
        else:
            return ['push']
            
    def _save_alert_to_disk(self, alert: Dict[str, Any]):
        """Guarda la alerta en disco"""
        alerts_dir = Path('data/alerts')
        alerts_dir.mkdir(exist_ok=True)
        
        file_path = alerts_dir / f"alert_{alert['alert_id']}.json"
        with open(file_path, 'w') as f:
            json.dump(alert, f, indent=2) 
```

### src\services\visitor_management.py
```py | 3805 bytes | Modificado: 2025-03-05 13:47:52.225543
```
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import uuid
from dataclasses import dataclass
import json
from pathlib import Path

@dataclass
class VisitorPass:
    visitor_id: str
    host_id: str
    name: str
    document_id: str
    valid_from: datetime
    valid_until: datetime
    access_points: List[str]
    vehicle_plate: Optional[str] = None
    face_id: Optional[str] = None
    status: str = "active"

class VisitorManager:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.active_passes: Dict[str, VisitorPass] = {}
        self.pass_history: List[Dict[str, Any]] = []
        self.storage_path = Path(config['storage_path'])
        self._load_passes()
        
    async def create_visitor_pass(self, visitor_data: Dict[str, Any]) -> VisitorPass:
        """Crea un nuevo pase de visitante"""
        visitor_id = str(uuid.uuid4())
        
        # Crear pase
        pass_data = VisitorPass(
            visitor_id=visitor_id,
            host_id=visitor_data['host_id'],
            name=visitor_data['name'],
            document_id=visitor_data['document_id'],
            valid_from=datetime.fromisoformat(visitor_data['valid_from']),
            valid_until=datetime.fromisoformat(visitor_data['valid_until']),
            access_points=visitor_data.get('access_points', ['main']),
            vehicle_plate=visitor_data.get('vehicle_plate'),
            face_id=visitor_data.get('face_id')
        )
        
        # Guardar pase
        self.active_passes[visitor_id] = pass_data
        await self._save_passes()
        
        return pass_data
        
    async def validate_pass(self, visitor_id: str, access_point: str) -> bool:
        """Valida un pase de visitante"""
        if visitor_id not in self.active_passes:
            return False
            
        pass_data = self.active_passes[visitor_id]
        now = datetime.now()
        
        # Verificar validez temporal
        if not (pass_data.valid_from <= now <= pass_data.valid_until):
            await self._expire_pass(visitor_id)
            return False
            
        # Verificar punto de acceso
        if access_point not in pass_data.access_points:
            return False
            
        return pass_data.status == "active"
        
    async def _expire_pass(self, visitor_id: str):
        """Expira un pase de visitante"""
        if visitor_id in self.active_passes:
            pass_data = self.active_passes[visitor_id]
            pass_data.status = "expired"
            
            # Mover a historial
            self.pass_history.append({
                "pass_data": pass_data.__dict__,
                "expiry_date": datetime.now().isoformat()
            })
            
            del self.active_passes[visitor_id]
            await self._save_passes()
            
    async def _save_passes(self):
        """Guarda los pases en disco"""
        try:
            self.storage_path.mkdir(parents=True, exist_ok=True)
            
            # Guardar pases activos
            active_file = self.storage_path / "active_passes.json"
            with open(active_file, 'w') as f:
                json.dump(
                    {k: v.__dict__ for k, v in self.active_passes.items()},
                    f,
                    default=str
                )
                
            # Guardar historial
            history_file = self.storage_path / "pass_history.json"
            with open(history_file, 'w') as f:
                json.dump(self.pass_history, f, default=str)
                
        except Exception as e:
            print(f"Error guardando pases: {e}") 
```

### src\services\communication\alert_service.py
```py | 2343 bytes | Modificado: 2025-03-05 13:54:09.479122
```
from typing import Dict, Any, List
from datetime import datetime
import asyncio
from .communication_base import Message, MessagePriority
from .whatsapp_service import WhatsAppService

class AlertService:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.channels = self._initialize_channels()
        self.alert_levels = {
            "info": MessagePriority.LOW,
            "warning": MessagePriority.MEDIUM,
            "alert": MessagePriority.HIGH,
            "critical": MessagePriority.URGENT,
            "emergency": MessagePriority.EMERGENCY
        }
        
    def _initialize_channels(self) -> Dict[str, Any]:
        """Inicializa los canales de comunicación"""
        channels = {}
        
        if self.config.get('whatsapp', {}).get('enabled', False):
            channels['whatsapp'] = WhatsAppService(
                self.config['whatsapp']
            )
            
        # Añadir más canales aquí
        
        return channels
        
    async def start(self):
        """Inicia todos los canales de comunicación"""
        for channel in self.channels.values():
            asyncio.create_task(channel.start())
            
    async def stop(self):
        """Detiene todos los canales de comunicación"""
        for channel in self.channels.values():
            await channel.stop()
            
    async def send_alert(self, 
                        alert_type: str,
                        message: str,
                        recipients: List[str],
                        metadata: Dict[str, Any] = None):
        """Envía una alerta por todos los canales configurados"""
        priority = self.alert_levels.get(alert_type, MessagePriority.MEDIUM)
        
        alert_message = Message(
            message_id=f"alert_{datetime.now().timestamp()}",
            content=message,
            priority=priority,
            recipients=recipients,
            metadata=metadata or {},
            timestamp=datetime.now()
        )
        
        # Enviar por todos los canales activos
        for channel in self.channels.values():
            await channel.queue_message(alert_message)

    def format_alert(self, alert_type, data):
        """Formatea la alerta según el canal""" 
```

### src\services\communication\communication_base.py
```py | 2523 bytes | Modificado: 2025-03-05 13:54:09.478591
```
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from datetime import datetime
import asyncio
from enum import Enum

class MessagePriority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    URGENT = 4
    EMERGENCY = 5

@dataclass
class Message:
    message_id: str
    content: str
    priority: MessagePriority
    recipients: List[str]
    metadata: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)
    status: str = "pending"
    retries: int = 0

class CommunicationChannel(ABC):
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.max_retries = config.get('max_retries', 3)
        self.retry_delay = config.get('retry_delay', 5)
        self._message_queue = asyncio.Queue()
        self._running = False
        
    @abstractmethod
    async def send_message(self, message: Message) -> bool:
        """Envía un mensaje a través del canal"""
        pass
        
    @abstractmethod
    async def format_message(self, message: Message) -> str:
        """Formatea el mensaje según el canal"""
        pass
        
    async def start(self):
        """Inicia el procesamiento de mensajes"""
        self._running = True
        while self._running:
            try:
                message = await self._message_queue.get()
                success = False
                retries = 0
                
                while not success and retries < self.max_retries:
                    success = await self.send_message(message)
                    if not success:
                        retries += 1
                        await asyncio.sleep(self.retry_delay)
                        
                if not success:
                    await self._handle_failed_message(message)
                    
            except Exception as e:
                print(f"Error procesando mensaje: {e}")
                
    async def stop(self):
        """Detiene el procesamiento de mensajes"""
        self._running = False
        
    async def queue_message(self, message: Message):
        """Encola un mensaje para envío"""
        await self._message_queue.put(message)
        
    async def _handle_failed_message(self, message: Message):
        """Maneja mensajes que no pudieron ser enviados"""
        message.status = "failed"
        # Implementar lógica de manejo de fallos
        pass 
```

### src\services\communication\whatsapp_service.py
```py | 2584 bytes | Modificado: 2025-03-05 13:54:09.479122
```
from .communication_base import CommunicationChannel, Message, MessagePriority
import aiohttp
from typing import Dict, Any
import json
from datetime import datetime

class WhatsAppService(CommunicationChannel):
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.api_url = config['api_url']
        self.auth_token = config['auth_token']
        self.templates = config.get('templates', {})
        
    async def send_message(self, message: Message) -> bool:
        """Envía un mensaje por WhatsApp"""
        try:
            formatted_message = await self.format_message(message)
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.auth_token}",
                    "Content-Type": "application/json"
                }
                
                for recipient in message.recipients:
                    payload = {
                        "messaging_product": "whatsapp",
                        "to": recipient,
                        "type": "text",
                        "text": {"body": formatted_message}
                    }
                    
                    async with session.post(
                        self.api_url,
                        headers=headers,
                        json=payload
                    ) as response:
                        if response.status != 200:
                            return False
                            
            return True
            
        except Exception as e:
            print(f"Error enviando mensaje WhatsApp: {e}")
            return False
            
    async def format_message(self, message: Message) -> str:
        """Formatea el mensaje según plantillas predefinidas"""
        template = self.templates.get(
            message.metadata.get('template_type', 'default'),
            "{content}"
        )
        
        # Formatear según prioridad
        priority_prefix = {
            MessagePriority.EMERGENCY: "🚨 EMERGENCIA: ",
            MessagePriority.URGENT: "⚠️ URGENTE: ",
            MessagePriority.HIGH: "❗ ",
            MessagePriority.MEDIUM: "",
            MessagePriority.LOW: ""
        }
        
        prefix = priority_prefix.get(message.priority, "")
        formatted_content = template.format(
            content=message.content,
            **message.metadata
        )
        
        return f"{prefix}{formatted_content}" 
```

### src\services\notification\__init__.py
```py | 88 bytes | Modificado: 2025-03-05 19:28:48.457529
```
from .notification_base import NotificationService

__all__ = ['NotificationService'] 
```

### src\services\notification\notification_base.py
```py | 1677 bytes | Modificado: 2025-03-05 19:32:02.150809
```
from abc import ABC, abstractmethod
from typing import Dict, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class NotificationConfig:
    enabled: bool
    credentials: Dict[str, str]
    templates: Dict[str, str]
    retry_count: int = 3
    retry_delay: int = 5  # segundos

class NotificationChannel(ABC):
    def __init__(self, config: NotificationConfig):
        self.config = config
        self.last_error = None
        
    @abstractmethod
    async def send(self, message: Dict[str, Any]) -> bool:
        """Envía una notificación"""
        pass
        
    @abstractmethod
    def format_message(self, data: Dict[str, Any]) -> str:
        """Formatea el mensaje según el canal"""
        pass
        
    async def handle_error(self, error: Exception):
        """Maneja errores de envío"""
        self.last_error = {
            'timestamp': datetime.now(),
            'error': str(error),
            'type': type(error).__name__
        } 

class NotificationService(ABC):
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
    @abstractmethod
    async def send_notification(self, message: str, data: Dict[str, Any] = None):
        """Envía una notificación"""
        pass
        
    async def send_alert(self, alert_type: str, details: Dict[str, Any]):
        """Envía una alerta"""
        message = f"ALERTA: {alert_type}"
        data = {
            "type": alert_type,
            "details": details,
            "timestamp": datetime.now().isoformat()
        }
        await self.send_notification(message, data) 
```

### src\services\notification\whatsapp_service.py
```py | 2253 bytes | Modificado: 2025-03-05 13:44:31.962374
```
from .notification_base import NotificationChannel, NotificationConfig
import aiohttp
from typing import Dict, Any
import json

class WhatsAppService(NotificationChannel):
    def __init__(self, config: NotificationConfig):
        super().__init__(config)
        self.api_url = "https://graph.facebook.com/v17.0/"
        self.headers = {
            "Authorization": f"Bearer {self.config.credentials['access_token']}",
            "Content-Type": "application/json"
        }
        
    async def send(self, message: Dict[str, Any]) -> bool:
        """Envía mensaje por WhatsApp"""
        formatted_message = self.format_message(message)
        
        payload = {
            "messaging_product": "whatsapp",
            "to": message['recipient'],
            "type": "text",
            "text": {"body": formatted_message}
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.api_url}{self.config.credentials['phone_number_id']}/messages",
                    headers=self.headers,
                    json=payload
                ) as response:
                    if response.status == 200:
                        return True
                    else:
                        error_data = await response.json()
                        await self.handle_error(Exception(f"WhatsApp API error: {error_data}"))
                        return False
                        
        except Exception as e:
            await self.handle_error(e)
            return False
            
    def format_message(self, data: Dict[str, Any]) -> str:
        """Formatea el mensaje para WhatsApp"""
        template = self.config.templates.get(data['type'], self.config.templates['default'])
        
        # Formatear mensaje según el tipo de alerta
        if data['type'] == 'suspicious_behavior':
            return template.format(
                location=data['location'],
                behavior=data['behavior'],
                confidence=f"{data['confidence']*100:.1f}%",
                time=data['timestamp']
            )
        
        return template.format(**data) 
```

### src\services\video_recorder\__init__.py
```py | 67 bytes | Modificado: 2025-03-05 19:28:48.457529
```
from .recorder import VideoRecorder

__all__ = ['VideoRecorder'] 
```

### src\services\video_recorder\recorder.py
```py | 6390 bytes | Modificado: 2025-03-06 00:37:32.361975
```
from typing import Dict, List, Any, Optional
import cv2
import numpy as np
from pathlib import Path
import asyncio
from datetime import datetime, timedelta
import json
from dataclasses import dataclass, field
import shutil
import os

@dataclass
class RecordingMetadata:
    start_time: datetime
    end_time: Optional[datetime]
    trigger_type: str
    camera_id: str
    file_path: str
    file_size: int
    duration: float
    resolution: tuple
    fps: float
    events: List[Dict[str, Any]] = field(default_factory=list)

class VideoRecorder:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.active_recordings: Dict[str, Dict[str, Any]] = {}
        
    async def start_recording(
        self, camera_id: str, trigger_type: str, frame: Optional[Any] = None
    ) -> str:
        """Inicia una grabación"""
        # Crear nombre único para la grabación
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        recording_id = f"{camera_id}_{timestamp}"
        
        # Crear directorio de almacenamiento
        storage_path = Path(self.config['storage_path'])
        storage_path.mkdir(parents=True, exist_ok=True)
        
        # Crear archivo de video
        video_path = storage_path / f"{recording_id}.mp4"
        
        # Obtener dimensiones del frame
        if frame is not None:
            height, width = frame.shape[:2]
        else:
            height, width = 480, 640  # Valores predeterminados
            
        # Crear escritor de video
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = self.config.get('fps', 20)
        
        writer = cv2.VideoWriter(
            str(video_path),
            fourcc,
            fps,
            (width, height)
        )
        
        # Crear metadatos
        metadata = {
            'recording_id': recording_id,
            'camera_id': camera_id,
            'start_time': datetime.now().isoformat(),
            'trigger_type': trigger_type,
            'events': []
        }
        
        # Almacenar información de la grabación
        self.active_recordings[recording_id] = {
            'writer': writer,
            'metadata': metadata,
            'frame_count': 0,
            'start_time': datetime.now()
        }
        
        # Escribir primer frame si está disponible
        if frame is not None:
            writer.write(frame)
            self.active_recordings[recording_id]['frame_count'] += 1
            
        return recording_id
        
    async def add_frame(
        self, recording_id: str, frame: Any, events: Optional[List[Dict[str, Any]]] = None
    ) -> bool:
        """Añade un frame a la grabación"""
        if recording_id not in self.active_recordings:
            return False
            
        recording = self.active_recordings[recording_id]
        
        # Añadir frame
        recording['writer'].write(frame)
        recording['frame_count'] += 1
        
        # Añadir eventos
        if events:
            recording['metadata']['events'].extend(events)
            
        # Verificar duración máxima
        if self.config.get('max_duration_minutes'):
            elapsed = (datetime.now() - recording['start_time']).total_seconds() / 60
            if elapsed >= self.config['max_duration_minutes']:
                await self.stop_recording(recording_id)
                return False
                
        return True
        
    async def stop_recording(self, recording_id: str) -> bool:
        """Detiene una grabación"""
        if recording_id not in self.active_recordings:
            return False
            
        recording = self.active_recordings[recording_id]
        
        # Liberar escritor de video
        recording['writer'].release()
        
        # Actualizar metadatos
        recording['metadata']['end_time'] = datetime.now().isoformat()
        recording['metadata']['frame_count'] = recording['frame_count']
        
        # Guardar metadatos
        storage_path = Path(self.config['storage_path'])
        metadata_path = storage_path / f"{recording_id}_metadata.json"
        
        with open(metadata_path, 'w') as f:
            json.dump(recording['metadata'], f, indent=2)
            
        # Eliminar grabación activa
        del self.active_recordings[recording_id]
        
        return True
        
    async def get_recording_metadata(self, recording_id: str) -> Optional[Dict[str, Any]]:
        """Obtiene los metadatos de una grabación"""
        # Verificar si es una grabación activa
        if recording_id in self.active_recordings:
            return self.active_recordings[recording_id]['metadata'].copy()
            
        # Verificar si existe archivo de metadatos
        storage_path = Path(self.config['storage_path'])
        metadata_path = storage_path / f"{recording_id}_metadata.json"
        
        if not metadata_path.exists():
            return None
            
        # Cargar metadatos
        with open(metadata_path, 'r') as f:
            return json.load(f)
            
    async def clean_old_recordings(self, max_age_days: int = 30) -> int:
        """Limpia grabaciones antiguas"""
        storage_path = Path(self.config['storage_path'])
        if not storage_path.exists():
            return 0
            
        # Obtener fecha límite
        limit_date = datetime.now().timestamp() - (max_age_days * 86400)
        
        # Contar eliminados
        deleted_count = 0
        
        # Listar archivos
        for file_path in storage_path.glob('*.mp4'):
            # Obtener fecha de modificación
            mod_time = os.path.getmtime(file_path)
            
            # Eliminar si es antiguo
            if mod_time < limit_date:
                # Eliminar archivo de video
                file_path.unlink()
                
                # Eliminar metadatos si existen
                metadata_path = file_path.with_name(f"{file_path.stem}_metadata.json")
                if metadata_path.exists():
                    metadata_path.unlink()
                    
                deleted_count += 1
                
        return deleted_count 
```

### src\storage\smart_recorder.py
```py | 10504 bytes | Modificado: 2025-03-07 00:45:19.618122
```
from collections import deque
import cv2
import os
import time
import logging
import threading
import numpy as np
from datetime import datetime

class SmartRecorder:
    def __init__(self, config_path="configs/storage.json", storage_manager=None):
        self.config = self._load_config(config_path)
        self.pre_event_buffer_size = self.config.get("pre_event_buffer", 300)  # frames
        self.buffers = {}  # Camera ID -> deque of frames
        self.recording_sessions = {}  # Session ID -> recording info
        self.logger = logging.getLogger('SmartRecorder')
        self.storage_manager = storage_manager
        self.lock = threading.RLock()
        
    def _load_config(self, config_path):
        """Cargar configuración desde archivo JSON"""
        if not os.path.exists(config_path):
            return {
                "pre_event_buffer": 300,  # frames (10 segundos a 30 fps)
                "post_event_buffer": 150,  # frames (5 segundos a 30 fps)
                "default_recording_duration": 60,  # segundos
                "output_directory": "recordings",
                "codec": "mp4v",
                "quality": 95,
                "resolution": null  # Mantener resolución original
            }
            
        import json
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            print(f"Error loading storage config: {e}")
            return {}
            
    def initialize_camera(self, camera_id, fps=30.0):
        """Inicializar buffer para una cámara"""
        with self.lock:
            if camera_id not in self.buffers:
                self.buffers[camera_id] = {
                    'frames': deque(maxlen=self.pre_event_buffer_size),
                    'fps': fps
                }
                self.logger.info(f"Initialized buffer for camera {camera_id}")
                
    def add_frame(self, camera_id, frame, timestamp=None, metadata=None):
        """Añadir frame al buffer temporal de una cámara"""
        if timestamp is None:
            timestamp = time.time()
            
        if metadata is None:
            metadata = {}
            
        # Asegurar que existe el buffer para esta cámara
        if camera_id not in self.buffers:
            self.initialize_camera(camera_id)
            
        # Añadir frame al buffer
        with self.lock:
            buffer = self.buffers[camera_id]['frames']
            buffer.append({
                'frame': frame.copy(),
                'timestamp': timestamp,
                'metadata': metadata
            })
            
        # Procesar grabaciones activas para esta cámara
        self._process_active_recordings(camera_id, frame, timestamp, metadata)
        
    def _process_active_recordings(self, camera_id, frame, timestamp, metadata):
        """Procesar grabaciones activas para una cámara"""
        with self.lock:
            # Identificar grabaciones activas para esta cámara
            active_sessions = [
                session_id for session_id, session in self.recording_sessions.items()
                if session['camera_id'] == camera_id and session['active']
            ]
            
            # Agregar frame a cada grabación activa
            for session_id in active_sessions:
                session = self.recording_sessions[session_id]
                
                # Agregar frame a grabadora
                session['writer'].write(frame)
                session['frame_count'] += 1
                session['last_frame_time'] = timestamp
                
                # Verificar si la grabación ha alcanzado su duración máxima
                if session['duration'] and timestamp - session['start_time'] >= session['duration']:
                    self._finish_recording(session_id)
                    
    def start_recording(self, camera_id, event_id, event_type, duration=None, pre_event=10):
        """Iniciar grabación con pre-buffer de eventos"""
        with self.lock:
            # Verificar que la cámara existe
            if camera_id not in self.buffers:
                self.logger.error(f"Camera {camera_id} not initialized")
                return None
                
            # Crear ID de sesión único
            session_id = f"{camera_id}_{event_id}_{int(time.time())}"
            
            # Obtener directorio de salida
            output_dir = self.config.get("output_directory", "recordings")
            os.makedirs(output_dir, exist_ok=True)
            
            # Crear nombre de archivo
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{output_dir}/{camera_id}_{event_type}_{timestamp}.mp4"
            
            # Obtener información del buffer
            buffer = self.buffers[camera_id]['frames']
            fps = self.buffers[camera_id]['fps']
            
            # Si el buffer está vacío, no podemos iniciar grabación
            if not buffer:
                self.logger.warning(f"Buffer empty for camera {camera_id}")
                return None
                
            # Obtener un frame para determinar tamaño
            sample_frame = buffer[0]['frame']
            height, width = sample_frame.shape[:2]
            
            # Verificar si necesitamos cambiar la resolución
            target_resolution = self.config.get("resolution")
            if target_resolution:
                width, height = target_resolution
                
            # Configurar codec de video
            fourcc = cv2.VideoWriter_fourcc(*self.config.get("codec", "mp4v"))
            out = cv2.VideoWriter(filename, fourcc, fps, (width, height))
            
            # Escribir frames del pre-buffer
            now = time.time()
            pre_event_time = now - pre_event  # Tiempo desde hace N segundos
            
            for item in buffer:
                if item['timestamp'] >= pre_event_time:
                    # Redimensionar si es necesario
                    if target_resolution:
                        frame = cv2.resize(item['frame'], (width, height))
                    else:
                        frame = item['frame']
                    out.write(frame)
                    
            # Crear entrada para la sesión de grabación
            self.recording_sessions[session_id] = {
                'camera_id': camera_id,
                'event_id': event_id,
                'event_type': event_type,
                'filename': filename,
                'writer': out,
                'start_time': now,
                'duration': duration,  # None significa grabar hasta stop_recording
                'active': True,
                'frame_count': len([item for item in buffer if item['timestamp'] >= pre_event_time]),
                'last_frame_time': now
            }
            
            self.logger.info(f"Started recording session {session_id} for event {event_id}")
            return session_id
            
    def stop_recording(self, session_id):
        """Finalizar grabación y almacenar video resultante"""
        with self.lock:
            return self._finish_recording(session_id)
            
    def _finish_recording(self, session_id):
        """Finalizar grabación y liberar recursos"""
        if session_id not in self.recording_sessions:
            self.logger.error(f"Recording session {session_id} not found")
            return False
            
        session = self.recording_sessions[session_id]
        
        if not session['active']:
            self.logger.warning(f"Recording session {session_id} already finished")
            return False
            
        # Liberar escritor de video
        session['writer'].release()
        session['active'] = False
        session['end_time'] = time.time()
        
        # Calcular duración real
        duration = session['end_time'] - session['start_time']
        
        # Guardar información de metadatos
        metadata = {
            'camera_id': session['camera_id'],
            'event_id': session['event_id'],
            'event_type': session['event_type'],
            'start_time': session['start_time'],
            'end_time': session['end_time'],
            'duration': duration,
            'frame_count': session['frame_count'],
            'filename': session['filename']
        }
        
        # Si tenemos storage_manager, registrar el video
        if self.storage_manager:
            self.storage_manager.register_video(session['filename'], metadata)
            
        self.logger.info(f"Finished recording session {session_id}, duration: {duration:.2f}s, frames: {session['frame_count']}")
        
        return {
            'filename': session['filename'],
            'metadata': metadata
        }
        
    def get_active_recordings(self):
        """Obtener lista de grabaciones activas"""
        with self.lock:
            return {
                session_id: {
                    'camera_id': session['camera_id'],
                    'event_id': session['event_id'],
                    'event_type': session['event_type'],
                    'start_time': session['start_time'],
                    'filename': session['filename'],
                    'frame_count': session['frame_count']
                }
                for session_id, session in self.recording_sessions.items()
                if session['active']
            }
            
    def stop_all_recordings(self):
        """Detener todas las grabaciones activas"""
        with self.lock:
            active_sessions = [
                session_id for session_id, session in self.recording_sessions.items()
                if session['active']
            ]
            
            results = {}
            for session_id in active_sessions:
                results[session_id] = self._finish_recording(session_id)
                
            return results
            
    def cleanup(self):
        """Limpiar recursos y detener grabaciones"""
        results = self.stop_all_recordings()
        
        with self.lock:
            self.buffers.clear()
            
        return results
```

### src\storage\storage_manager.py
```py | 18832 bytes | Modificado: 2025-03-15 10:07:42.181323
```
import os
import json
import logging
import shutil
import time
import sqlite3
from datetime import datetime, timedelta
import threading
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
import cv2
import asyncio

from typing import Optional, Dict, List, Any, Tuple
from src.config.config_loader import load_config
from src.events.event_bus import EventBus, EventTypes
from src.database.models import Camera, Recording, Alert
from src.database.db import get_db

class StorageManager:
    """
    Gestor de almacenamiento para grabaciones y snapshots
    Maneja la creación de directorios, limpieza y rotación de archivos
    """
    
    def __init__(self, config_path: str = "configs/config.yaml", event_bus: Optional[EventBus] = None):
        """Inicializa el gestor de almacenamiento"""
        self.logger = logging.getLogger("StorageManager")
        
        # Cargar configuración
        self.config = load_config(config_path)
        self.storage_config = self.config["storage"]
        
        # Directorios base
        self.recordings_dir = self.storage_config["recordings_dir"]
        self.snapshots_dir = self.storage_config["snapshots_dir"]
        
        # Estadísticas de uso
        self.disk_usage = 0
        self.disk_free = 0
        self.disk_total = 0
        
        # Crear directorios si no existen
        os.makedirs(self.recordings_dir, exist_ok=True)
        os.makedirs(self.snapshots_dir, exist_ok=True)
        
        # Bus de eventos
        self.event_bus = event_bus
        
        # Estado
        self.is_cleaning = False
        self.pending_recordings = {}  # camera_id: {recording_info}
    
    async def initialize(self):
        """Inicializa el gestor de almacenamiento"""
        try:
            # Conexión al evento bus si no está ya conectado
            if self.event_bus is None:
                self.event_bus = EventBus(
                    redis_host=self.config["redis"]["host"],
                    redis_port=self.config["redis"]["port"],
                    redis_db=self.config["redis"]["db"],
                    redis_password=self.config["redis"]["password"],
                )
                await self.event_bus.connect()
            
            # Verificar estado de almacenamiento
            self.update_disk_stats()
            
            # Realizar limpieza inicial si está habilitado
            if self.storage_config["auto_clean"] and self.disk_usage > self.storage_config["max_disk_usage_percent"]:
                await self.clean_old_recordings()
            
            # Suscribirse a eventos relevantes
            await self.event_bus.subscribe(EventTypes.RECORDING_STARTED, self.handle_recording_started)
            await self.event_bus.subscribe(EventTypes.RECORDING_STOPPED, self.handle_recording_stopped)
            await self.event_bus.subscribe(EventTypes.ALERT_GENERATED, self.handle_alert_generated)
            
            # Iniciar listener de eventos
            await self.event_bus.start_listener()
            
            self.logger.info("Gestor de almacenamiento inicializado")
            return True
            
        except Exception as e:
            self.logger.error(f"Error inicializando gestor de almacenamiento: {e}")
            return False
    
    def update_disk_stats(self):
        """Actualiza estadísticas de uso de disco"""
        try:
            # Obtener estadísticas de la unidad donde está el directorio de grabaciones
            stat = shutil.disk_usage(self.recordings_dir)
            
            self.disk_total = stat.total
            self.disk_free = stat.free
            self.disk_usage = 100 - (stat.free / stat.total * 100)
            
            self.logger.debug(f"Estadísticas de disco: Uso {self.disk_usage:.1f}%, Libre {self.disk_free / (1024**3):.1f} GB")
            return True
            
        except Exception as e:
            self.logger.error(f"Error actualizando estadísticas de disco: {e}")
            return False
    
    def get_snapshot_path(self, camera_id: int, timestamp: Optional[datetime] = None) -> str:
        """Construye la ruta para un snapshot"""
        if timestamp is None:
            timestamp = datetime.now()
        
        year_month = timestamp.strftime("%Y_%m")
        day = timestamp.strftime("%d")
        filename = f"cam_{camera_id}_{timestamp.strftime('%Y%m%d_%H%M%S')}.jpg"
        
        # Crear estructura de directorios
        path = os.path.join(self.snapshots_dir, f"camera_{camera_id}", year_month, day)
        os.makedirs(path, exist_ok=True)
        
        return os.path.join(path, filename)
    
    async def save_snapshot(self, camera_id: int, frame, timestamp: Optional[datetime] = None) -> Optional[str]:
        """Guarda un snapshot en disco"""
        try:
            if timestamp is None:
                timestamp = datetime.now()
                
            # Construir ruta
            snapshot_path = self.get_snapshot_path(camera_id, timestamp)
            
            # Guardar imagen
            cv2.imwrite(snapshot_path, frame)
            
            self.logger.debug(f"Snapshot guardado: {snapshot_path}")
            
            # Publicar evento
            if self.event_bus:
                await self.event_bus.publish(EventTypes.SNAPSHOT_SAVED, {
                    "camera_id": camera_id,
                    "path": snapshot_path,
                    "timestamp": timestamp.isoformat(),
                })
            
            return snapshot_path
            
        except Exception as e:
            self.logger.error(f"Error guardando snapshot: {e}")
            return None
    
    async def close(self):
        """Cierra el gestor de almacenamiento"""
        try:
            # Detener listener de eventos
            if self.event_bus:
                await self.event_bus.stop_listener()
            
            # Cerrar writers pendientes
            for camera_id, rec_info in self.pending_recordings.items():
                if "writer" in rec_info and rec_info["writer"]:
                    rec_info["writer"].release()
            
            self.pending_recordings = {}
            
            self.logger.info("Gestor de almacenamiento cerrado")
            return True
            
        except Exception as e:
            self.logger.error(f"Error cerrando gestor de almacenamiento: {e}")
            return False

    async def handle_recording_started(self, channel: str, data: dict):
        """Manejador para evento de inicio de grabación"""
        self.logger.info(f"Grabación iniciada: {data}")
        try:
            camera_id = data.get('camera_id')
            if not camera_id:
                self.logger.error("Evento de grabación sin camera_id")
                return
            
            # Agregar a grabaciones pendientes
            self.pending_recordings[camera_id] = {
                'start_time': datetime.now(),
                'metadata': data
            }
        except Exception as e:
            self.logger.error(f"Error manejando evento de inicio de grabación: {e}")
        
    async def handle_recording_stopped(self, channel: str, data: dict):
        """Manejador para evento de fin de grabación"""
        self.logger.info(f"Grabación detenida: {data}")
        try:
            camera_id = data.get('camera_id')
            if not camera_id or camera_id not in self.pending_recordings:
                self.logger.error(f"Evento de fin de grabación para cámara no iniciada: {camera_id}")
                return
            
            # Procesar fin de grabación
            del self.pending_recordings[camera_id]
        except Exception as e:
            self.logger.error(f"Error manejando evento de fin de grabación: {e}")

    async def handle_alert_generated(self, channel: str, data: dict):
        """Manejador para evento de alerta generada"""
        self.logger.info(f"Alerta generada: {data}")
        try:
            # Obtener metadatos relevantes
            camera_id = data.get('camera_id')
            alert_id = data.get('alert_id')
            
            if not camera_id:
                self.logger.error("Evento de alerta sin camera_id")
                return
            
            # Guardar snapshot si hay frame disponible
            if 'frame' in data:
                snapshot_path = await self.save_snapshot(
                    camera_id, 
                    data['frame'],
                    datetime.fromisoformat(data.get('timestamp', datetime.now().isoformat()))
                )
                
                # Asociar snapshot a la alerta en la base de datos
                if snapshot_path and alert_id:
                    with get_db() as db:
                        alert = db.query(Alert).filter(Alert.id == alert_id).first()
                        if alert:
                            alert.snapshot_path = snapshot_path
                            db.commit()
                            
        except Exception as e:
            self.logger.error(f"Error manejando evento de alerta: {e}")


class LocalStorage:
    """Backend de almacenamiento local en disco"""
    def __init__(self, config):
        self.config = config
        self.base_path = config.get('base_path', 'data/videos')
        self.structure = config.get('structure', '{year}/{month}/{day}/{camera_id}')
        self.logger = logging.getLogger('LocalStorage')
        
        # Crear directorio base si no existe
        os.makedirs(self.base_path, exist_ok=True)
        
    def _get_storage_path(self, metadata):
        """Generar estructura de directorios basada en metadatos"""
        timestamp = metadata.get('timestamp', time.time())
        dt = datetime.fromtimestamp(timestamp)
        
        # Variables para reemplazar en la estructura
        vars = {
            'year': dt.strftime('%Y'),
            'month': dt.strftime('%m'),
            'day': dt.strftime('%d'),
            'hour': dt.strftime('%H'),
            'camera_id': metadata.get('camera_id', 'unknown'),
            'event_type': metadata.get('event_type', 'recording')
        }
        
        # Reemplazar variables en la estructura
        dir_structure = self.structure.format(**vars)
        full_path = os.path.join(self.base_path, dir_structure)
        
        # Crear directorio si no existe
        os.makedirs(full_path, exist_ok=True)
        
        return full_path
        
    def store(self, source_path, metadata):
        """Almacenar un archivo en el sistema de archivos local"""
        try:
            if not os.path.exists(source_path):
                self.logger.error(f"Source file not found: {source_path}")
                return None
                
            # Generar estructura de directorios
            dest_dir = self._get_storage_path(metadata)
            
            # Generar nombre de archivo basado en timestamp y metadatos
            timestamp = metadata.get('timestamp', time.time())
            dt = datetime.fromtimestamp(timestamp)
            
            # Obtener extensión del archivo original
            _, ext = os.path.splitext(source_path)
            if not ext:
                ext = '.mp4'  # Default para videos
                
            # Nombre final: camera_eventtype_timestamp.ext
            filename = f"{metadata.get('camera_id', 'cam')}_{metadata.get('event_type', 'rec')}_{dt.strftime('%Y%m%d_%H%M%S')}{ext}"
            
            # Ruta completa de destino
            dest_path = os.path.join(dest_dir, filename)
            
            # Si el archivo origen es diferente al destino, copiar
            if os.path.abspath(source_path) != os.path.abspath(dest_path):
                shutil.copy2(source_path, dest_path)
                self.logger.info(f"File copied: {source_path} -> {dest_path}")
                
            return dest_path
            
        except Exception as e:
            self.logger.error(f"Error storing file: {e}")
            return None
            
    def retrieve(self, path):
        """Verificar si un archivo existe y es accesible"""
        if os.path.exists(path) and os.access(path, os.R_OK):
            return path
        return None
        
    def delete(self, path):
        """Eliminar un archivo"""
        try:
            if os.path.exists(path):
                os.remove(path)
                self.logger.info(f"File deleted: {path}")
                return True
            return False
        except Exception as e:
            self.logger.error(f"Error deleting file: {e}")
            return False
            
    def is_managed_path(self, path):
        """Verificar si una ruta está dentro del sistema gestionado"""
        try:
            base = os.path.abspath(self.base_path)
            path = os.path.abspath(path)
            return path.startswith(base)
        except:
            return False


class S3Storage:
    """Backend de almacenamiento en Amazon S3"""
    def __init__(self, config):
        self.config = config
        self.bucket = config.get('bucket')
        self.prefix = config.get('prefix', '')
        self.credentials_profile = config.get('credentials_profile', 'default')
        self.region = config.get('region', 'us-east-1')
        self.logger = logging.getLogger('S3Storage')
        self._s3_client = None
        
    @property
    def s3_client(self):
        """Obtener cliente S3 con inicialización perezosa"""
        if self._s3_client is None:
            try:
                import boto3
                session = boto3.Session(profile_name=self.credentials_profile)
                self._s3_client = session.client('s3', region_name=self.region)
            except ImportError:
                self.logger.error("boto3 package not installed. Install with: pip install boto3")
                raise
                
        return self._s3_client
        
    def _get_s3_key(self, source_path, metadata):
        """Generar clave S3 para el archivo"""
        timestamp = metadata.get('timestamp', time.time())
        dt = datetime.fromtimestamp(timestamp)
        
        # Generar estructura de directorios en S3
        year = dt.strftime('%Y')
        month = dt.strftime('%m')
        day = dt.strftime('%d')
        camera_id = metadata.get('camera_id', 'unknown')
        
        # Nombre del archivo
        filename = os.path.basename(source_path)
        
        # Combinar para formar la clave S3
        s3_key = f"{self.prefix}{year}/{month}/{day}/{camera_id}/{filename}"
        
        return s3_key.lstrip('/')
        
    def store(self, source_path, metadata):
        """Almacenar un archivo en S3"""
        try:
            if not os.path.exists(source_path):
                self.logger.error(f"Source file not found: {source_path}")
                return None
                
            # Generar clave S3
            s3_key = self._get_s3_key(source_path, metadata)
            
            # Preparar metadatos para S3
            s3_metadata = {
                'camera-id': str(metadata.get('camera_id', 'unknown')),
                'event-type': str(metadata.get('event_type', 'recording')),
                'timestamp': str(int(metadata.get('timestamp', time.time())))
            }
            
            # Subir archivo a S3
            self.s3_client.upload_file(
                source_path, 
                self.bucket, 
                s3_key,
                ExtraArgs={
                    'Metadata': s3_metadata,
                    'ContentType': 'video/mp4'
                }
            )
            
            # Generar URL
            s3_url = f"s3://{self.bucket}/{s3_key}"
            
            self.logger.info(f"File uploaded to S3: {source_path} -> {s3_url}")
            return s3_url
            
        except Exception as e:
            self.logger.error(f"Error uploading to S3: {e}")
            return None
            
    def retrieve(self, s3_url):
        """Descargar un archivo de S3 a una ubicación temporal"""
        try:
            # Parsear URL de S3
            if not s3_url.startswith('s3://'):
                self.logger.error(f"Invalid S3 URL: {s3_url}")
                return None
                
            parts = s3_url[5:].split('/', 1)
            if len(parts) != 2:
                self.logger.error(f"Invalid S3 URL format: {s3_url}")
                return None
                
            bucket = parts[0]
            s3_key = parts[1]
            
            # Crear directorio temporal para la descarga
            temp_dir = os.path.join(tempfile.gettempdir(), 'security_videos')
            os.makedirs(temp_dir, exist_ok=True)
            
            # Nombre de archivo local
            local_filename = os.path.basename(s3_key)
            local_path = os.path.join(temp_dir, local_filename)
            
            # Descargar archivo
            self.s3_client.download_file(bucket, s3_key, local_path)
            
            self.logger.info(f"File downloaded from S3: {s3_url} -> {local_path}")
            return local_path
            
        except Exception as e:
            self.logger.error(f"Error downloading from S3: {e}")
            return None
            
    def delete(self, s3_url):
        """Eliminar un archivo de S3"""
        try:
            # Parsear URL de S3
            if not s3_url.startswith('s3://'):
                self.logger.error(f"Invalid S3 URL: {s3_url}")
                return False
                
            parts = s3_url[5:].split('/', 1)
            if len(parts) != 2:
                self.logger.error(f"Invalid S3 URL format: {s3_url}")
                return False
                
            bucket = parts[0]
            s3_key = parts[1]
            
            # Eliminar archivo
            self.s3_client.delete_object(Bucket=bucket, Key=s3_key)
            
            self.logger.info(f"File deleted from S3: {s3_url}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error deleting from S3: {e}")
            return False
            
    def is_managed_path(self, path):
        """Verificar si una ruta está dentro del sistema gestionado"""
        return path.startswith(f"s3://{self.bucket}/{self.prefix}") 
```

### src\storage\video_indexer.py
```py | 19867 bytes | Modificado: 2025-03-07 00:47:33.121631
```
import logging
import sqlite3
import json
import os
import cv2
import time
from datetime import datetime
import tempfile
import shutil

class VideoIndexer:
    def __init__(self, db_path="data/video_index.db"):
        self.db_path = db_path
        self.logger = logging.getLogger('VideoIndexer')
        self._ensure_db_exists()
        
    def _ensure_db_exists(self):
        """Asegurar que la base de datos existe y tiene las tablas necesarias"""
        # Crear directorio si no existe
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Crear tabla videos
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS videos (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            filename TEXT UNIQUE,
            path TEXT,
            start_time REAL,
            end_time REAL,
            duration REAL,
            camera_id TEXT,
            frame_count INTEGER,
            thumbnail_path TEXT,
            created_at REAL
        )
        ''')
        
        # Crear tabla events
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            video_id INTEGER,
            event_id TEXT,
            event_type TEXT,
            start_time REAL,
            end_time REAL,
            metadata TEXT,
            FOREIGN KEY (video_id) REFERENCES videos (id)
        )
        ''')
        
        # Crear índices
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_videos_camera_id ON videos (camera_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_videos_start_time ON videos (start_time)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_events_video_id ON events (video_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_events_event_type ON events (event_type)')
        
        conn.commit()
        conn.close()
        
    def _index_video(self, video_path, metadata=None):
        """Indexar un archivo de video y extraer metadatos"""
        try:
            if not os.path.exists(video_path):
                self.logger.error(f"Video file not found: {video_path}")
                return None
                
            # Abrir video para extraer metadatos
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                self.logger.error(f"Could not open video: {video_path}")
                return None
                
            # Extraer metadatos del video
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            
            # Generar thumbnail
            thumbnail_path = self._generate_thumbnail(cap, video_path)
            
            # Actualizar los metadatos con información adicional
            if metadata is None:
                metadata = {}
                
            # Extraer información de tiempo desde el nombre de archivo si no hay metadatos
            if 'start_time' not in metadata and 'end_time' not in metadata:
                timestamp_str = os.path.basename(video_path).split('_')[-1].split('.')[0]
                try:
                    start_time = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S').timestamp()
                    metadata['start_time'] = start_time
                    metadata['end_time'] = start_time + duration
                except:
                    # Si no podemos extraer el timestamp del nombre, usar el tiempo actual
                    metadata['start_time'] = time.time() - duration
                    metadata['end_time'] = time.time()
            
            # Guardar en base de datos
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
            INSERT INTO videos 
            (filename, path, start_time, end_time, duration, camera_id, frame_count, thumbnail_path, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                os.path.basename(video_path),
                video_path,
                metadata.get('start_time', 0),
                metadata.get('end_time', 0),
                duration,
                metadata.get('camera_id', 'unknown'),
                frame_count,
                thumbnail_path,
                time.time()
            ))
            
            video_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            cap.release()
            
            self.logger.info(f"Video indexed: {video_path}, ID: {video_id}")
            return video_id
            
        except Exception as e:
            self.logger.error(f"Error indexing video {video_path}: {e}")
            return None
            
    def _generate_thumbnail(self, video_capture, video_path):
        """Generar thumbnail para el video"""
        try:
            # Crear directorio para thumbnails
            thumb_dir = os.path.join(os.path.dirname(self.db_path), 'thumbnails')
            os.makedirs(thumb_dir, exist_ok=True)
            
            # Generar nombre de archivo para thumbnail
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            thumb_path = os.path.join(thumb_dir, f"{base_name}_thumb.jpg")
            
            # Capturar frame para thumbnail (25% del video)
            frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            if frame_count > 0:
                video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(frame_count * 0.25))
                ret, frame = video_capture.read()
                if ret:
                    # Redimensionar si es muy grande
                    height, width = frame.shape[:2]
                    if width > 640:
                        ratio = 640.0 / width
                        frame = cv2.resize(frame, (640, int(height * ratio)))
                        
                    # Guardar thumbnail
                    cv2.imwrite(thumb_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    return thumb_path
                    
            # Si no se pudo generar thumbnail, retornar None
            return None
            
        except Exception as e:
            self.logger.error(f"Error generating thumbnail: {e}")
            return None
            
    def index_event(self, event_data, video_path, start_time, end_time):
        """Indexar evento y su video asociado"""
        try:
            # Verificar si el video ya está indexado
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('SELECT id FROM videos WHERE path = ?', (video_path,))
            result = cursor.fetchone()
            
            if result:
                video_id = result[0]
            else:
                # Generar metadatos para indexar el video
                metadata = {
                    'camera_id': event_data.get('camera_id', 'unknown'),
                    'event_id': event_data.get('id', str(int(time.time()))),
                    'start_time': start_time,
                    'end_time': end_time
                }
                
                # Indexar el video
                video_id = self._index_video(video_path, metadata)
                if not video_id:
                    conn.close()
                    return False
            
            # Insertar evento
            cursor.execute('''
            INSERT INTO events
            (video_id, event_id, event_type, start_time, end_time, metadata)
            VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                video_id,
                event_data.get('id', str(int(time.time()))),
                event_data.get('type', 'unknown'),
                start_time,
                end_time,
                json.dumps(event_data)
            ))
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"Event indexed: {event_data.get('type', 'unknown')} for video ID {video_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error indexing event: {e}")
            return False
            
    def search_events(self, filters=None, time_range=None, object_types=None, behavior_types=None):
        """Buscar eventos que coincidan con criterios"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row  # Para acceder a las columnas por nombre
            cursor = conn.cursor()
            
            # Construir consulta SQL
            query = '''
            SELECT e.*, v.filename, v.path, v.thumbnail_path, v.camera_id 
            FROM events e
            JOIN videos v ON e.video_id = v.id
            WHERE 1=1
            '''
            
            params = []
            
            # Filtrar por rango de tiempo
            if time_range:
                if 'start' in time_range:
                    query += " AND e.start_time >= ?"
                    params.append(time_range['start'])
                if 'end' in time_range:
                    query += " AND e.end_time <= ?"
                    params.append(time_range['end'])
                    
            # Filtrar por tipo de evento
            if filters and 'event_type' in filters:
                if isinstance(filters['event_type'], list):
                    placeholders = ','.join(['?'] * len(filters['event_type']))
                    query += f" AND e.event_type IN ({placeholders})"
                    params.extend(filters['event_type'])
                else:
                    query += " AND e.event_type = ?"
                    params.append(filters['event_type'])
                    
            # Filtrar por cámara
            if filters and 'camera_id' in filters:
                if isinstance(filters['camera_id'], list):
                    placeholders = ','.join(['?'] * len(filters['camera_id']))
                    query += f" AND v.camera_id IN ({placeholders})"
                    params.extend(filters['camera_id'])
                else:
                    query += " AND v.camera_id = ?"
                    params.append(filters['camera_id'])
                    
            # Ordenar por tiempo de inicio (más reciente primero)
            query += " ORDER BY e.start_time DESC"
            
            # Limitar resultados
            if filters and 'limit' in filters:
                query += " LIMIT ?"
                params.append(filters['limit'])
                
            # Ejecutar consulta
            cursor.execute(query, params)
            results = cursor.fetchall()
            
            # Formatear resultados
            events = []
            for row in results:
                event_data = json.loads(row['metadata']) if row['metadata'] else {}
                
                # Filtrar por tipos de objetos o comportamientos si se especifican
                if object_types and not self._event_has_object_types(event_data, object_types):
                    continue
                    
                if behavior_types and not self._event_has_behavior_types(event_data, behavior_types):
                    continue
                    
                events.append({
                    'id': row['id'],
                    'event_id': row['event_id'],
                    'event_type': row['event_type'],
                    'start_time': row['start_time'],
                    'end_time': row['end_time'],
                    'video_id': row['video_id'],
                    'video_path': row['path'],
                    'thumbnail_path': row['thumbnail_path'],
                    'camera_id': row['camera_id'],
                    'metadata': event_data
                })
                
            conn.close()
            return events
            
        except Exception as e:
            self.logger.error(f"Error searching events: {e}")
            return []
            
    def _event_has_object_types(self, event_data, object_types):
        """Verificar si el evento contiene alguno de los tipos de objetos especificados"""
        # Buscar en los metadatos del evento por objetos
        detected_objects = event_data.get('objects', [])
        if not detected_objects:
            return False
            
        # Verificar si algún objeto coincide con los tipos buscados
        for obj in detected_objects:
            if obj.get('type') in object_types or obj.get('class') in object_types:
                return True
                
        return False
        
    def _event_has_behavior_types(self, event_data, behavior_types):
        """Verificar si el evento contiene alguno de los comportamientos especificados"""
        # Buscar en los metadatos del evento por comportamientos
        behaviors = event_data.get('behaviors', [])
        if not behaviors:
            return False
            
        # Verificar si algún comportamiento coincide con los tipos buscados
        for behavior in behaviors:
            if behavior.get('type') in behavior_types:
                return True
                
        return False
        
    def get_video_details(self, video_id):
        """Obtener detalles de un video específico"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute('''
            SELECT * FROM videos WHERE id = ?
            ''', (video_id,))
            
            row = cursor.fetchone()
            if not row:
                conn.close()
                return None
                
            # Obtener eventos asociados
            cursor.execute('''
            SELECT * FROM events WHERE video_id = ? ORDER BY start_time
            ''', (video_id,))
            
            events = []
            for event_row in cursor.fetchall():
                events.append({
                    'id': event_row['id'],
                    'event_id': event_row['event_id'],
                    'event_type': event_row['event_type'],
                    'start_time': event_row['start_time'],
                    'end_time': event_row['end_time'],
                    'metadata': json.loads(event_row['metadata']) if event_row['metadata'] else {}
                })
                
            conn.close()
            
            # Formatear resultado
            return {
                'id': row['id'],
                'filename': row['filename'],
                'path': row['path'],
                'start_time': row['start_time'],
                'end_time': row['end_time'],
                'duration': row['duration'],
                'camera_id': row['camera_id'],
                'frame_count': row['frame_count'],
                'thumbnail_path': row['thumbnail_path'],
                'created_at': row['created_at'],
                'events': events
            }
            
        except Exception as e:
            self.logger.error(f"Error getting video details: {e}")
            return None
            
    def extract_clip(self, video_id, start_offset, end_offset, output_path=None):
        """Extraer un clip de un video más largo basado en tiempos de inicio y fin"""
        try:
            # Obtener detalles del video
            video_details = self.get_video_details(video_id)
            if not video_details:
                return None
                
            video_path = video_details['path']
            if not os.path.exists(video_path):
                self.logger.error(f"Video file not found: {video_path}")
                return None
                
            # Si no se especifica ruta de salida, crear una temporal
            if not output_path:
                base_name = os.path.splitext(os.path.basename(video_path))[0]
                output_dir = os.path.join(os.path.dirname(self.db_path), 'clips')
                os.makedirs(output_dir, exist_ok=True)
                output_path = os.path.join(output_dir, f"{base_name}_clip_{int(time.time())}.mp4")
                
            # Abrir video origen
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                self.logger.error(f"Could not open video: {video_path}")
                return None
                
            # Obtener propiedades del video
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # Calcular frames de inicio y fin
            start_frame = int(start_offset * fps)
            end_frame = int(end_offset * fps)
            
            # Configurar escritor de video
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            # Posicionar en frame inicial
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            
            # Copiar frames al nuevo video
            current_frame = start_frame
            while current_frame <= end_frame:
                ret, frame = cap.read()
                if not ret:
                    break
                    
                out.write(frame)
                current_frame += 1
                
            # Liberar recursos
            cap.release()
            out.release()
            
            self.logger.info(f"Clip extracted to {output_path}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"Error extracting clip: {e}")
            return None
            
    def delete_video(self, video_id, delete_file=False):
        """Eliminar video de la base de datos y opcionalmente el archivo"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Obtener ruta del archivo antes de eliminarlo
            cursor.execute('SELECT path, thumbnail_path FROM videos WHERE id = ?', (video_id,))
            row = cursor.fetchone()
            
            if not row:
                conn.close()
                return False
                
            video_path, thumbnail_path = row
            
            # Eliminar eventos asociados
            cursor.execute('DELETE FROM events WHERE video_id = ?', (video_id,))
            
            # Eliminar video de la base de datos
            cursor.execute('DELETE FROM videos WHERE id = ?', (video_id,))
            
            conn.commit()
            conn.close()
            
            # Opcionalmente eliminar el archivo físico
            if delete_file and os.path.exists(video_path):
                os.remove(video_path)
                
            # Eliminar thumbnail si existe
            if thumbnail_path and os.path.exists(thumbnail_path):
                os.remove(thumbnail_path)
                
            self.logger.info(f"Video {video_id} deleted from database")
            return True
            
        except Exception as e:
            self.logger.error(f"Error deleting video: {e}")
            return False 
```

### src\tools\diagnostic.py
```py | 11635 bytes | Modificado: 2025-03-15 10:53:59.873260
```
#!/usr/bin/env python
"""
Script de diagnóstico para el sistema vigIA
Verifica la configuración, base de datos, y componentes críticos
"""

import os
import sys
import sqlite3
import logging
import json
from pathlib import Path
from werkzeug.security import generate_password_hash, check_password_hash

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("diagnostic")

def check_database():
    """Verificar la base de datos y sus tablas"""
    logger.info("=== Verificando base de datos ===")
    
    try:
        # Verificar si el archivo existe
        db_path = 'vigia.db'
        if not os.path.exists(db_path):
            logger.error(f"Archivo de base de datos no encontrado: {db_path}")
            return False
            
        logger.info(f"Archivo de base de datos encontrado: {db_path} ({os.path.getsize(db_path)/1024:.2f} KB)")
        
        # Conectar a la base de datos
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Listar tablas
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        logger.info(f"Tablas encontradas: {len(tables)}")
        for table in tables:
            logger.info(f"  - {table[0]}")
            
        # Verificar usuarios
        try:
            cursor.execute("SELECT id, username, email, password_hash, is_active, role_id FROM users")
            users = cursor.fetchall()
            logger.info(f"Usuarios encontrados: {len(users)}")
            for user in users:
                logger.info(f"  - ID: {user[0]}, Usuario: {user[1]}, Email: {user[2]}, Activo: {user[4]}, Rol: {user[5]}")
                logger.info(f"    Hash de contraseña: {user[3][:20]}...")
        except sqlite3.OperationalError as e:
            logger.error(f"Error al consultar usuarios: {e}")
            
        # Verificar roles
        try:
            cursor.execute("SELECT id, name FROM roles")
            roles = cursor.fetchall()
            logger.info(f"Roles encontrados: {len(roles)}")
            for role in roles:
                logger.info(f"  - ID: {role[0]}, Nombre: {role[1]}")
        except sqlite3.OperationalError as e:
            logger.error(f"Error al consultar roles: {e}")
            
        # Verificar cámaras
        try:
            cursor.execute("SELECT COUNT(*) FROM cameras")
            camera_count = cursor.fetchone()[0]
            logger.info(f"Cámaras configuradas: {camera_count}")
        except sqlite3.OperationalError as e:
            logger.error(f"Error al consultar cámaras: {e}")
        
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"Error verificando la base de datos: {e}")
        return False

def check_password_hash_compatibility():
    """Verificar la compatibilidad del hash de contraseña"""
    logger.info("=== Verificando compatibilidad de hash de contraseña ===")
    
    try:
        # Generar un hash con werkzeug
        test_password = "test123"
        password_hash = generate_password_hash(test_password)
        logger.info(f"Hash generado para 'test123': {password_hash}")
        
        # Verificar el hash
        is_valid = check_password_hash(password_hash, test_password)
        logger.info(f"Verificación del hash: {'EXITOSA' if is_valid else 'FALLIDA'}")
        
        # Intentar verificar con contraseña incorrecta
        is_invalid = check_password_hash(password_hash, "wrong_password")
        logger.info(f"Verificación con contraseña incorrecta: {'FALLIDA COMO SE ESPERABA' if not is_invalid else 'INCORRECTAMENTE EXITOSA'}")
        
        # Prueba con hash conocido
        conn = sqlite3.connect('vigia.db')
        cursor = conn.cursor()
        cursor.execute("SELECT username, password_hash FROM users WHERE username = 'admin'")
        admin_user = cursor.fetchone()
        conn.close()
        
        if admin_user:
            username, stored_hash = admin_user
            logger.info(f"Usuario admin encontrado con hash: {stored_hash[:20]}...")
            
            # Verificar con la contraseña conocida
            is_admin_valid = check_password_hash(stored_hash, "admin123")
            logger.info(f"Verificación de contraseña de admin: {'EXITOSA' if is_admin_valid else 'FALLIDA'}")
            
            # Si falló, crear un nuevo hash y actualizar la base de datos
            if not is_admin_valid:
                logger.warning("La verificación falló. Se corregirá el hash del usuario admin.")
                new_hash = generate_password_hash("admin123")
                logger.info(f"Nuevo hash generado: {new_hash[:20]}...")
                
                # Actualizar en la base de datos
                conn = sqlite3.connect('vigia.db')
                cursor = conn.cursor()
                cursor.execute("UPDATE users SET password_hash = ? WHERE username = 'admin'", (new_hash,))
                conn.commit()
                conn.close()
                logger.info("Hash actualizado en la base de datos.")
        else:
            logger.error("Usuario admin no encontrado en la base de datos.")
        
        return True
        
    except Exception as e:
        logger.error(f"Error verificando la compatibilidad del hash: {e}")
        return False

def check_config_files():
    """Verificar archivos de configuración"""
    logger.info("=== Verificando archivos de configuración ===")
    
    try:
        # Verificar archivo principal de configuración
        config_file = 'configs/config.yaml'
        if not os.path.exists(config_file):
            logger.error(f"Archivo de configuración no encontrado: {config_file}")
            return False
            
        logger.info(f"Archivo de configuración encontrado: {config_file}")
        
        # Verificar directorios importantes
        important_dirs = ['data', 'logs', 'models', 'configs']
        for dir_name in important_dirs:
            if os.path.exists(dir_name) and os.path.isdir(dir_name):
                logger.info(f"Directorio encontrado: {dir_name}")
            else:
                logger.warning(f"Directorio no encontrado: {dir_name}")
                os.makedirs(dir_name, exist_ok=True)
                logger.info(f"Directorio creado: {dir_name}")
        
        return True
        
    except Exception as e:
        logger.error(f"Error verificando archivos de configuración: {e}")
        return False

def check_logs():
    """Verificar archivos de log"""
    logger.info("=== Verificando archivos de log ===")
    
    try:
        log_dir = 'logs'
        if not os.path.exists(log_dir):
            logger.error(f"Directorio de logs no encontrado: {log_dir}")
            return False
            
        log_files = list(Path(log_dir).glob('*.log'))
        logger.info(f"Archivos de log encontrados: {len(log_files)}")
        
        if log_files:
            # Verificar el archivo más reciente
            latest_log = max(log_files, key=os.path.getmtime)
            logger.info(f"Log más reciente: {latest_log.name} ({os.path.getsize(latest_log)/1024:.2f} KB)")
            
            # Mostrar las últimas líneas
            with open(latest_log, 'r') as f:
                last_lines = f.readlines()[-10:]
                logger.info("Últimas 10 líneas del log:")
                for line in last_lines:
                    logger.info(f"  {line.strip()}")
        
        return True
        
    except Exception as e:
        logger.error(f"Error verificando archivos de log: {e}")
        return False

def repair_database():
    """Reparar problemas comunes en la base de datos"""
    logger.info("=== Reparando la base de datos ===")
    
    try:
        conn = sqlite3.connect('vigia.db')
        cursor = conn.cursor()
        
        # 1. Comprobar si existe el rol de administrador
        cursor.execute("SELECT id FROM roles WHERE name = 'admin'")
        admin_role = cursor.fetchone()
        
        if not admin_role:
            logger.warning("Rol de administrador no encontrado. Creando...")
            cursor.execute("INSERT INTO roles (name, description, created_at, updated_at) VALUES ('admin', 'Administrador del sistema', datetime('now'), datetime('now'))")
            admin_role_id = cursor.lastrowid
            logger.info(f"Rol de administrador creado con ID: {admin_role_id}")
        else:
            admin_role_id = admin_role[0]
            logger.info(f"Rol de administrador encontrado con ID: {admin_role_id}")
        
        # 2. Comprobar si existe el usuario administrador
        cursor.execute("SELECT id FROM users WHERE username = 'admin'")
        admin_user = cursor.fetchone()
        
        if not admin_user:
            logger.warning("Usuario administrador no encontrado. Creando...")
            from werkzeug.security import generate_password_hash
            password_hash = generate_password_hash("admin123")
            
            cursor.execute("""
                INSERT INTO users (username, email, password_hash, first_name, last_name, role_id, is_active, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now'), datetime('now'))
            """, ("admin", "admin@vigia.local", password_hash, "Administrador", "del Sistema", admin_role_id, 1))
            
            admin_user_id = cursor.lastrowid
            logger.info(f"Usuario administrador creado con ID: {admin_user_id}")
        else:
            admin_user_id = admin_user[0]
            logger.info(f"Usuario administrador encontrado con ID: {admin_user_id}")
            
            # Actualizar hash de contraseña
            from werkzeug.security import generate_password_hash
            password_hash = generate_password_hash("admin123")
            
            cursor.execute("UPDATE users SET password_hash = ? WHERE id = ?", (password_hash, admin_user_id))
            logger.info("Hash de contraseña actualizado para el usuario administrador")
        
        conn.commit()
        conn.close()
        logger.info("Reparación de la base de datos completada")
        
        return True
        
    except Exception as e:
        logger.error(f"Error reparando la base de datos: {e}")
        return False

def main():
    """Función principal del diagnóstico"""
    logger.info("=== Iniciando diagnóstico del sistema vigIA ===")
    
    # Ejecutar todas las verificaciones
    db_ok = check_database()
    hash_ok = check_password_hash_compatibility()
    config_ok = check_config_files()
    logs_ok = check_logs()
    
    # Resumen
    logger.info("=== Resumen del diagnóstico ===")
    logger.info(f"Base de datos: {'OK' if db_ok else 'ERROR'}")
    logger.info(f"Hash de contraseña: {'OK' if hash_ok else 'ERROR'}")
    logger.info(f"Archivos de configuración: {'OK' if config_ok else 'ERROR'}")
    logger.info(f"Archivos de log: {'OK' if logs_ok else 'ERROR'}")
    
    # Reparar si es necesario
    if not db_ok or not hash_ok:
        logger.info("Se detectaron problemas. Iniciando reparación...")
        repair_database()
    
    logger.info("=== Diagnóstico completado ===")

if __name__ == "__main__":
    main() 
```

### src\tracking\multi_object_tracker.py
```py | 6402 bytes | Modificado: 2025-03-07 00:42:24.516925
```
import numpy as np
import cv2
from scipy.spatial import distance
from collections import OrderedDict

class MultiObjectTracker:
    def __init__(self, max_disappeared=40, tracker_type="centroid"):
        self.next_object_id = 0
        self.objects = OrderedDict()       # ID del objeto -> centroide
        self.disappeared = OrderedDict()   # ID del objeto -> contador de frames desaparecido
        self.bbox = OrderedDict()          # ID del objeto -> bounding box
        self.max_disappeared = max_disappeared
        self.tracker_type = tracker_type
        
    def register(self, centroid, bbox):
        """Registrar un nuevo objeto con su centroide y bbox"""
        self.objects[self.next_object_id] = centroid
        self.disappeared[self.next_object_id] = 0
        self.bbox[self.next_object_id] = bbox
        self.next_object_id += 1
        
    def deregister(self, object_id):
        """Eliminar un objeto del tracking"""
        del self.objects[object_id]
        del self.disappeared[object_id]
        del self.bbox[object_id]
        
    def _get_centroid(self, bbox):
        """Calcula el centroide a partir del bounding box"""
        # bbox formato: [x1, y1, x2, y2]
        cX = int((bbox[0] + bbox[2]) / 2.0)
        cY = int((bbox[1] + bbox[3]) / 2.0)
        return (cX, cY)
        
    def update(self, detections):
        """Actualizar trackers con nuevas detecciones"""
        # Si no hay detecciones, incrementar contador de desaparecidos
        if len(detections) == 0:
            for object_id in list(self.disappeared.keys()):
                self.disappeared[object_id] += 1
                
                # Eliminar si ha desaparecido por demasiados frames
                if self.disappeared[object_id] > self.max_disappeared:
                    self.deregister(object_id)
                    
            # No hay centroides a actualizar
            return self.get_tracks()
            
        # Inicializar array de centroides de detecciones actuales
        input_centroids = np.zeros((len(detections), 2), dtype="int")
        input_bboxes = []
        
        # Obtener centroides y bboxes de cada detección
        for (i, detection) in enumerate(detections):
            bbox = detection['bbox']
            input_bboxes.append(bbox)
            input_centroids[i] = self._get_centroid(bbox)
            
        # Si no estamos rastreando ningún objeto, registrar todos
        if len(self.objects) == 0:
            for i in range(len(input_centroids)):
                self.register(input_centroids[i], input_bboxes[i])
                
        # Si ya estamos rastreando objetos, necesitamos emparejarlos
        else:
            object_ids = list(self.objects.keys())
            object_centroids = list(self.objects.values())
            
            # Calcular distancias entre centroides existentes y nuevos
            D = distance.cdist(np.array(object_centroids), input_centroids)
            
            # Encontrar el objeto más cercano para cada detección nueva
            rows = D.min(axis=1).argsort()
            cols = D.argmin(axis=1)[rows]
            
            # Manejar asignaciones
            used_rows = set()
            used_cols = set()
            
            for (row, col) in zip(rows, cols):
                # Si ya hemos examinado esta fila o columna, ignorarla
                if row in used_rows or col in used_cols:
                    continue
                    
                # Obtener ID del objeto y actualizar su centroide y bbox
                object_id = object_ids[row]
                self.objects[object_id] = input_centroids[col]
                self.bbox[object_id] = input_bboxes[col]
                self.disappeared[object_id] = 0
                
                # Marcar fila y columna como usadas
                used_rows.add(row)
                used_cols.add(col)
                
            # Encontrar filas no utilizadas (objetos perdidos)
            unused_rows = set(range(D.shape[0])).difference(used_rows)
            
            # Incrementar contador de desaparecidos para objetos no emparejados
            for row in unused_rows:
                object_id = object_ids[row]
                self.disappeared[object_id] += 1
                
                if self.disappeared[object_id] > self.max_disappeared:
                    self.deregister(object_id)
                    
            # Encontrar columnas no utilizadas (nuevos objetos)
            unused_cols = set(range(D.shape[1])).difference(used_cols)
            
            # Registrar nuevos objetos
            for col in unused_cols:
                self.register(input_centroids[col], input_bboxes[col])
                
        # Retornar objetos rastreados
        return self.get_tracks()
        
    def get_tracks(self):
        """Retornar objetos actualmente rastreados con sus IDs"""
        tracks = []
        for object_id, centroid in self.objects.items():
            bbox = self.bbox[object_id]
            tracks.append({
                'id': object_id,
                'centroid': centroid,
                'bbox': bbox,
                'disappeared': self.disappeared[object_id]
            })
        return tracks
    
    def draw_tracks(self, frame, tracks, draw_id=True, color=(0, 255, 0)):
        """Dibuja los objetos rastreados en el frame"""
        result_frame = frame.copy()
        
        for track in tracks:
            # Obtener información del track
            bbox = track['bbox']
            track_id = track['id']
            
            # Dibujar bounding box
            cv2.rectangle(
                result_frame,
                (int(bbox[0]), int(bbox[1])),
                (int(bbox[2]), int(bbox[3])),
                color,
                2
            )
            
            # Dibujar ID del objeto
            if draw_id:
                cv2.putText(
                    result_frame,
                    f"ID: {track_id}",
                    (int(bbox[0]), int(bbox[1] - 10)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    color,
                    2
                )
                
        return result_frame 
```

### src\training\adaptive_learning.py
```py | 28874 bytes | Modificado: 2025-03-07 01:54:31.037788
```
import os
import logging
import numpy as np
import pandas as pd
import joblib
import json
import time
from datetime import datetime, timedelta
import tensorflow as tf
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

class AdaptiveLearningSystem:
    """
    Sistema de aprendizaje adaptativo para personalización por cliente
    
    Permite ajustar los modelos de detección y análisis de comportamiento
    basado en datos históricos específicos del cliente y retroalimentación.
    """
    
    def __init__(self, config=None):
        """
        Inicializar sistema de aprendizaje adaptativo
        
        Args:
            config: Configuración del sistema de aprendizaje
        """
        self.logger = logging.getLogger('AdaptiveLearningSystem')
        self.config = config or {}
        
        # Directorio para modelos y datos de entrenamiento
        self.models_dir = self.config.get('models_dir', 'data/client_models')
        os.makedirs(self.models_dir, exist_ok=True)
        
        # Cliente actual
        self.client_id = self.config.get('client_id', 'default')
        
        # Registro de eventos para entrenamiento
        self.event_history = []
        
        # Modelos personalizados
        self.behavior_models = {}
        self.detection_thresholds = {}
        self.zone_risk_profiles = {}
        
        # Cargar modelos existentes si hay
        self._load_client_models()
        
        self.logger.info(f"Sistema de aprendizaje adaptativo inicializado para cliente: {self.client_id}")
    
    def _load_client_models(self):
        """Cargar modelos específicos del cliente si existen"""
        client_dir = os.path.join(self.models_dir, self.client_id)
        
        if not os.path.exists(client_dir):
            os.makedirs(client_dir, exist_ok=True)
            self.logger.info(f"Creado nuevo directorio para cliente: {self.client_id}")
            return
            
        # Cargar umbrales personalizados
        thresholds_path = os.path.join(client_dir, 'detection_thresholds.json')
        if os.path.exists(thresholds_path):
            try:
                with open(thresholds_path, 'r') as f:
                    self.detection_thresholds = json.load(f)
                self.logger.info(f"Umbrales de detección cargados: {len(self.detection_thresholds)} configuraciones")
            except Exception as e:
                self.logger.error(f"Error al cargar umbrales: {e}")
                
        # Cargar perfiles de riesgo por zona
        risk_path = os.path.join(client_dir, 'zone_risk_profiles.json')
        if os.path.exists(risk_path):
            try:
                with open(risk_path, 'r') as f:
                    self.zone_risk_profiles = json.load(f)
                self.logger.info(f"Perfiles de riesgo cargados: {len(self.zone_risk_profiles)} zonas")
            except Exception as e:
                self.logger.error(f"Error al cargar perfiles de riesgo: {e}")
                
        # Cargar modelos de comportamiento
        for model_type in ['loitering', 'intrusion', 'tailgating', 'abandoned_object']:
            model_path = os.path.join(client_dir, f'{model_type}_model.pkl')
            if os.path.exists(model_path):
                try:
                    model = joblib.load(model_path)
                    self.behavior_models[model_type] = model
                    self.logger.info(f"Modelo de comportamiento '{model_type}' cargado")
                except Exception as e:
                    self.logger.error(f"Error al cargar modelo {model_type}: {e}")
    
    def register_event(self, event_data, feedback=None):
        """
        Registrar evento para entrenamiento futuro
        
        Args:
            event_data: Datos del evento detectado
            feedback: Retroalimentación opcional (true positive, false positive)
        """
        # Enriquecer datos con retroalimentación
        event_record = event_data.copy()
        event_record['registration_time'] = datetime.now().isoformat()
        
        if feedback:
            event_record['feedback'] = feedback
            
        self.event_history.append(event_record)
        
        # Guardar periódicamente si hay suficientes eventos nuevos
        if len(self.event_history) % 100 == 0:
            self._save_event_history()
            
        return True
    
    def register_simulation_data(self, simulation_data):
        """
        Registrar datos de simulación para entrenamiento
        
        Args:
            simulation_data: Lista de eventos simulados
        """
        if not simulation_data:
            return False
            
        # Marcar como datos de simulación
        for event in simulation_data:
            event['source'] = 'simulation'
            event['registration_time'] = datetime.now().isoformat()
            self.event_history.append(event)
            
        self.logger.info(f"Registrados {len(simulation_data)} eventos de simulación")
        
        # Entrenar con datos combinados
        if len(self.event_history) > 500:  # Entrenar cuando tengamos suficientes datos
            self.train_models()
            
        return True
    
    def _save_event_history(self):
        """Guardar historial de eventos para entrenamiento"""
        try:
            client_dir = os.path.join(self.models_dir, self.client_id)
            os.makedirs(client_dir, exist_ok=True)
            
            # Guardar en formato JSON
            history_path = os.path.join(client_dir, 'event_history.json')
            with open(history_path, 'w') as f:
                json.dump(self.event_history, f, indent=2)
                
            self.logger.info(f"Historial de eventos guardado: {len(self.event_history)} registros")
            return True
        except Exception as e:
            self.logger.error(f"Error al guardar historial de eventos: {e}")
            return False
    
    def train_models(self, specific_model=None):
        """
        Entrenar o reentrenar modelos con datos acumulados
        
        Args:
            specific_model: Entrenar solo un tipo específico de modelo
        
        Returns:
            Diccionario con resultados del entrenamiento
        """
        results = {}
        
        if len(self.event_history) < 100:
            self.logger.warning("Datos insuficientes para entrenamiento")
            return {"error": "Datos insuficientes", "min_required": 100}
            
        try:
            # Convertir a DataFrame para facilitar el preprocesamiento
            df = pd.DataFrame(self.event_history)
            
            # Modelos a entrenar
            models_to_train = [specific_model] if specific_model else ['loitering', 'intrusion', 'tailgating', 'abandoned_object']
            
            for model_type in models_to_train:
                if model_type not in df['type'].unique():
                    continue  # No hay datos para este tipo
                    
                # Filtrar por tipo de evento
                model_df = df[df['type'] == model_type].copy()
                
                # Preparar características según el tipo de evento
                X, y = self._prepare_features(model_df, model_type)
                
                if len(X) < 50:
                    self.logger.warning(f"Datos insuficientes para modelo {model_type}")
                    continue
                    
                # División train/test
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                # Entrenar modelo (RandomForest como ejemplo)
                model = RandomForestClassifier(n_estimators=100, random_state=42)
                model.fit(X_train, y_train)
                
                # Evaluar modelo
                accuracy = model.score(X_test, y_test)
                results[model_type] = {
                    "accuracy": accuracy,
                    "samples": len(X),
                    "features": X.shape[1]
                }
                
                # Guardar modelo
                self.behavior_models[model_type] = model
                self._save_model(model, model_type)
                
                self.logger.info(f"Modelo {model_type} entrenado. Precisión: {accuracy:.4f}")
                
            # Actualizar umbrales de detección basados en datos
            self._optimize_detection_thresholds(df)
            
            # Actualizar perfiles de riesgo por zona
            self._update_zone_risk_profiles(df)
            
            return results
            
        except Exception as e:
            self.logger.error(f"Error durante entrenamiento: {e}")
            return {"error": str(e)}
    
    def _prepare_features(self, df, event_type):
        """
        Preparar características para entrenamiento según tipo de evento
        
        Args:
            df: DataFrame con eventos
            event_type: Tipo de evento a modelar
            
        Returns:
            X, y para entrenamiento
        """
        # Crear etiquetas (1 para eventos confirmados, 0 para falsos positivos)
        y = np.ones(len(df))
        
        if 'feedback' in df.columns:
            mask = df['feedback'] == 'false_positive'
            y[mask] = 0
        
        feature_columns = []
        
        # Extraer características según tipo de evento
        if event_type == 'loitering':
            # Características para detección de merodeo
            if 'duration' in df.columns:
                df['duration_sec'] = df['duration'].apply(lambda x: x if isinstance(x, (int, float)) else 0)
                feature_columns.append('duration_sec')
                
            if 'details' in df.columns:
                # Extraer características del diccionario de detalles
                df['movement_radius'] = df['details'].apply(
                    lambda x: x.get('radius', 0) if isinstance(x, dict) else 0
                )
                df['detection_confidence'] = df['details'].apply(
                    lambda x: x.get('confidence', 0) if isinstance(x, dict) else 0
                )
                feature_columns.extend(['movement_radius', 'detection_confidence'])
                
        elif event_type == 'intrusion':
            # Características para detección de intrusión
            if 'details' in df.columns:
                df['zone_type'] = df['details'].apply(
                    lambda x: x.get('zone_type', 'unknown') if isinstance(x, dict) else 'unknown'
                )
                
                # Convertir zona a numérico
                zone_mapping = {zone: i for i, zone in enumerate(df['zone_type'].unique())}
                df['zone_type_id'] = df['zone_type'].map(zone_mapping)
                
                df['detection_confidence'] = df['details'].apply(
                    lambda x: x.get('confidence', 0) if isinstance(x, dict) else 0
                )
                
                feature_columns.extend(['zone_type_id', 'detection_confidence'])
                
        elif event_type in ['tailgating', 'abandoned_object']:
            # Características para otros tipos de eventos
            if 'details' in df.columns:
                df['detection_confidence'] = df['details'].apply(
                    lambda x: x.get('confidence', 0) if isinstance(x, dict) else 0
                )
                feature_columns.append('detection_confidence')
        
        # Añadir hora del día como característica
        if 'timestamp' in df.columns:
            df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
            feature_columns.append('hour')
            
        # Asegurar que tenemos al menos una característica
        if not feature_columns:
            # Usar cualquier columna numérica disponible
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                feature_columns = numeric_cols
            else:
                # Si no hay columnas numéricas, crear una
                df['dummy'] = 1
                feature_columns = ['dummy']
                
        X = df[feature_columns].fillna(0).values
        return X, y
    
    def _optimize_detection_thresholds(self, df):
        """
        Optimizar umbrales de detección basados en datos históricos
        
        Args:
            df: DataFrame con eventos históricos
        """
        # Optimizar por tipo de evento
        for event_type in df['type'].unique():
            type_df = df[df['type'] == event_type]
            
            # Solo optimizar si tenemos feedback
            if 'feedback' in type_df.columns and not type_df['feedback'].isna().all():
                confirmed_df = type_df[type_df['feedback'] == 'true_positive']
                rejected_df = type_df[type_df['feedback'] == 'false_positive']
                
                if len(confirmed_df) > 10 and len(rejected_df) > 5:
                    # Analizar niveles de confianza
                    conf_values = []
                    
                    for _, row in type_df.iterrows():
                        if 'confidence' in row and isinstance(row['confidence'], (int, float)):
                            conf_values.append(row['confidence'])
                        elif 'details' in row and isinstance(row['details'], dict) and 'confidence' in row['details']:
                            conf_values.append(row['details']['confidence'])
                            
                    if conf_values:
                        # Encontrar umbral óptimo (simplificado)
                        new_threshold = np.percentile(conf_values, 25)  # Usar percentil 25 como umbral
                        
                        # Evitar umbrales extremos
                        new_threshold = max(0.3, min(0.8, new_threshold))
                        
                        self.detection_thresholds[event_type] = new_threshold
                        self.logger.info(f"Umbral optimizado para {event_type}: {new_threshold:.2f}")
            
        # Guardar umbrales
        if self.detection_thresholds:
            self._save_detection_thresholds()
    
    def _update_zone_risk_profiles(self, df):
        """
        Actualizar perfiles de riesgo por zona basados en eventos históricos
        
        Args:
            df: DataFrame con eventos históricos
        """
        # Verificar si tenemos datos de zona
        if 'details' not in df.columns:
            return
            
        # Extraer zonas de los detalles
        zones = set()
        for _, row in df.iterrows():
            if isinstance(row['details'], dict) and 'zone' in row['details']:
                zones.add(row['details']['zone'])
                
        # Para cada zona, calcular perfil de riesgo
        for zone in zones:
            # Filtrar eventos en esta zona
            zone_events = []
            for _, row in df.iterrows():
                if isinstance(row['details'], dict) and row['details'].get('zone') == zone:
                    zone_events.append(row)
                    
            if len(zone_events) < 5:
                continue
                
            # Calcular distribución de tipos de eventos
            event_types = {}
            for event in zone_events:
                event_type = event['type']
                if event_type not in event_types:
                    event_types[event_type] = 0
                event_types[event_type] += 1
                
            # Calcular horas de mayor actividad
            hours = [0] * 24
            for event in zone_events:
                if 'timestamp' in event:
                    try:
                        hour = datetime.fromisoformat(event['timestamp']).hour
                        hours[hour] += 1
                    except:
                        pass
                        
            # Crear perfil de riesgo
            risk_profile = {
                'event_distribution': event_types,
                'total_events': len(zone_events),
                'active_hours': hours,
                'last_updated': datetime.now().isoformat()
            }
            
            # Calcular nivel de riesgo (0-100)
            events_per_day = len(zone_events) / max(1, (datetime.now() - datetime.fromisoformat(zone_events[0]['timestamp'])).days)
            risk_level = min(100, events_per_day * 10)  # 10 eventos/día = riesgo máximo
            risk_profile['risk_level'] = risk_level
            
            # Guardar perfil
            self.zone_risk_profiles[zone] = risk_profile
            
        # Guardar perfiles
        if self.zone_risk_profiles:
            self._save_zone_risk_profiles()
    
    def _save_model(self, model, model_type):
        """Guardar modelo entrenado"""
        try:
            client_dir = os.path.join(self.models_dir, self.client_id)
            os.makedirs(client_dir, exist_ok=True)
            
            model_path = os.path.join(client_dir, f'{model_type}_model.pkl')
            joblib.dump(model, model_path)
            
            self.logger.info(f"Modelo {model_type} guardado en {model_path}")
            return True
        except Exception as e:
            self.logger.error(f"Error al guardar modelo {model_type}: {e}")
            return False
    
    def _save_detection_thresholds(self):
        """Guardar umbrales de detección optimizados"""
        try:
            client_dir = os.path.join(self.models_dir, self.client_id)
            os.makedirs(client_dir, exist_ok=True)
            
            thresholds_path = os.path.join(client_dir, 'detection_thresholds.json')
            with open(thresholds_path, 'w') as f:
                json.dump(self.detection_thresholds, f, indent=2)
                
            self.logger.info(f"Umbrales de detección guardados: {len(self.detection_thresholds)} configuraciones")
            return True
        except Exception as e:
            self.logger.error(f"Error al guardar umbrales: {e}")
            return False
    
    def _save_zone_risk_profiles(self):
        """Guardar perfiles de riesgo por zona"""
        try:
            client_dir = os.path.join(self.models_dir, self.client_id)
            os.makedirs(client_dir, exist_ok=True)
            
            risk_path = os.path.join(client_dir, 'zone_risk_profiles.json')
            with open(risk_path, 'w') as f:
                json.dump(self.zone_risk_profiles, f, indent=2)
                
            self.logger.info(f"Perfiles de riesgo guardados: {len(self.zone_risk_profiles)} zonas")
            return True
        except Exception as e:
            self.logger.error(f"Error al guardar perfiles de riesgo: {e}")
            return False
            
    def get_optimized_parameters(self, camera_id=None, zone_id=None, event_type=None):
        """
        Obtener parámetros optimizados específicos
        
        Args:
            camera_id: ID de cámara opcional
            zone_id: ID de zona opcional
            event_type: Tipo de evento opcional
            
        Returns:
            Diccionario con parámetros optimizados
        """
        result = {
            'client_id': self.client_id,
            'updated_at': datetime.now().isoformat()
        }
        
        # Añadir umbrales de detección
        if event_type and event_type in self.detection_thresholds:
            result['detection_threshold'] = self.detection_thresholds[event_type]
        elif not event_type:
            result['detection_thresholds'] = self.detection_thresholds
            
        # Añadir perfil de riesgo de zona
        if zone_id and zone_id in self.zone_risk_profiles:
            result['zone_risk_profile'] = self.zone_risk_profiles[zone_id]
        elif not zone_id:
            # Incluir zonas de mayor riesgo
            high_risk_zones = {}
            for zone_id, profile in self.zone_risk_profiles.items():
                if profile.get('risk_level', 0) > 50:  # Zonas de alto riesgo
                    high_risk_zones[zone_id] = profile
            
            if high_risk_zones:
                result['high_risk_zones'] = high_risk_zones
        
        return result
    
    def run_scenario_simulation(self, scenario_config):
        """
        Ejecutar simulación de escenario para entrenamiento
        
        Args:
            scenario_config: Configuración del escenario a simular
            
        Returns:
            Resultados de la simulación
        """
        try:
            scenario_type = scenario_config.get('type', 'random')
            num_events = scenario_config.get('num_events', 100)
            event_types = scenario_config.get('event_types', ['intrusion', 'loitering', 'tailgating'])
            
            self.logger.info(f"Iniciando simulación de escenario: {scenario_type} con {num_events} eventos")
            
            # Generar eventos simulados
            simulated_events = []
            
            if scenario_type == 'random':
                simulated_events = self._generate_random_events(num_events, event_types)
            elif scenario_type == 'intrusion_sequence':
                simulated_events = self._simulate_intrusion_sequence(scenario_config)
            elif scenario_type == 'tailgating_sequence':
                simulated_events = self._simulate_tailgating_sequence(scenario_config)
            
            # Registrar eventos para entrenamiento
            if simulated_events:
                self.register_simulation_data(simulated_events)
                
            return {
                'status': 'success',
                'events_generated': len(simulated_events),
                'simulation_id': str(int(time.time()))
            }
            
        except Exception as e:
            self.logger.error(f"Error en simulación de escenario: {e}")
            return {'status': 'error', 'message': str(e)}
    
    def _generate_random_events(self, num_events, event_types):
        """Generar eventos aleatorios para simulación"""
        events = []
        base_time = datetime.now() - timedelta(days=7)  # Una semana atrás
        
        for i in range(num_events):
            event_type = np.random.choice(event_types)
            
            # Timestamp aleatorio en la última semana
            random_minutes = np.random.randint(0, 7 * 24 * 60)
            timestamp = (base_time + timedelta(minutes=random_minutes)).isoformat()
            
            # Crear evento simulado
            event = {
                'type': event_type,
                'timestamp': timestamp,
                'camera_id': f"cam_{np.random.randint(1, 5)}",
                'confidence': np.random.uniform(0.5, 0.95),
                'source': 'simulation',
                'details': {}
            }
            
            # Detalles específicos según tipo
            if event_type == 'intrusion':
                event['details'] = {
                    'zone': f"zone_{np.random.randint(1, 4)}",
                    'zone_type': np.random.choice(['restricted', 'secure', 'monitored']),
                    'duration': np.random.randint(5, 60)
                }
            elif event_type == 'loitering':
                event['details'] = {
                    'duration': np.random.randint(30, 300),
                    'radius': np.random.randint(10, 100)
                }
            elif event_type == 'tailgating':
                event['details'] = {
                    'follower_distance': np.random.randint(5, 30),
                    'time_gap': np.random.uniform(0.5, 3.0)
                }
                
            events.append(event)
            
        return events
    
    def _simulate_intrusion_sequence(self, config):
        """Simular secuencia de intrusión"""
        num_events = config.get('num_events', 20)
        zone_id = config.get('zone_id', 'zone_1')
        camera_id = config.get('camera_id', 'cam_1')
        
        events = []
        base_time = datetime.now() - timedelta(hours=24)
        
        # Simular secuencia de acercamiento a zona restringida
        for i in range(num_events):
            progress = i / num_events  # 0 -> 1
            
            # En etapas tempranas, solo acercamiento
            if progress < 0.3:
                event_type = 'loitering'
                confidence = np.random.uniform(0.5, 0.7)
                details = {
                    'duration': np.random.randint(10, 60),
                    'radius': np.random.randint(50, 100),
                    'distance_to_zone': int(100 * (1 - progress))
                }
            # Etapa media, intentos
            elif progress < 0.7:
                event_type = np.random.choice(['loitering', 'intrusion'], p=[0.7, 0.3])
                confidence = np.random.uniform(0.6, 0.8)
                details = {
                    'zone': zone_id,
                    'zone_type': 'restricted',
                    'duration': np.random.randint(5, 30),
                    'partial_entry': True
                }
            # Etapa final, intrusión completa
            else:
                event_type = 'intrusion'
                confidence = np.random.uniform(0.7, 0.95)
                details = {
                    'zone': zone_id,
                    'zone_type': 'restricted',
                    'duration': np.random.randint(10, 120),
                    'complete_entry': True
                }
                
            # Timestamp progresivo
            timestamp = (base_time + timedelta(minutes=i*15)).isoformat()
            
            event = {
                'type': event_type,
                'timestamp': timestamp,
                'camera_id': camera_id,
                'confidence': confidence,
                'source': 'simulation',
                'details': details
            }
            
            events.append(event)
            
        return events
    
    def _simulate_tailgating_sequence(self, config):
        """Simular secuencia de tailgating (seguimiento no autorizado)"""
        num_events = config.get('num_events', 15)
        zone_id = config.get('zone_id', 'entrance_1')
        camera_id = config.get('camera_id', 'cam_1')
        
        events = []
        base_time = datetime.now() - timedelta(hours=12)
        
        # Simular varios intentos de tailgating
        for i in range(num_events):
            # Variar tiempo entre eventos
            timestamp = (base_time + timedelta(minutes=i*30 + np.random.randint(0, 15))).isoformat()
            
            # Simular acceso autorizado seguido por no autorizado
            if i % 3 == 0:  # Cada 3 eventos, persona autorizada
                event_type = 'authorized_access'
                confidence = 0.9
                person_id = f"employee_{np.random.randint(1, 20)}"
                details = {
                    'zone': zone_id,
                    'person_id': person_id,
                    'access_method': np.random.choice(['card', 'biometric']),
                    'success': True
                }
            else:  # Intentos de tailgating
                event_type = 'tailgating'
                confidence = np.random.uniform(0.6, 0.9)
                details = {
                    'zone': zone_id,
                    'follower_distance': np.random.randint(5, 30),
                    'time_gap': np.random.uniform(0.5, 5.0),
                    'leader_id': f"employee_{np.random.randint(1, 20)}",
                    'success': np.random.random() > 0.5
                }
                
            event = {
                'type': event_type,
                'timestamp': timestamp,
                'camera_id': camera_id,
                'confidence': confidence,
                'source': 'simulation',
                'details': details
            }
            
            events.append(event)
            
        return events 
```

### src\training\dataset_manager.py
```py | 8947 bytes | Modificado: 2025-03-13 20:25:02.535138
```
import os
import json
import shutil
import cv2
import numpy as np
from datetime import datetime
from pathlib import Path

class DatasetManager:
    def __init__(self, base_path="data/custom_datasets"):
        self.base_path = base_path
        self.datasets = self._discover_datasets()
        
    def _discover_datasets(self):
        """Encuentra datasets existentes en el directorio base"""
        datasets = {}
        if os.path.exists(self.base_path):
            for dataset_name in os.listdir(self.base_path):
                dataset_path = os.path.join(self.base_path, dataset_name)
                if os.path.isdir(dataset_path):
                    # Verificar archivo de metadatos
                    metadata_path = os.path.join(dataset_path, "metadata.json")
                    if os.path.exists(metadata_path):
                        with open(metadata_path, 'r') as f:
                            metadata = json.load(f)
                        datasets[dataset_name] = metadata
        return datasets
        
    def create_dataset(self, name, description=None):
        """Crea estructura para un nuevo dataset"""
        dataset_path = os.path.join(self.base_path, name)
        
        if os.path.exists(dataset_path):
            raise ValueError(f"El dataset '{name}' ya existe")
            
        # Crear directorios
        os.makedirs(dataset_path, exist_ok=True)
        os.makedirs(os.path.join(dataset_path, "images"), exist_ok=True)
        os.makedirs(os.path.join(dataset_path, "labels"), exist_ok=True)
        
        # Crear metadatos
        metadata = {
            "name": name,
            "description": description or "",
            "created": datetime.now().isoformat(),
            "samples_count": 0,
            "classes": {}
        }
        
        with open(os.path.join(dataset_path, "metadata.json"), 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # Actualizar caché de datasets
        self.datasets[name] = metadata
        
        return name
        
    def add_sample(self, dataset_name, image_data, annotations=None):
        """Añade muestra al dataset con anotaciones opcionales"""
        if dataset_name not in self.datasets:
            raise ValueError(f"El dataset '{dataset_name}' no existe")
            
        dataset_path = os.path.join(self.base_path, dataset_name)
        metadata = self.datasets[dataset_name]
        
        # Generar ID de muestra
        sample_id = f"{dataset_name}_{metadata['samples_count'] + 1:06d}"
        
        # Guardar imagen
        image_path = os.path.join(dataset_path, "images", f"{sample_id}.jpg")
        cv2.imwrite(image_path, image_data)
        
        # Guardar anotaciones si se proporcionaron
        if annotations:
            label_path = os.path.join(dataset_path, "labels", f"{sample_id}.txt")
            
            with open(label_path, 'w') as f:
                for annotation in annotations:
                    # Actualizar estadísticas de clase
                    class_id = annotation["class_id"]
                    if str(class_id) not in metadata["classes"]:
                        metadata["classes"][str(class_id)] = {
                            "name": annotation.get("class_name", f"class_{class_id}"),
                            "count": 0
                        }
                    metadata["classes"][str(class_id)]["count"] += 1
                    
                    # Escribir anotación en formato YOLO: class_id x_center y_center width height
                    # Convertir de coordenadas absolutas a relativas (0-1)
                    height, width = image_data.shape[:2]
                    x, y, w, h = annotation["bbox"]
                    x_center = (x + w/2) / width
                    y_center = (y + h/2) / height
                    w_rel = w / width
                    h_rel = h / height
                    
                    f.write(f"{class_id} {x_center} {y_center} {w_rel} {h_rel}\n")
        
        # Actualizar metadatos
        metadata["samples_count"] += 1
        with open(os.path.join(dataset_path, "metadata.json"), 'w') as f:
            json.dump(metadata, f, indent=2)
        
        return sample_id
    
    def export_dataset(self, dataset_name, format="yolo"):
        """Exporta dataset en formato compatible con entrenamiento"""
        if dataset_name not in self.datasets:
            raise ValueError(f"El dataset '{dataset_name}' no existe")
            
        dataset_path = os.path.join(self.base_path, dataset_name)
        export_path = os.path.join(self.base_path, f"{dataset_name}_export")
        
        # Crear directorio de exportación
        os.makedirs(export_path, exist_ok=True)
        
        if format.lower() == "yolo":
            # Para YOLO, la estructura ya está correcta, solo necesitamos
            # copiar archivos y crear data.yaml
            
            # Copiar imágenes y etiquetas
            os.makedirs(os.path.join(export_path, "images", "train"), exist_ok=True)
            os.makedirs(os.path.join(export_path, "labels", "train"), exist_ok=True)
            
            # Copiar todas las imágenes y etiquetas
            for filename in os.listdir(os.path.join(dataset_path, "images")):
                shutil.copy(
                    os.path.join(dataset_path, "images", filename),
                    os.path.join(export_path, "images", "train", filename)
                )
                
            for filename in os.listdir(os.path.join(dataset_path, "labels")):
                shutil.copy(
                    os.path.join(dataset_path, "labels", filename),
                    os.path.join(export_path, "labels", "train", filename)
                )
            
            # Crear data.yaml para entrenamiento YOLO
            metadata = self.datasets[dataset_name]
            classes = []
            for class_id in sorted(metadata["classes"].keys(), key=int):
                classes.append(metadata["classes"][class_id]["name"])
                
            yaml_content = {
                "path": os.path.abspath(export_path),
                "train": "images/train",
                "val": "images/train",  # Mismo conjunto para simplificar
                "nc": len(classes),
                "names": classes
            }
            
            with open(os.path.join(export_path, "data.yaml"), 'w') as f:
                # Formato YAML manual simple
                f.write(f"path: {yaml_content['path']}\n")
                f.write(f"train: {yaml_content['train']}\n")
                f.write(f"val: {yaml_content['val']}\n")
                f.write(f"nc: {yaml_content['nc']}\n")
                f.write("names:\n")
                for name in yaml_content["names"]:
                    f.write(f"  - '{name}'\n")
            
            return export_path
            
        elif format.lower() == "coco":
            # Implementar exportación a formato COCO JSON
            # (Implementación simplificada)
            coco_data = {
                "info": {
                    "description": self.datasets[dataset_name].get("description", ""),
                    "date_created": datetime.now().isoformat()
                },
                "images": [],
                "annotations": [],
                "categories": []
            }
            
            # Llenar categorías
            for class_id, class_info in self.datasets[dataset_name]["classes"].items():
                coco_data["categories"].append({
                    "id": int(class_id),
                    "name": class_info["name"],
                    "supercategory": "object"
                })
            
            # Implementar resto de conversión COCO
            # ...
            
            with open(os.path.join(export_path, "annotations.json"), 'w') as f:
                json.dump(coco_data, f, indent=2)
                
            return export_path
            
        else:
            raise ValueError(f"Formato de exportación no soportado: {format}")
    
    def get_dataset_info(self, dataset_name):
        """Obtiene información del dataset"""
        if dataset_name not in self.datasets:
            raise ValueError(f"El dataset '{dataset_name}' no existe")
        return self.datasets[dataset_name]
    
    def delete_dataset(self, dataset_name):
        """Elimina un dataset completo"""
        if dataset_name not in self.datasets:
            raise ValueError(f"El dataset '{dataset_name}' no existe")
            
        dataset_path = os.path.join(self.base_path, dataset_name)
        shutil.rmtree(dataset_path)
        del self.datasets[dataset_name]
        return True 
```

### src\training\model_trainer.py
```py | 7823 bytes | Modificado: 2025-03-13 20:26:52.192403
```
import os
import json
import logging
import shutil
import yaml
import mlflow
import mlflow.pytorch
from pathlib import Path
from ultralytics import YOLO
from datetime import datetime
from src.training.dataset_manager import DatasetManager

class ModelTrainer:
    def __init__(self, config_path="configs/training.json"):
        self.config = self._load_config(config_path)
        self.dataset_manager = DatasetManager()
        self.logger = logging.getLogger("ModelTrainer")
        
        # Configurar MLflow
        mlflow_tracking_uri = self.config.get("mlflow_tracking_uri", "mlruns")
        mlflow.set_tracking_uri(mlflow_tracking_uri)
        
    def _load_config(self, config_path):
        """Carga la configuración de entrenamiento"""
        if not os.path.exists(config_path):
            self.logger.warning(f"Archivo de configuración no encontrado: {config_path}, usando valores por defecto")
            return {
                "default_epochs": 50,
                "default_batch_size": 16,
                "default_image_size": 640,
                "models_dir": "models",
                "exports_dir": "exports",
                "mlflow_tracking_uri": "mlruns",
                "mlflow_experiment_name": "vigia_model_training"
            }
            
        with open(config_path, 'r') as f:
            if config_path.endswith('.json'):
                return json.load(f)
            elif config_path.endswith('.yaml') or config_path.endswith('.yml'):
                return yaml.safe_load(f)
        
    def train_model(self, dataset_name, model_type="object_detection", 
                   base_model=None, epochs=None, batch_size=None, image_size=None):
        """Entrena un modelo con el dataset especificado"""
        # Validar dataset
        if dataset_name not in self.dataset_manager.datasets:
            raise ValueError(f"Dataset '{dataset_name}' no encontrado")
            
        # Usar valores predeterminados si no se especifican
        epochs = epochs or self.config.get("default_epochs", 50)
        batch_size = batch_size or self.config.get("default_batch_size", 16)
        image_size = image_size or self.config.get("default_image_size", 640)
        
        # Preparar dataset
        dataset_export_path = self.dataset_manager.export_dataset(dataset_name, format="yolo")
        dataset_yaml = os.path.join(dataset_export_path, "data.yaml")
        
        if not os.path.exists(dataset_yaml):
            raise FileNotFoundError(f"Archivo de configuración YOLO no encontrado: {dataset_yaml}")
        
        # Definir modelo base
        if not base_model:
            if model_type == "object_detection":
                base_model = "yolov8n.pt"  # Modelo más pequeño por defecto
            else:
                raise ValueError(f"Tipo de modelo no soportado: {model_type}")
        
        # Generar ID único para el modelo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_id = f"{dataset_name}_{model_type}_{timestamp}"
        
        # Crear directorio para el modelo si no existe
        models_dir = self.config.get("models_dir", "models")
        os.makedirs(models_dir, exist_ok=True)
        
        # Configurar MLflow
        mlflow.set_experiment(self.config.get("mlflow_experiment_name", "vigia_model_training"))
        
        # Entrenamiento con MLflow tracking
        with mlflow.start_run(run_name=model_id):
            self.logger.info(f"Iniciando entrenamiento: {model_id}")
            
            # Registrar parámetros
            mlflow.log_param("dataset", dataset_name)
            mlflow.log_param("model_type", model_type)
            mlflow.log_param("base_model", base_model)
            mlflow.log_param("epochs", epochs)
            mlflow.log_param("batch_size", batch_size)
            mlflow.log_param("image_size", image_size)
            
            try:
                # Cargar modelo base
                model = YOLO(base_model)
                
                # Entrenar modelo
                results = model.train(
                    data=dataset_yaml,
                    epochs=epochs,
                    batch=batch_size,
                    imgsz=image_size,
                    name=model_id
                )
                
                # Guardar modelo entrenado
                final_model_path = os.path.join(models_dir, f"{model_id}.pt")
                shutil.copy(results.model.path, final_model_path)
                
                # Registrar métricas
                metrics = results.results_dict
                for metric_name, metric_value in metrics.items():
                    if isinstance(metric_value, (int, float)):
                        mlflow.log_metric(metric_name, metric_value)
                
                # Registrar modelo en MLflow
                mlflow.pytorch.log_model(model.model, "model")
                
                # Registrar artefactos adicionales (gráficos, etc.)
                for plot_name in ["confusion_matrix.png", "results.png", "PR_curve.png"]:
                    plot_path = os.path.join("runs/detect", model_id, plot_name)
                    if os.path.exists(plot_path):
                        mlflow.log_artifact(plot_path, "plots")
                
                self.logger.info(f"Entrenamiento completado: {model_id}")
                return {
                    "model_id": model_id,
                    "model_path": final_model_path,
                    "metrics": metrics
                }
                
            except Exception as e:
                self.logger.error(f"Error durante el entrenamiento: {e}")
                mlflow.log_param("error", str(e))
                raise
    
    def export_model(self, model_id, format="onnx"):
        """Exporta modelo entrenado para producción"""
        models_dir = self.config.get("models_dir", "models")
        model_path = os.path.join(models_dir, f"{model_id}.pt")
        
        if not os.path.exists(model_path):
            raise ValueError(f"Modelo {model_id} no existe en {model_path}")
        
        exports_dir = self.config.get("exports_dir", "exports")
        export_path = os.path.join(exports_dir, model_id)
        os.makedirs(export_path, exist_ok=True)
        
        if format.lower() == "onnx":
            # Exportar a formato ONNX
            output_path = os.path.join(export_path, f"{model_id}.onnx")
            
            # Cargar el modelo
            model = YOLO(model_path)
            
            # Exportar a ONNX
            success = model.export(format="onnx", output=output_path)
            
            if success:
                self.logger.info(f"Modelo exportado exitosamente a ONNX: {output_path}")
                return output_path
            else:
                raise RuntimeError(f"Error al exportar modelo {model_id} a formato ONNX")
        
        elif format.lower() == "tflite":
            # Exportar a formato TFLite
            output_path = os.path.join(export_path, f"{model_id}.tflite")
            
            # Cargar el modelo
            model = YOLO(model_path)
            
            # Exportar a TFLite
            success = model.export(format="tflite", output=output_path)
            
            if success:
                self.logger.info(f"Modelo exportado exitosamente a TFLite: {output_path}")
                return output_path
            else:
                raise RuntimeError(f"Error al exportar modelo {model_id} a formato TFLite")
        
        else:
            raise ValueError(f"Formato de exportación no soportado: {format}") 
```

### src\utils\__init__.py
```py | 47 bytes | Modificado: 2025-03-06 00:07:42.445548
```
from . import logging

__all__ = ['logging'] 
```

### src\utils\logging\__init__.py
```py | 67 bytes | Modificado: 2025-03-06 00:06:56.191480
```
from .logger import SecurityLogger

__all__ = ['SecurityLogger'] 
```

### src\utils\logging\logger.py
```py | 3327 bytes | Modificado: 2025-03-05 19:49:44.406646
```
import logging
from pathlib import Path
from datetime import datetime
import json
from typing import Dict, Any, Optional
import asyncio
from logging.handlers import RotatingFileHandler

class SecurityLogger:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.log_dir = Path(config['log_dir'])
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # Configurar logger
        self.logger = logging.getLogger('security_system')
        self.logger.setLevel(logging.INFO)
        
        # Handler para archivo
        log_file = self.log_dir / 'security.log'
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(
            logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        )
        self.logger.addHandler(file_handler)
        
        # Handler para consola
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(
            logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        )
        self.logger.addHandler(console_handler)
        
    async def log_event(self, event_type: str, data: Dict[str, Any]):
        """Registra un evento en el log"""
        event_data = {
            'timestamp': datetime.now().isoformat(),
            'type': event_type,
            'data': data
        }
        
        # Guardar en archivo JSON
        events_file = self.log_dir / 'events.json'
        try:
            if events_file.exists():
                with open(events_file) as f:
                    events = json.load(f)
            else:
                events = []
                
            events.append(event_data)
            
            with open(events_file, 'w') as f:
                json.dump(events, f, indent=2)
                
        except Exception as e:
            self.logger.error(f"Error guardando evento: {e}")
            
        # Registrar en log
        self.logger.info(f"Event: {event_type} - {json.dumps(data)}")
        
    async def log_error(self, error: Exception, context: Dict[str, Any] = None):
        """Registra un error en el log"""
        error_data = {
            'timestamp': datetime.now().isoformat(),
            'error': str(error),
            'type': type(error).__name__,
            'context': context or {}
        }
        
        # Guardar en archivo JSON
        errors_file = self.log_dir / 'errors.json'
        try:
            if errors_file.exists():
                with open(errors_file) as f:
                    errors = json.load(f)
            else:
                errors = []
                
            errors.append(error_data)
            
            with open(errors_file, 'w') as f:
                json.dump(errors, f, indent=2)
                
        except Exception as e:
            self.logger.error(f"Error guardando error: {e}")
            
        # Registrar en log
        self.logger.error(f"Error: {error} - Context: {context}")
            
    def rotate_logs(self):
        """Fuerza la rotación de logs"""
        for handler in self.logger.handlers:
            if isinstance(handler, RotatingFileHandler):
                handler.doRollover() 
```

### src\web\__init__.py
```py | 31 bytes | Modificado: 2025-03-06 00:55:40.495805
```
# Paquete para la interfaz web 
```

### src\web\server.py
```py | 6552 bytes | Modificado: 2025-03-06 01:03:56.717170
```
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import httpx
import os
from pathlib import Path

# Crear directorio de templates si no existe
templates_dir = Path("src/web/templates")
templates_dir.mkdir(parents=True, exist_ok=True)

# Crear directorio de static si no existe
static_dir = Path("src/web/static")
static_dir.mkdir(parents=True, exist_ok=True)

# Inicializar aplicación FastAPI
app = FastAPI(title="Sistema de Videovigilancia - Interfaz Web")

# Configurar cliente HTTP para comunicación con API
API_URL = os.environ.get("API_URL", "http://127.0.0.1:8050")
http_client = httpx.AsyncClient(base_url=API_URL)

# Configurar templates
templates = Jinja2Templates(directory="src/web/templates")

# Montar archivos estáticos
app.mount("/static", StaticFiles(directory="src/web/static"), name="static")

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    """Página principal del dashboard"""
    try:
        # Obtener estado del sistema desde la API
        system_status = await http_client.get("/status")
        system_status.raise_for_status()
        status_data = system_status.json()
        
        # Obtener últimos eventos
        events = await http_client.get("/events", params={"limit": 10})
        events.raise_for_status()
        events_data = events.json()
        
        return templates.TemplateResponse(
            "index.html",
            {
                "request": request,
                "system_status": status_data,
                "events": events_data
            }
        )
    except httpx.HTTPError as e:
        return templates.TemplateResponse(
            "error.html",
            {
                "request": request,
                "error": f"Error de comunicación con API: {str(e)}"
            }
        )

@app.get("/agents", response_class=HTMLResponse)
async def agents_page(request: Request):
    """Página de gestión de agentes"""
    try:
        # Obtener lista de agentes
        agents = await http_client.get("/agents")
        agents.raise_for_status()
        agents_data = agents.json()
        
        return templates.TemplateResponse(
            "agents.html",
            {
                "request": request,
                "agents": agents_data
            }
        )
    except httpx.HTTPError as e:
        return templates.TemplateResponse(
            "error.html",
            {
                "request": request,
                "error": f"Error de comunicación con API: {str(e)}"
            }
        )

@app.get("/events", response_class=HTMLResponse)
async def events_page(
    request: Request,
    limit: int = 50,
    offset: int = 0,
    event_type: str = None
):
    """Página de historial de eventos"""
    try:
        # Construir parámetros de consulta
        params = {"limit": limit, "offset": offset}
        if event_type:
            params["event_type"] = event_type
            
        # Obtener eventos
        events = await http_client.get("/events", params=params)
        events.raise_for_status()
        events_data = events.json()
        
        return templates.TemplateResponse(
            "events.html",
            {
                "request": request,
                "events": events_data,
                "current_page": offset // limit + 1,
                "total_pages": max(1, (len(events_data) + limit - 1) // limit),
                "event_type": event_type
            }
        )
    except httpx.HTTPError as e:
        return templates.TemplateResponse(
            "error.html",
            {
                "request": request,
                "error": f"Error de comunicación con API: {str(e)}"
            }
        )

@app.get("/media", response_class=HTMLResponse)
async def media_page(request: Request):
    """Página de visualización de grabaciones y snapshots"""
    try:
        # Obtener snapshots
        snapshots = await http_client.get("/snapshots", params={"limit": 20})
        snapshots.raise_for_status()
        snapshots_data = snapshots.json()
        
        # Obtener grabaciones
        recordings = await http_client.get("/recordings", params={"limit": 20})
        recordings.raise_for_status()
        recordings_data = recordings.json()
        
        return templates.TemplateResponse(
            "media.html",
            {
                "request": request,
                "snapshots": snapshots_data,
                "recordings": recordings_data
            }
        )
    except httpx.HTTPError as e:
        return templates.TemplateResponse(
            "error.html",
            {
                "request": request,
                "error": f"Error de comunicación con API: {str(e)}"
            }
        )

@app.post("/api/agents/{agent_id}/start")
async def start_agent_proxy(agent_id: str):
    """Proxy para iniciar agente"""
    try:
        response = await http_client.post(f"/agents/{agent_id}/start")
        response.raise_for_status()
        return response.json()
    except httpx.HTTPError as e:
        raise HTTPException(status_code=e.response.status_code if hasattr(e, 'response') else 500, 
                           detail=str(e))

@app.post("/api/agents/{agent_id}/stop")
async def stop_agent_proxy(agent_id: str):
    """Proxy para detener agente"""
    try:
        response = await http_client.post(f"/agents/{agent_id}/stop")
        response.raise_for_status()
        return response.json()
    except httpx.HTTPError as e:
        raise HTTPException(status_code=e.response.status_code if hasattr(e, 'response') else 500, 
                           detail=str(e))

@app.delete("/api/agents/{agent_id}")
async def delete_agent_proxy(agent_id: str):
    """Proxy para eliminar agente"""
    try:
        response = await http_client.delete(f"/agents/{agent_id}")
        response.raise_for_status()
        return response.json()
    except httpx.HTTPError as e:
        raise HTTPException(status_code=e.response.status_code if hasattr(e, 'response') else 500, 
                           detail=str(e))

@app.on_event("shutdown")
async def shutdown_event():
    """Cierra el cliente HTTP al apagar la aplicación"""
    await http_client.aclose() 
```

### src\web\templates\agents.html
```html | 11342 bytes | Modificado: 2025-03-06 00:55:40.499806
```
{% extends "base.html" %}

{% block title %}Gestión de Agentes - Sistema de Videovigilancia{% endblock %}

{% block content %}
<div class="container">
    <div class="d-flex justify-content-between align-items-center mb-4">
        <h1>Gestión de Agentes</h1>
        <button class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#newAgentModal">
            <i class="bi bi-plus-circle"></i> Nuevo Agente
        </button>
    </div>
    
    {% if agents %}
        <div class="row">
            {% for agent in agents %}
                <div class="col-md-6 mb-4">
                    <div class="card h-100">
                        <div class="card-header d-flex justify-content-between align-items-center">
                            <h5 class="card-title mb-0">
                                <span class="status-indicator status-{{ agent.status }}"></span>
                                {{ agent.agent_id }}
                            </h5>
                            <span class="badge {% if agent.status == 'running' %}bg-success{% else %}bg-danger{% endif %}">
                                {{ agent.status }}
                            </span>
                        </div>
                        <div class="card-body">
                            <div class="row mb-3">
                                <div class="col-md-6">
                                    <p><strong>Tipo:</strong> {{ agent.agent_type }}</p>
                                    <p><strong>Eventos procesados:</strong> {{ agent.events_processed }}</p>
                                </div>
                                <div class="col-md-6">
                                    <p><strong>Tiempo activo:</strong> 
                                       {% if agent.uptime %}
                                           {{ (agent.uptime / 60)|round(1) }} minutos
                                       {% else %}
                                           No disponible
                                       {% endif %}
                                    </p>
                                </div>
                            </div>
                            
                            <div class="mb-3">
                                <h6>Configuración</h6>
                                <ul class="list-group">
                                    {% if agent.config.camera_id is defined %}
                                        <li class="list-group-item d-flex justify-content-between">
                                            <span>Cámara ID:</span>
                                            <span>{{ agent.config.camera_id }}</span>
                                        </li>
                                    {% endif %}
                                    {% if agent.config.video_source is defined %}
                                        <li class="list-group-item d-flex justify-content-between">
                                            <span>Fuente de video:</span>
                                            <span>{{ agent.config.video_source }}</span>
                                        </li>
                                    {% endif %}
                                    {% if agent.config.object_detection is defined and agent.config.object_detection.confidence_threshold is defined %}
                                        <li class="list-group-item d-flex justify-content-between">
                                            <span>Umbral de confianza:</span>
                                            <span>{{ agent.config.object_detection.confidence_threshold }}</span>
                                        </li>
                                    {% endif %}
                                </ul>
                            </div>
                        </div>
                        <div class="card-footer d-flex justify-content-between">
                            {% if agent.status == 'running' %}
                                <button class="btn btn-danger btn-sm" onclick="stopAgent('{{ agent.agent_id }}')">
                                    <i class="bi bi-stop-circle"></i> Detener
                                </button>
                            {% else %}
                                <button class="btn btn-success btn-sm" onclick="startAgent('{{ agent.agent_id }}')">
                                    <i class="bi bi-play-circle"></i> Iniciar
                                </button>
                            {% endif %}
                            <button class="btn btn-outline-danger btn-sm" onclick="deleteAgent('{{ agent.agent_id }}')">
                                <i class="bi bi-trash"></i> Eliminar
                            </button>
                        </div>
                    </div>
                </div>
            {% endfor %}
        </div>
    {% else %}
        <div class="alert alert-info">
            <i class="bi bi-info-circle"></i> No hay agentes registrados. Crea un nuevo agente para comenzar.
        </div>
    {% endif %}
</div>

<!-- Modal para crear nuevo agente -->
<div class="modal fade" id="newAgentModal" tabindex="-1">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Crear Nuevo Agente</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <form id="newAgentForm">
                    <div class="mb-3">
                        <label for="agentId" class="form-label">ID del Agente</label>
                        <input type="text" class="form-control" id="agentId" required>
                    </div>
                    <div class="mb-3">
                        <label for="videoSource" class="form-label">Fuente de Video</label>
                        <input type="text" class="form-control" id="videoSource" required 
                               placeholder="0 para webcam, ruta para video o URL RTSP">
                    </div>
                    <div class="mb-3">
                        <label for="cameraId" class="form-label">ID de Cámara (opcional)</label>
                        <input type="text" class="form-control" id="cameraId" 
                               placeholder="Si se deja vacío, se usará el ID del agente">
                    </div>
                    <div class="mb-3">
                        <label for="confidenceThreshold" class="form-label">
                            Umbral de Confianza
                            <span id="confidenceValue">0.5</span>
                        </label>
                        <input type="range" class="form-range" id="confidenceThreshold" 
                               min="0.1" max="0.9" step="0.1" value="0.5"
                               oninput="document.getElementById('confidenceValue').textContent = this.value">
                    </div>
                </form>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancelar</button>
                <button type="button" class="btn btn-primary" onclick="createAgent()">Crear Agente</button>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block extra_js %}
<script>
    // Crear nuevo agente
    async function createAgent() {
        const agentId = document.getElementById('agentId').value;
        const videoSource = document.getElementById('videoSource').value;
        const cameraId = document.getElementById('cameraId').value;
        const confidenceThreshold = document.getElementById('confidenceThreshold').value;
        
        if (!agentId || !videoSource) {
            alert('Por favor completa los campos requeridos');
            return;
        }
        
        try {
            const params = new URLSearchParams({
                agent_id: agentId,
                video_source: videoSource,
                confidence_threshold: confidenceThreshold
            });
            
            if (cameraId) {
                params.append('camera_id', cameraId);
            }
            
            const response = await fetch(`/api/agents/video?${params.toString()}`, {
                method: 'POST'
            });
            
            if (!response.ok) {
                throw new Error(`Error: ${response.status} - ${response.statusText}`);
            }
            
            const data = await response.json();
            alert(data.message);
            
            // Cerrar modal y recargar página
            const modal = bootstrap.Modal.getInstance(document.getElementById('newAgentModal'));
            modal.hide();
            location.reload();
        } catch (error) {
            console.error('Error creating agent:', error);
            alert(`Error al crear agente: ${error.message}`);
        }
    }
    
    // Iniciar agente
    async function startAgent(agentId) {
        try {
            const response = await fetch(`/api/agents/${agentId}/start`, {
                method: 'POST'
            });
            
            if (!response.ok) {
                throw new Error(`Error: ${response.status} - ${response.statusText}`);
            }
            
            const data = await response.json();
            alert(data.message);
            location.reload();
        } catch (error) {
            console.error('Error starting agent:', error);
            alert(`Error al iniciar agente: ${error.message}`);
        }
    }
    
    // Detener agente
    async function stopAgent(agentId) {
        try {
            const response = await fetch(`/api/agents/${agentId}/stop`, {
                method: 'POST'
            });
            
            if (!response.ok) {
                throw new Error(`Error: ${response.status} - ${response.statusText}`);
            }
            
            const data = await response.json();
            alert(data.message);
            location.reload();
        } catch (error) {
            console.error('Error stopping agent:', error);
            alert(`Error al detener agente: ${error.message}`);
        }
    }
    
    // Eliminar agente
    async function deleteAgent(agentId) {
        if (!confirm(`¿Estás seguro de que deseas eliminar el agente ${agentId}?`)) {
            return;
        }
        
        try {
            const response = await fetch(`/api/agents/${agentId}`, {
                method: 'DELETE'
            });
            
            if (!response.ok) {
                throw new Error(`Error: ${response.status} - ${response.statusText}`);
            }
            
            const data = await response.json();
            alert(data.message);
            location.reload();
        } catch (error) {
            console.error('Error deleting agent:', error);
            alert(`Error al eliminar agente: ${error.message}`);
        }
    }
</script>
{% endblock %} 
```

### src\web\templates\base.html
```html | 5271 bytes | Modificado: 2025-03-07 02:38:14.492825
```
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{% block title %}Sistema de Videovigilancia{% endblock %}</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.3/font/bootstrap-icons.css">
    <style>
        body {
            padding-top: 60px;
            background-color: #f8f9fa;
        }
        .navbar-brand {
            font-weight: bold;
        }
        .sidebar {
            position: fixed;
            top: 56px;
            bottom: 0;
            left: 0;
            z-index: 100;
            padding: 20px 0;
            overflow-x: hidden;
            overflow-y: auto;
            background-color: #343a40;
        }
        .sidebar .nav-link {
            font-weight: 500;
            color: #ced4da;
        }
        .sidebar .nav-link.active {
            color: #fff;
        }
        .sidebar .nav-link:hover {
            color: #fff;
        }
        .sidebar .nav-link i {
            margin-right: 4px;
        }
        .main-content {
            padding: 20px;
        }
        .card {
            margin-bottom: 20px;
            box-shadow: 0 0.125rem 0.25rem rgba(0, 0, 0, 0.075);
        }
        .event-card {
            border-left: 4px solid #007bff;
        }
        .event-card.high-priority {
            border-left-color: #dc3545;
        }
        .event-card.medium-priority {
            border-left-color: #fd7e14;
        }
        .event-card.low-priority {
            border-left-color: #28a745;
        }
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 5px;
        }
        .status-running {
            background-color: #28a745;
        }
        .status-stopped {
            background-color: #dc3545;
        }
        .status-warning {
            background-color: #ffc107;
        }
    </style>
    {% block extra_css %}{% endblock %}
</head>
<body>
    <nav class="navbar navbar-expand-md navbar-dark bg-dark fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="/">
                <i class="bi bi-camera-video"></i> Sistema de Videovigilancia
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarCollapse">
                <ul class="navbar-nav me-auto mb-2 mb-md-0">
                    <li class="nav-item">
                        <a class="nav-link {% if request.url.path == '/' %}active{% endif %}" href="/">Dashboard</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link {% if request.url.path == '/agents' %}active{% endif %}" href="/agents">Agentes</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link {% if request.url.path == '/events' %}active{% endif %}" href="/events">Eventos</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link {% if request.url.path == '/media' %}active{% endif %}" href="/media">Multimedia</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container-fluid">
        <div class="row">
            <main class="col-md-12 ms-sm-auto px-md-4 main-content">
                {% block content %}{% endblock %}
            </main>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.7.1/dist/chart.min.js"></script>
    <script>
        // Función común para realizar solicitudes a la API
        async function apiRequest(url, method = 'GET', body = null) {
            const options = {
                method: method,
                headers: {
                    'Content-Type': 'application/json'
                }
            };
            
            if (body) {
                options.body = JSON.stringify(body);
            }
            
            try {
                const response = await fetch(url, options);
                if (!response.ok) {
                    throw new Error(`Error: ${response.status} - ${response.statusText}`);
                }
                return await response.json();
            } catch (error) {
                console.error('API request failed:', error);
                alert(`Error en la solicitud: ${error.message}`);
                throw error;
            }
        }
    </script>
    {% block extra_js %}{% endblock %}
</body>
</html> 
```

### src\web\templates\error.html
```html | 1149 bytes | Modificado: 2025-03-06 00:57:49.741354
```
{% extends "base.html" %}

{% block title %}Error - Sistema de Videovigilancia{% endblock %}

{% block content %}
<div class="container">
    <div class="row justify-content-center">
        <div class="col-md-8">
            <div class="card border-danger">
                <div class="card-header bg-danger text-white">
                    <h5 class="card-title mb-0">
                        <i class="bi bi-exclamation-triangle-fill"></i> Error
                    </h5>
                </div>
                <div class="card-body">
                    <p class="card-text">{{ error }}</p>
                    <div class="text-center mt-4">
                        <a href="javascript:history.back()" class="btn btn-outline-primary me-2">
                            <i class="bi bi-arrow-left"></i> Volver
                        </a>
                        <a href="/" class="btn btn-primary">
                            <i class="bi bi-house"></i> Ir al Dashboard
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock %} 
```

### src\web\templates\events.html
```html | 10031 bytes | Modificado: 2025-03-06 00:57:49.741354
```
{% extends "base.html" %}

{% block title %}Historial de Eventos - Sistema de Videovigilancia{% endblock %}

{% block content %}
<div class="container">
    <h1 class="mb-4">Historial de Eventos</h1>
    
    <div class="card mb-4">
        <div class="card-header bg-secondary text-white">
            <h5 class="card-title mb-0">Filtros</h5>
        </div>
        <div class="card-body">
            <form action="/events" method="get" class="row g-3">
                <div class="col-md-4">
                    <label for="eventType" class="form-label">Tipo de Evento</label>
                    <select class="form-select" id="eventType" name="event_type">
                        <option value="">Todos</option>
                        <option value="motion_detected" {% if event_type == 'motion_detected' %}selected{% endif %}>Movimiento detectado</option>
                        <option value="object_detected" {% if event_type == 'object_detected' %}selected{% endif %}>Objeto detectado</option>
                        <option value="behavior_detected" {% if event_type == 'behavior_detected' %}selected{% endif %}>Comportamiento sospechoso</option>
                        <option value="zone_violation" {% if event_type == 'zone_violation' %}selected{% endif %}>Violación de zona</option>
                        <option value="system" {% if event_type == 'system' %}selected{% endif %}>Sistema</option>
                    </select>
                </div>
                <div class="col-md-4">
                    <label for="limit" class="form-label">Resultados por página</label>
                    <select class="form-select" id="limit" name="limit">
                        <option value="10">10</option>
                        <option value="25">25</option>
                        <option value="50" selected>50</option>
                        <option value="100">100</option>
                    </select>
                </div>
                <div class="col-md-4 d-flex align-items-end">
                    <button type="submit" class="btn btn-primary w-100">
                        <i class="bi bi-search"></i> Filtrar
                    </button>
                </div>
            </form>
        </div>
    </div>
    
    {% if events %}
        <div class="card">
            <div class="card-header bg-primary text-white">
                <h5 class="card-title mb-0">Eventos</h5>
            </div>
            <div class="card-body p-0">
                <div class="table-responsive">
                    <table class="table table-striped table-hover mb-0">
                        <thead class="table-light">
                            <tr>
                                <th>Tipo</th>
                                <th>Prioridad</th>
                                <th>Fecha/Hora</th>
                                <th>Detalles</th>
                            </tr>
                        </thead>
                        <tbody>
                            {% for event in events %}
                                <tr>
                                    <td>{{ event.event_type }}</td>
                                    <td>
                                        {% if event.priority >= 4 %}
                                            <span class="badge bg-danger">Alta</span>
                                        {% elif event.priority >= 2 %}
                                            <span class="badge bg-warning text-dark">Media</span>
                                        {% else %}
                                            <span class="badge bg-success">Baja</span>
                                        {% endif %}
                                    </td>
                                    <td>{{ event.timestamp }}</td>
                                    <td>
                                        <button type="button" class="btn btn-sm btn-outline-info" 
                                                data-bs-toggle="modal" 
                                                data-bs-target="#eventModal{{ loop.index }}">
                                            Ver detalles
                                        </button>
                                    </td>
                                </tr>
                                
                                <!-- Modal para detalles del evento -->
                                <div class="modal fade" id="eventModal{{ loop.index }}" tabindex="-1">
                                    <div class="modal-dialog modal-lg">
                                        <div class="modal-content">
                                            <div class="modal-header">
                                                <h5 class="modal-title">Detalles del evento: {{ event.event_type }}</h5>
                                                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                                            </div>
                                            <div class="modal-body">
                                                <dl class="row">
                                                    <dt class="col-sm-3">ID:</dt>
                                                    <dd class="col-sm-9">{{ event.event_id }}</dd>
                                                    
                                                    <dt class="col-sm-3">Tipo:</dt>
                                                    <dd class="col-sm-9">{{ event.event_type }}</dd>
                                                    
                                                    <dt class="col-sm-3">Fecha/Hora:</dt>
                                                    <dd class="col-sm-9">{{ event.timestamp }}</dd>
                                                    
                                                    <dt class="col-sm-3">Prioridad:</dt>
                                                    <dd class="col-sm-9">{{ event.priority }}</dd>
                                                    
                                                    <dt class="col-sm-3">Datos:</dt>
                                                    <dd class="col-sm-9">
                                                        <pre class="bg-light p-3">{{ event.data|tojson(indent=2) }}</pre>
                                                    </dd>
                                                </dl>
                                                
                                                {% if event.data.snapshot_path is defined %}
                                                    <h6>Imagen de captura:</h6>
                                                    <img src="/snapshots/{{ event.data.snapshot_path.split('/')[-1] }}" 
                                                         class="img-fluid" alt="Captura del evento">
                                                {% endif %}
                                            </div>
                                            <div class="modal-footer">
                                                <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cerrar</button>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            {% endfor %}
                        </tbody>
                    </table>
                </div>
            </div>
            <div class="card-footer">
                <nav>
                    <ul class="pagination justify-content-center mb-0">
                        {% if current_page > 1 %}
                            <li class="page-item">
                                <a class="page-link" href="/events?limit={{ limit }}&offset={{ (current_page - 2) * limit }}{% if event_type %}&event_type={{ event_type }}{% endif %}">
                                    Anterior
                                </a>
                            </li>
                        {% else %}
                            <li class="page-item disabled">
                                <span class="page-link">Anterior</span>
                            </li>
                        {% endif %}
                        
                        {% for i in range(1, total_pages + 1) %}
                            <li class="page-item {% if i == current_page %}active{% endif %}">
                                <a class="page-link" href="/events?limit={{ limit }}&offset={{ (i - 1) * limit }}{% if event_type %}&event_type={{ event_type }}{% endif %}">
                                    {{ i }}
                                </a>
                            </li>
                        {% endfor %}
                        
                        {% if current_page < total_pages %}
                            <li class="page-item">
                                <a class="page-link" href="/events?limit={{ limit }}&offset={{ current_page * limit }}{% if event_type %}&event_type={{ event_type }}{% endif %}">
                                    Siguiente
                                </a>
                            </li>
                        {% else %}
                            <li class="page-item disabled">
                                <span class="page-link">Siguiente</span>
                            </li>
                        {% endif %}
                    </ul>
                </nav>
            </div>
        </div>
    {% else %}
        <div class="alert alert-info">
            <i class="bi bi-info-circle"></i> No se encontraron eventos que coincidan con los criterios de búsqueda.
        </div>
    {% endif %}
</div>
{% endblock %} 
```

### src\web\templates\index.html
```html | 10243 bytes | Modificado: 2025-03-06 00:55:40.499806
```
{% extends "base.html" %}

{% block title %}Dashboard - Sistema de Videovigilancia{% endblock %}

{% block content %}
<div class="container">
    <h1 class="mb-4">Dashboard</h1>
    
    <div class="row">
        <div class="col-md-6">
            <div class="card">
                <div class="card-header bg-primary text-white">
                    <h5 class="card-title mb-0">Estado del Sistema</h5>
                </div>
                <div class="card-body">
                    <div class="d-flex justify-content-between mb-3">
                        <div><strong>Estado:</strong></div>
                        <div>
                            <span class="badge bg-success">{{ system_status.status }}</span>
                        </div>
                    </div>
                    <div class="d-flex justify-content-between mb-3">
                        <div><strong>Versión:</strong></div>
                        <div>{{ system_status.version }}</div>
                    </div>
                    <div class="d-flex justify-content-between mb-3">
                        <div><strong>Agentes activos:</strong></div>
                        <div>{{ system_status.agents|length }}</div>
                    </div>
                    <div class="d-flex justify-content-between">
                        <div><strong>Total de eventos:</strong></div>
                        <div>{{ system_status.total_events }}</div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="col-md-6">
            <div class="card">
                <div class="card-header bg-info text-white">
                    <h5 class="card-title mb-0">Agentes</h5>
                </div>
                <div class="card-body">
                    {% if system_status.agents %}
                        <ul class="list-group">
                            {% for agent in system_status.agents %}
                                <li class="list-group-item d-flex justify-content-between align-items-center">
                                    <div>
                                        <span class="status-indicator status-{{ agent.status }}"></span>
                                        {{ agent.agent_id }} ({{ agent.agent_type }})
                                    </div>
                                    <div>
                                        {% if agent.status == 'running' %}
                                            <span class="badge bg-success">Activo</span>
                                        {% else %}
                                            <span class="badge bg-danger">Inactivo</span>
                                        {% endif %}
                                    </div>
                                </li>
                            {% endfor %}
                        </ul>
                    {% else %}
                        <div class="alert alert-info mb-0">
                            No hay agentes registrados.
                            <a href="/agents" class="alert-link">Crear un agente</a>
                        </div>
                    {% endif %}
                </div>
                <div class="card-footer text-end">
                    <a href="/agents" class="btn btn-primary btn-sm">Gestionar agentes</a>
                </div>
            </div>
        </div>
    </div>
    
    <div class="row mt-4">
        <div class="col-12">
            <div class="card">
                <div class="card-header bg-warning">
                    <h5 class="card-title mb-0">Últimos eventos</h5>
                </div>
                <div class="card-body">
                    {% if events %}
                        <div class="table-responsive">
                            <table class="table table-striped">
                                <thead>
                                    <tr>
                                        <th>Tipo</th>
                                        <th>Prioridad</th>
                                        <th>Fecha/Hora</th>
                                        <th>Detalles</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    {% for event in events %}
                                        <tr>
                                            <td>{{ event.event_type }}</td>
                                            <td>
                                                {% if event.priority >= 4 %}
                                                    <span class="badge bg-danger">Alta</span>
                                                {% elif event.priority >= 2 %}
                                                    <span class="badge bg-warning text-dark">Media</span>
                                                {% else %}
                                                    <span class="badge bg-success">Baja</span>
                                                {% endif %}
                                            </td>
                                            <td>{{ event.timestamp }}</td>
                                            <td>
                                                <button type="button" class="btn btn-sm btn-outline-info" 
                                                        data-bs-toggle="modal" 
                                                        data-bs-target="#eventModal{{ loop.index }}">
                                                    Ver detalles
                                                </button>
                                            </td>
                                        </tr>
                                        
                                        <!-- Modal para detalles del evento -->
                                        <div class="modal fade" id="eventModal{{ loop.index }}" tabindex="-1">
                                            <div class="modal-dialog modal-lg">
                                                <div class="modal-content">
                                                    <div class="modal-header">
                                                        <h5 class="modal-title">Detalles del evento: {{ event.event_type }}</h5>
                                                        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                                                    </div>
                                                    <div class="modal-body">
                                                        <dl class="row">
                                                            <dt class="col-sm-3">ID:</dt>
                                                            <dd class="col-sm-9">{{ event.event_id }}</dd>
                                                            
                                                            <dt class="col-sm-3">Tipo:</dt>
                                                            <dd class="col-sm-9">{{ event.event_type }}</dd>
                                                            
                                                            <dt class="col-sm-3">Fecha/Hora:</dt>
                                                            <dd class="col-sm-9">{{ event.timestamp }}</dd>
                                                            
                                                            <dt class="col-sm-3">Prioridad:</dt>
                                                            <dd class="col-sm-9">{{ event.priority }}</dd>
                                                            
                                                            <dt class="col-sm-3">Datos:</dt>
                                                            <dd class="col-sm-9">
                                                                <pre class="bg-light p-3">{{ event.data|tojson(indent=2) }}</pre>
                                                            </dd>
                                                        </dl>
                                                        
                                                        {% if event.data.snapshot_path is defined %}
                                                            <h6>Imagen de captura:</h6>
                                                            <img src="/snapshots/{{ event.data.snapshot_path.split('/')[-1] }}" 
                                                                 class="img-fluid" alt="Captura del evento">
                                                        {% endif %}
                                                    </div>
                                                    <div class="modal-footer">
                                                        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cerrar</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    {% endfor %}
                                </tbody>
                            </table>
                        </div>
                    {% else %}
                        <div class="alert alert-info mb-0">
                            No hay eventos registrados.
                        </div>
                    {% endif %}
                </div>
                <div class="card-footer text-end">
                    <a href="/events" class="btn btn-primary btn-sm">Ver todos los eventos</a>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block extra_js %}
<script>
    // Refrescar automáticamente la página cada 30 segundos
    setTimeout(function() {
        location.reload();
    }, 30000);
</script>
{% endblock %} 
```

### src\web\templates\media.html
```html | 8108 bytes | Modificado: 2025-03-06 00:57:49.741354
```
{% extends "base.html" %}

{% block title %}Multimedia - Sistema de Videovigilancia{% endblock %}

{% block content %}
<div class="container">
    <h1 class="mb-4">Multimedia</h1>
    
    <ul class="nav nav-tabs mb-4" id="mediaTab" role="tablist">
        <li class="nav-item" role="presentation">
            <button class="nav-link active" id="snapshots-tab" data-bs-toggle="tab" 
                    data-bs-target="#snapshots" type="button" role="tab">
                <i class="bi bi-image"></i> Capturas
            </button>
        </li>
        <li class="nav-item" role="presentation">
            <button class="nav-link" id="recordings-tab" data-bs-toggle="tab" 
                    data-bs-target="#recordings" type="button" role="tab">
                <i class="bi bi-film"></i> Grabaciones
            </button>
        </li>
    </ul>
    
    <div class="tab-content" id="mediaTabContent">
        <!-- Pestaña de capturas -->
        <div class="tab-pane fade show active" id="snapshots" role="tabpanel">
            {% if snapshots %}
                <div class="row">
                    {% for snapshot in snapshots %}
                        <div class="col-md-4 mb-4">
                            <div class="card h-100">
                                <img src="/snapshots/{{ snapshot.filename }}" class="card-img-top" 
                                     alt="Snapshot" style="height: 200px; object-fit: cover;">
                                <div class="card-body">
                                    <h6 class="card-title">{{ snapshot.filename }}</h6>
                                    <p class="card-text">
                                        <small class="text-muted">Fecha: {{ snapshot.created }}</small><br>
                                        <small class="text-muted">Tamaño: {{ (snapshot.size / 1024)|round(1) }} KB</small>
                                    </p>
                                </div>
                                <div class="card-footer">
                                    <a href="/snapshots/{{ snapshot.filename }}" target="_blank" class="btn btn-sm btn-primary">
                                        <i class="bi bi-eye"></i> Ver
                                    </a>
                                    <a href="/snapshots/{{ snapshot.filename }}" download class="btn btn-sm btn-outline-secondary">
                                        <i class="bi bi-download"></i> Descargar
                                    </a>
                                </div>
                            </div>
                        </div>
                    {% endfor %}
                </div>
            {% else %}
                <div class="alert alert-info">
                    <i class="bi bi-info-circle"></i> No hay capturas disponibles.
                </div>
            {% endif %}
        </div>
        
        <!-- Pestaña de grabaciones -->
        <div class="tab-pane fade" id="recordings" role="tabpanel">
            {% if recordings %}
                <div class="table-responsive">
                    <table class="table table-striped table-hover">
                        <thead>
                            <tr>
                                <th>Nombre</th>
                                <th>Fecha</th>
                                <th>Tamaño</th>
                                <th>Acciones</th>
                            </tr>
                        </thead>
                        <tbody>
                            {% for recording in recordings %}
                                <tr>
                                    <td>{{ recording.filename }}</td>
                                    <td>{{ recording.created }}</td>
                                    <td>{{ (recording.size / (1024 * 1024))|round(2) }} MB</td>
                                    <td>
                                        <a href="#" class="btn btn-sm btn-primary" data-bs-toggle="modal" 
                                           data-bs-target="#videoModal{{ loop.index }}">
                                            <i class="bi bi-play-circle"></i> Reproducir
                                        </a>
                                        <a href="/recordings/{{ recording.filename }}" download class="btn btn-sm btn-outline-secondary">
                                            <i class="bi bi-download"></i> Descargar
                                        </a>
                                        {% if recording.metadata %}
                                            <button class="btn btn-sm btn-outline-info" data-bs-toggle="modal" 
                                                   data-bs-target="#metadataModal{{ loop.index }}">
                                                <i class="bi bi-info-circle"></i> Info
                                            </button>
                                        {% endif %}
                                    </td>
                                </tr>
                                
                                <!-- Modal para reproducir video -->
                                <div class="modal fade" id="videoModal{{ loop.index }}" tabindex="-1">
                                    <div class="modal-dialog modal-lg">
                                        <div class="modal-content">
                                            <div class="modal-header">
                                                <h5 class="modal-title">{{ recording.filename }}</h5>
                                                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                                            </div>
                                            <div class="modal-body">
                                                <video controls class="w-100">
                                                    <source src="/recordings/{{ recording.filename }}" type="video/mp4">
                                                    Tu navegador no soporta la reproducción de videos.
                                                </video>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                
                                <!-- Modal para metadatos -->
                                {% if recording.metadata %}
                                    <div class="modal fade" id="metadataModal{{ loop.index }}" tabindex="-1">
                                        <div class="modal-dialog">
                                            <div class="modal-content">
                                                <div class="modal-header">
                                                    <h5 class="modal-title">Metadatos de {{ recording.filename }}</h5>
                                                    <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                                                </div>
                                                <div class="modal-body">
                                                    <pre class="bg-light p-3">{{ recording.metadata|tojson(indent=2) }}</pre>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                {% endif %}
                            {% endfor %}
                        </tbody>
                    </table>
                </div>
            {% else %}
                <div class="alert alert-info">
                    <i class="bi bi-info-circle"></i> No hay grabaciones disponibles.
                </div>
            {% endif %}
        </div>
    </div>
</div>
{% endblock %} 
```

## RESUMEN DE LA DOCUMENTACIÓN

- Archivos procesados: 110
- Archivos ignorados: 2
- Tamaño total de archivos incluidos: 822.12 KB

Documentación generada con el script de documentación automática de vigIA.
